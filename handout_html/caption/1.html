<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
0:00:00.000,0:00:01.400
臺灣大學人工智慧中心
科技部人工智慧技術暨全幅健康照護聯合研究中心
http://aintu.tw

0:00:01.400,0:00:02.920
臺灣大學人工智慧中心
科技部人工智慧技術暨全幅健康照護聯合研究中心
http://aintu.tw

0:00:02.920,0:00:03.420
臺灣大學人工智慧中心
科技部人工智慧技術暨全幅健康照護聯合研究中心
http://aintu.tw

0:00:03.420,0:00:03.920
臺灣大學人工智慧中心
科技部人工智慧技術暨全幅健康照護聯合研究中心
http://aintu.tw

0:00:09.860,0:00:11.540
這一門課，我們預期可以學到甚麼呢  ?

0:00:13.515,0:00:16.475
我想很多同學心理的預期就是 :

0:00:16.475,0:00:19.635
"你可以學到一個很潮的人工智慧"

0:00:19.655,0:00:23.005
我知道從今年開始，"人工智慧"這個詞，

0:00:23.365,0:00:26.375
突然變得非常非常非常的

0:00:26.375,0:00:27.665
熱門

0:00:29.255,0:00:32.065
大家,政府,internship,通通都在講"人工智慧"這個詞

0:00:32.065,0:00:34.585
但人工智慧是甚麼呢?

0:00:34.585,0:00:37.465
人工智慧其實一點都不是新的詞彙

0:00:37.465,0:00:41.180
人工智慧這個詞，AI這個詞，artificial intelligence這個詞

0:00:41.680,0:00:42.180
在1950年代，

0:00:42.180,0:00:43.085
就有了!

0:00:44.085,0:00:46.895
這個詞意味著甚麼呢?

0:00:46.895,0:00:51.740
這個詞意味著人類長遠以來的目標 : 希望機器可以跟人

0:00:51.740,0:00:52.475
一樣的聰明。

0:00:52.475,0:00:55.355
在科幻小說裡面，

0:00:55.355,0:00:58.215
我們看到很多的幻想和期待。

0:00:58.215,0:01:01.335
在很長的一段時間內，人們並不知道怎麼做到

0:01:01.335,0:01:04.725
人工智慧這件事情。

0:01:04.765,0:01:06.780
直到後來，大概1980年代以後，

0:01:07.635,0:01:09.635
有了機器學習的方法。

0:01:09.635,0:01:10.135
機器學習，

0:01:10.195,0:01:13.215
顧名思義，從名詞就可以猜出

0:01:13.215,0:01:15.215
就是讓機器具有學習的能力。

0:01:16.140,0:01:19.215
機器學習跟人工智慧有甚麼關係呢?

0:01:19.215,0:01:21.215
人工智慧

0:01:21.215,0:01:22.175
是我們想要達成的目標 ;

0:01:22.175,0:01:25.165
而機器學習，

0:01:25.165,0:01:25.665
是想要

0:01:25.665,0:01:26.165
達成目標

0:01:26.165,0:01:29.525
的手段! 讓機器透過學習的方式

0:01:29.745,0:01:32.895
它可以跟人一樣聰明。

0:01:32.895,0:01:35.625
而深度學習和機器學習有甚麼關係呢?

0:01:35.625,0:01:36.125
深度學習就是

0:01:36.125,0:01:37.695
機器學習的其中一種方法。

0:01:40.355,0:01:43.345
在有深度學習機器學習之前，

0:01:43.345,0:01:45.345
人們用什麼樣的方式，

0:01:45.345,0:01:46.700
來做到人工智慧

0:01:46.700,0:01:48.485
這件事呢?

0:01:48.485,0:01:50.485
我記得高中生物學的

0:01:50.485,0:01:51.895
告訴我們說，

0:01:51.895,0:01:53.895
生物的行為取決於兩件事 :

0:01:54.625,0:01:56.335
"一個是後天學習的結果

0:01:56.735,0:01:59.525
不是後天學習的結果就是先天的本能。"

0:02:00.005,0:02:02.905
這對機器來說也是一樣，

0:02:02.905,0:02:04.905
它怎麼樣表現得很有智慧?

0:02:04.905,0:02:05.405
要嘛就是透過後天學習的手段，

0:02:05.885,0:02:08.995
表現得很有智慧；

0:02:08.995,0:02:11.895
要嘛就是這是它先天的本能。

0:02:11.895,0:02:13.525
機器為甚麼會有先天的本能?那個本能就是

0:02:14.295,0:02:17.355
就是它的創造者，其實就是人類，幫它事先設定好。

0:02:18.455,0:02:24.260
那麼我們先來看一下生物的本能

0:02:24.260,0:02:27.415
講一個跟機器學習一點都沒關係的，我們來講生物的本能

0:02:27.865,0:02:29.865
這個是河狸。河狸的特色就是

0:02:29.865,0:02:30.795
牠會

0:02:30.795,0:02:33.765
築水壩把水擋起來。

0:02:34.775,0:02:37.545
但是河狸怎麼知道要築水壩呢?

0:02:37.545,0:02:40.885
河狸築水壩的能力是天生的。

0:02:40.885,0:02:41.400
也就是說，

0:02:41.400,0:02:42.305
講這個河狸是天生的，

0:02:42.625,0:02:44.640
牠在實驗室裡出生，牠沒有父母教牠怎麼 築水壩，

0:02:46.035,0:02:46.535
但是

0:02:46.535,0:02:47.665
牠一生下來，

0:02:48.405,0:02:50.405
心裡就有一個衝動，就是牠想要

0:02:50.405,0:02:51.655
築水壩。

0:02:53.695,0:02:56.715
如果我們用程式語言來描述牠的話，

0:02:56.715,0:02:58.715
牠內建的程式語言是這樣的

0:02:58.715,0:02:59.795
:

0:03:01.605,0:03:02.835
if 牠聽到流水聲

0:03:03.205,0:03:06.095
then 牠就築水壩直到聽不到流水聲為止

0:03:07.405,0:03:10.675
所以生物學家就可以欺負河狸，

0:03:10.675,0:03:13.795
他就用一個揚聲器來播放流水聲

0:03:13.795,0:03:16.725
如果把揚聲器放在水泥牆裡面，

0:03:18.325,0:03:21.325
河狸就會在水泥牆上面

0:03:21.335,0:03:23.335
放很多的樹枝，

0:03:23.335,0:03:23.835
在水泥牆上築一個堤，

0:03:24.275,0:03:27.305
然後想要把揚聲器的聲音蓋住

0:03:27.355,0:03:29.355
如果把揚聲器放在地上，

0:03:30.145,0:03:33.415
河狸就會用樹枝把它蓋住，直到聽不到揚聲器的聲音為止

0:03:34.135,0:03:36.115
所以這是 生物的本能。

0:03:36.935,0:03:40.125
那機器的本能跟生物的本能其實很像:

0:03:40.125,0:03:43.375
假設有一天，你想要做一個chat-bot

0:03:43.375,0:03:46.405
如果你不是用learning的方式，也不是用機器學習的方式，

0:03:46.405,0:03:49.765
而是給它天生的本能的話，

0:03:49.765,0:03:52.695
那像是甚麼樣子呢?你可能會在這個chat-bot裡面，

0:03:52.695,0:03:55.885
在這個聊天機器人裡面，

0:03:55.885,0:03:58.855
設定一些規則，這些規則我們通常稱之為hand-crafted rules

0:03:58.855,0:04:01.665
就是人設定的規則。

0:04:02.455,0:04:02.955
假設你今天要

0:04:03.705,0:04:06.465
設定一個對話機器人，

0:04:06.465,0:04:09.795
它可以幫你打開和關掉音樂的話，那你的做法可能是這樣:

0:04:09.795,0:04:12.885
設定一條規則，就是寫程式這樣，

0:04:13.625,0:04:14.420
如果

0:04:14.420,0:04:16.135
輸入的句子裡面，

0:04:16.905,0:04:18.115
看到turn off這個詞彙，

0:04:18.595,0:04:20.905
那麼chat-bot要做的事情就是，

0:04:21.335,0:04:24.025
把音樂關掉。

0:04:24.335,0:04:24.835
這個時候，

0:04:24.835,0:04:26.725
你之後對chat-bot說

0:04:27.065,0:04:29.935
"Please turn off the music."

0:04:29.935,0:04:32.495
或"Can you turn off the music,  please?"

0:04:33.075,0:04:36.395
看起來好像很聰明，

0:04:36.395,0:04:39.355
人家就會覺得，嗯果然這就是人工智慧。

0:04:39.355,0:04:41.935
但是如果你今天想要欺負那個chat-bot的話，

0:04:42.085,0:04:44.975
你就可以說，"Please don't turn off the music."

0:04:46.125,0:04:49.375
但是它還是會把音樂關掉。

0:04:49.375,0:04:50.320
這是個真實的例子，

0:04:50.320,0:04:52.385
你可以看看你身邊有沒有類似的chat-bot

0:04:52.385,0:04:55.375
然後你去真的對它說這種

0:04:55.455,0:04:57.615
故意欺負它講這種話，它其實是會答錯的。

0:04:58.065,0:04:58.920
這其實是真實的例子，

0:04:58.920,0:04:59.785
不要告訴你是哪家公司的產品，

0:05:00.525,0:05:03.785
這家公司也是號稱他們做了很多AI的東西。

0:05:04.315,0:05:07.045
不要讓你發現是哪一家的產品，

0:05:07.045,0:05:08.045
免得被告。

0:05:08.335,0:05:11.155
用這個hand-crafted rules 有甚麼壞處呢?

0:05:11.155,0:05:14.195
它的壞處就是，

0:05:14.195,0:05:17.145
hand-crafted rules沒有辦法考慮到所有的可能性，

0:05:17.145,0:05:20.075
它非常的僵化，

0:05:21.685,0:05:23.685
而用hand-crafted rules創造出來的machine，

0:05:24.815,0:05:25.600
它永遠沒有辦法

0:05:25.600,0:05:27.845
超過它的創造者，也就是人類。

0:05:27.845,0:05:28.845
人類想不到的東西，

0:05:29.515,0:05:31.515
你就沒有辦法寫規則，

0:05:31.515,0:05:32.895
你沒有寫規則，

0:05:33.015,0:05:35.015
機器就不知道要怎麼辦。

0:05:35.015,0:05:36.095
所以一個機器如果

0:05:36.095,0:05:38.095
只能按照人設定好的hand-crafted rules，

0:05:38.095,0:05:42.025
它所有的行為都是set好，

0:05:42.255,0:05:44.255
它沒有free style的。如果是這樣子的話，

0:05:44.255,0:05:45.435
它就沒有辦法超越創造它的

0:05:45.435,0:05:47.715
人類。

0:05:48.435,0:05:49.480
你可能會說，

0:05:50.645,0:05:51.645
但是你好像看到很多chat-bot，

0:05:51.855,0:05:54.565
看起來非常的聰明，

0:05:54.965,0:05:56.965
這些chat-bot,

0:05:58.035,0:06:01.325
如果是個非常大的industry，其實它可以hire成千上萬的工程師這類的職業，

0:06:01.635,0:06:04.655
以血汗的方式，

0:06:04.655,0:06:05.380
來建出

0:06:05.380,0:06:07.645
數以萬計的規則，

0:06:09.875,0:06:10.855
然後讓它的機器

0:06:10.855,0:06:11.620
看起來好像很聰明。

0:06:11.620,0:06:13.695
但是對於中小企業來說，

0:06:13.695,0:06:16.625
這樣建規則的方式，反而是不利的。

0:06:16.625,0:06:19.365
所以我認為機器學習的發展，

0:06:19.365,0:06:22.555
對於比較小規模的企業反而是有利的，因為接下來也不需要hire 非常大量的人，

0:06:22.555,0:06:25.765
來幫你想各式各樣的規則。

0:06:26.195,0:06:29.095
你只要手上有data，

0:06:29.095,0:06:32.395
你可以讓機器來幫你做這件事情。

0:06:32.395,0:06:34.185
當然怎麼collect data又是另外一個問題，

0:06:34.185,0:06:36.565
這個不是我們今天要討論的主題。

0:06:37.445,0:06:39.445
我知道

0:06:39.445,0:06:40.545
AI這個詞，

0:06:40.545,0:06:43.665
現在非常非常非常的熱門，

0:06:43.665,0:06:44.460
所以會有

0:06:44.460,0:06:46.465
各式各樣，

0:06:46.465,0:06:49.215
奇奇怪怪的東西。

0:06:49.215,0:06:51.775
我覺得現在非常常遇到的問題，

0:06:51.775,0:06:54.935
以許可以用以下這個漫畫來說明，這是個四格漫畫，

0:06:54.935,0:06:56.355
這個漫畫並不是

0:06:56.695,0:06:59.825
隨隨便便的一個四格漫畫，這個一塊畫是，

0:06:59.975,0:07:02.005
Yann Lecun share在他的facebook上的漫畫。

0:07:03.875,0:07:05.520
這個漫畫說甚麼呢?

0:07:07.240,0:07:09.875
現在也一定常常在新聞或者是商展上看到這種東西。

0:07:10.665,0:07:13.655
有一個sales說，

0:07:13.655,0:07:16.445
看看我們最新的人工智慧機器人，

0:07:16.445,0:07:19.345
它就是非常的人工智慧，

0:07:19.755,0:07:22.475
要show這個系統呢，要搭配一個能言善道的sales，

0:07:22.475,0:07:24.735
加上一個非常非常潮的前端跟外殼

0:07:25.525,0:07:27.815
裡面是甚麼沒有人知道。

0:07:27.815,0:07:31.015
外面的觀眾就問說，它就是用甚麼neural的方法做的嗎?

0:07:32.200,0:07:34.375
反正就是，最潮的AI的技術就對了

0:07:34.375,0:07:37.705
但是有時候你把它剖開來看，

0:07:39.585,0:07:41.585
裡面都通通都是

0:07:41.585,0:07:42.385
" if "

0:07:42.385,0:07:43.385
掉出來這樣。

0:07:46.965,0:07:49.995
我知道現在

0:07:49.995,0:07:53.065
政府企業他們都說想要推廣AI，

0:07:53.065,0:07:56.295
有時候他們想要推廣的AI，

0:07:56.295,0:07:58.945
其實是這種AI

0:07:58.945,0:08:01.935
這個其實不是我們現在應該要做的事，

0:08:01.935,0:08:04.655
如果你要推廣的是這種hand-crafted 的AI的話，

0:08:04.655,0:08:07.625
你怎麼50年前不推廣一直到今天才突然做了呢?

0:08:07.625,0:08:10.655
今天我們要走的不是這個路線，

0:08:10.655,0:08:13.335
如果是這個路線，它應該是要被diss的

0:08:13.775,0:08:15.245
我們要做的其實是，

0:08:16.015,0:08:18.015
讓機器它有

0:08:18.475,0:08:19.280
自己學習的能力，

0:08:19.280,0:08:21.555
也就是我們要做的

0:08:21.555,0:08:22.895
應該是machine learning 的方向。

0:08:23.205,0:08:26.375
如果講得比較擬人化一點，

0:08:26.375,0:08:28.545
所謂machine learning 的方向就是，

0:08:29.055,0:08:30.955
這非常擬人化的講法啦

0:08:31.745,0:08:34.485
比較像是騙騙麻瓜的講法

0:08:35.275,0:08:38.205
你就寫一個程式，

0:08:38.205,0:08:38.820
然後它讓機器變得很聰明，

0:08:38.820,0:08:41.075
它就能夠

0:08:41.135,0:08:43.785
有學習的能力，

0:08:43.785,0:08:46.495
接下來就像教一個嬰兒或小孩一樣，

0:08:46.495,0:08:49.785
你並不是寫程式讓它做到這件事，

0:08:49.905,0:08:52.855
你是寫程式讓它具有學習的能力，

0:08:52.855,0:08:55.495
接下來你就可以用像教小孩一樣的方式告訴它說，

0:08:55.495,0:08:58.205
假設你要它學會做語音辨識，

0:08:58.205,0:09:01.225
你就告訴它，這段聲音就是"Hi"

0:09:01.225,0:09:04.125
這段聲音就是"How are you"

0:09:04.125,0:09:07.185
這段聲音就是"Good bye" 。然後希望接下來它就學會了

0:09:07.185,0:09:10.225
然後你給它一段新的聲音，

0:09:10.225,0:09:13.115
它就可以幫你產生語音辨識的結果。

0:09:13.115,0:09:15.000
或者是如過你希望它學會怎麼做影像辨識的話，

0:09:15.765,0:09:17.475
你可能

0:09:18.075,0:09:20.405
不太需要改太多的程式，因為它本身就有學習的能力

0:09:20.405,0:09:22.915
你只是需要教它告訴它說

0:09:23.015,0:09:25.775
看到這張圖片，你要說這是猴子，

0:09:25.775,0:09:28.905
看到這張圖片，你要說這是貓，

0:09:28.905,0:09:32.115
看到這張圖片，你要說這是狗，它就具有影像辨識的能力了，

0:09:32.115,0:09:35.015
接下來看到它沒有看過的貓，希望它可以認得。

0:09:35.815,0:09:38.765
這是比較擬人化的說法，

0:09:38.765,0:09:41.735
如果要講得更務實一點的話，

0:09:41.735,0:09:44.695
你做的事情可以想成是，

0:09:44.695,0:09:47.655
在尋找一個function。

0:09:47.655,0:09:50.435
你要讓機器具有一個能力，

0:09:50.435,0:09:52.185
這個能力是根據你提供給它的資料，

0:09:53.185,0:09:55.845
他去尋找出我們要尋找的function

0:09:57.055,0:09:59.055
那很多我們關心的問題，都可以想成是

0:09:59.055,0:10:00.065
我們就是

0:10:00.065,0:10:03.125
需要一個function,

0:10:03.125,0:10:04.125
舉例來說，語音辨識。

0:10:04.155,0:10:07.165
在語音辨識這個問題裡面，我們要找一個function，

0:10:07.165,0:10:07.880
它的輸入是聲音訊號，

0:10:07.880,0:10:09.975
它的輸出是語音辨識的文字。

0:10:09.975,0:10:13.055
這個function非常非常的複雜，

0:10:13.055,0:10:16.105
有人可能會想說我來用一些寫規則的方式，

0:10:16.105,0:10:18.945
用很多語言學

0:10:18.945,0:10:21.185
讀很多語言學的文獻，

0:10:21.185,0:10:23.815
寫一堆規則做語音辨識。

0:10:23.815,0:10:27.305
這些事情60年代就有人在做了，到現在都還沒做出來。

0:10:27.345,0:10:30.355
語音辨識太過複雜，

0:10:30.355,0:10:33.225
這個function太過複雜，不是人類可以寫出來可以想像的

0:10:33.225,0:10:35.955
所以我們需要憑藉機器的力量，

0:10:35.955,0:10:38.405
幫我們把這個function找出來。

0:10:38.975,0:10:41.895
或者說假設你要做影像辨識，

0:10:41.895,0:10:45.005
那你就要找到一個function，輸入就是一張圖片，

0:10:45.005,0:10:46.815
其實就是圖片裡面的peak zone，

0:10:46.815,0:10:49.845
輸出就是這張圖片有什麼樣的東西。

0:10:50.285,0:10:53.005
或者是這年頭大家都一直在說AlphaGo,

0:10:53.005,0:10:55.775
如果你要做一個可以下圍棋的machine的話，

0:10:55.775,0:10:58.745
其實你需要的也就是找一個function，

0:10:58.745,0:11:02.025
這個function輸入是

0:11:02.025,0:11:05.045
圍棋上19X19路的棋盤的盤勢，你告訴機器說，

0:11:05.660,0:11:08.035
在這19X19棋盤上，哪些位置有黑子，

0:11:08.035,0:11:10.595
哪些位置有白子，

0:11:10.595,0:11:13.025
然後機器就告訴你說，接下來下一步應該要落子在哪裡。

0:11:13.475,0:11:16.525
或者是你要做聊天機器人，

0:11:16.525,0:11:19.615
你需要的也是一個function，

0:11:19.615,0:11:22.265
這個function的輸入就是使用者的input，

0:11:22.265,0:11:25.255
它的輸出就是機器的回應。

0:11:25.255,0:11:28.235
以下我們先很簡短的跟大家說明，

0:11:28.235,0:11:31.015
怎麼樣找出一個function

0:11:31.015,0:11:33.220
找出這個function的framework是甚麼呢?

0:11:33.775,0:11:36.025
我們以影像辨識為例，我們要找一個function，

0:11:36.025,0:11:38.745
輸入一張圖片，它告訴我們圖片裡

0:11:38.745,0:11:40.105
有甚麼樣的東西。

0:11:40.735,0:11:41.460
在做這件事，

0:11:41.995,0:11:44.625
它的起手式是

0:11:44.625,0:11:48.045
你要先準備一個function的set，

0:11:48.525,0:11:51.555
這個function的set裡面，有成千上萬的function，

0:11:52.945,0:11:56.015
舉例來說，這個function set 裡面有一個f1，

0:11:56.015,0:11:58.965
你給它看一隻貓，它就告訴你輸出貓，

0:11:58.965,0:12:01.965
給它看一隻狗，就輸出狗。有一個function f2，

0:12:01.965,0:12:05.355
它很怪，你給它看貓它說是猴子，你給它看狗它說是蛇，

0:12:05.355,0:12:08.205
你要準備一個function set，這個function set

0:12:08.205,0:12:09.845
裡面有成千上萬的function。

0:12:10.205,0:12:13.245
這件事情講起來有點抽象，你可能會很懷疑說，

0:12:13.795,0:12:17.105
這怎麼回事? 怎麼準備成千上萬的function?我怎麼把成千上萬的function收集起來

0:12:17.105,0:12:20.345
變成一個function?不過，

0:12:20.475,0:12:21.240
這我們之後會再講。

0:12:21.240,0:12:23.615
總之我們先講，

0:12:23.615,0:12:26.715
假設你手上有一個function的set，

0:12:26.715,0:12:29.795
其實這個function的set就叫做model。

0:12:30.255,0:12:33.275
有了這個function的set以後，

0:12:33.565,0:12:36.165
接下來第二步機器要做的事情是，

0:12:36.165,0:12:38.915
開始有一些訓練的資料。

0:12:38.915,0:12:41.765
這些訓練資料告訴機器說，

0:12:41.765,0:12:44.745
一個好的function，它的輸入輸出應該長甚麼樣子，

0:12:44.745,0:12:46.715
有甚麼樣的關係。

0:12:46.715,0:12:48.995
你告訴機器說，

0:12:49.515,0:12:52.495
現在在這個影像辨識的問題裡面，

0:12:52.495,0:12:55.575
如果看到這個猴子的圖，你就要輸出猴子。

0:12:55.575,0:12:58.435
看到這個貓的圖你就要輸出貓，看到狗的圖你就要輸出狗，

0:12:58.435,0:13:01.375
這樣才是對。

0:13:01.375,0:13:04.225
藉由這些訓練資料，你拿出一個function，

0:13:04.225,0:13:07.545
機器就可以判斷說這個function是好的

0:13:07.915,0:13:10.825
還是不好的。機器可以判斷一個function

0:13:10.825,0:13:13.875
根據訓練資料判斷一個function是好的

0:13:13.875,0:13:17.105
還是不好的。舉例來說，

0:13:17.105,0:13:19.415
在這個例子裡面，顯然f1，

0:13:19.415,0:13:21.415
它比較符合training data的敘述，

0:13:22.805,0:13:25.775
它比較符合training data給我們的知識，所以f1看起來是比較好的，

0:13:25.775,0:13:28.805
f2看起來是一個很荒謬的function。

0:13:30.345,0:13:33.325
以下這個，我們今天講的這個task，

0:13:33.325,0:13:36.345
叫做supervised

0:13:36.345,0:13:39.155
這個學習的情境其實叫做supervised learning。

0:13:39.155,0:13:40.705
如果你告訴machine function的input

0:13:41.095,0:13:42.095
和output，

0:13:42.115,0:13:45.005
這個叫做supervised learning。

0:13:45.505,0:13:48.355
之後我們會講到其他不同learning的scenario。

0:13:48.405,0:13:51.555
現在機器有辦法決定一個function的好壞，

0:13:54.405,0:13:57.295
光能夠決定一個function的好壞是不夠的，

0:13:57.295,0:14:00.980
因為在你的function pool和function set裡面，它有成千上萬的function，

0:14:00.980,0:14:02.895
它有無窮無盡，幾乎是無窮

0:14:02.895,0:14:05.895
它有無窮的function，不可勝數的function，

0:14:05.895,0:14:09.065
所以我們需要一個有效率的演算法

0:14:09.065,0:14:12.015
這個有效率的演算法，可以從function的set裡面，

0:14:12.015,0:14:15.145
挑出最好的function。一個個function衡量它好不好，

0:14:15.145,0:14:18.215
太花時間了，

0:14:18.215,0:14:21.465
實際上做不到，所以我們需要一個好的演算法，

0:14:21.525,0:14:24.685
去從function的set裡面，挑出一個最好的function。

0:14:24.685,0:14:27.685
這個最好的function，我們把它寫作f*

0:14:28.025,0:14:30.905
找出這個f*以後

0:14:30.905,0:14:33.865
接下來我們就希望拿它來做一些事情

0:14:33.865,0:14:36.715
我們可以拿它來做影像的辨識

0:14:36.715,0:14:39.715
輸入一張在training data裡沒有看過的貓，

0:14:39.715,0:14:43.740
然後希望它的輸出也是貓。你可能會問說，

0:14:43.740,0:14:46.025
機器學的時候沒有看過這隻貓，

0:14:46.025,0:14:49.285
那怎麼知道在測試的時候找出來的最好的function : f*

0:14:49.285,0:14:52.315
可以正確的辨識這隻貓呢?

0:14:52.315,0:14:55.305
這個就是，這樣的序單元裡面，非常重要的問題:

0:14:55.305,0:14:59.380
就是"機器有沒有舉一反三的能力?"

0:14:59.380,0:15:01.745
這個我們之後會再講。

0:15:02.025,0:15:05.125
左邊的部分叫做training，就是學習的過程，

0:15:05.125,0:15:08.395
右邊的部分叫做testing，

0:15:08.395,0:15:11.425
就是學好以後你就可以拿它來運用

0:15:11.425,0:15:14.385
這個是testing。

0:15:14.385,0:15:17.595
所以在整個machine類的framework裡面，整個machine learning分成了三個步驟，

0:15:17.595,0:15:18.985
第一個步驟就是，

0:15:20.325,0:15:22.595
找一個function，訂出一個function的set，

0:15:22.925,0:15:23.580
第二個步驟就是，

0:15:25.075,0:15:28.475
讓一個machine可以衡量一個function是好還是不好

0:15:28.675,0:15:31.915
第三個步驟就是，讓machine有一個自動的方法，

0:15:31.915,0:15:35.245
有一個好的演算法可以挑出最好的function。

0:15:35.245,0:15:36.160
所以機器學習到這邊，

0:15:37.525,0:15:40.255
我們就說完了這樣子。

0:15:40.835,0:15:43.545
也許這整個學期的課你都不需要來，

0:15:45.085,0:15:48.035
所以機器學習就是三個步驟，

0:15:48.705,0:15:51.755
當然這三個步驟其實異常的簡化了整個process，

0:15:51.755,0:15:54.525
講說機器學習只有三個步驟，

0:15:54.525,0:15:57.555
就好像講說如果我們要把大象塞進一個冰箱，

0:15:57.555,0:16:00.585
其實也是三個步驟。

0:16:00.585,0:16:03.525
你怎麼把大象塞進冰箱? 就是把門打開，

0:16:03.525,0:16:06.615
把大象趕進去，然後把門關起來，

0:16:06.615,0:16:09.145
然後就結束了。

0:16:09.145,0:16:12.065
所以說機器學習只有三個步驟就好像是說，把大象放進冰箱

0:16:12.065,0:16:15.285
也只需要三個步驟。意思是一樣的。

0:16:16.445,0:16:19.185
接下來的時間我們要講一下，

0:16:19.185,0:16:21.185
這門課裡面，你可以學到

0:16:21.185,0:16:24.405
哪些和machine learning相關的技術。

0:16:24.425,0:16:26.955
這個是這學期的learning map,

0:16:27.315,0:16:30.395
看起來是有點複雜的，我們一塊一塊來解釋。

0:16:30.395,0:16:33.715
我們先從圖的左上角開始，

0:16:33.955,0:16:36.885
這個圖的左上角是regression，

0:16:36.885,0:16:39.455
甚麼是regression?

0:16:39.455,0:16:42.435
regression 是一種machine learning 的task

0:16:42.435,0:16:45.095
當我們說我們要做regression時的意思是說，

0:16:45.095,0:16:47.185
我們今天要machine找出來的function，

0:16:47.555,0:16:50.605
它的輸出是一個scalar

0:16:50.605,0:16:53.685
是一個數值，一個real number，

0:16:53.685,0:16:56.715
這個叫做regression。

0:16:56.715,0:16:59.685
舉例來說，在作業一裡面，

0:16:59.685,0:17:02.995
我們會要你做PM2.5的預測，也就是說你要找一個function，

0:17:02.995,0:17:05.945
這個function的輸出，

0:17:06.015,0:17:08.485
就是未來某一個時間。

0:17:08.765,0:17:11.805
舉例來說，明天上午的PM2.5。PM2.5是一個數值，

0:17:11.805,0:17:14.735
是一個number。所以這個是一個regression的problem。

0:17:14.735,0:17:17.545
那機器要判斷說，

0:17:17.545,0:17:20.525
今天這個function要輸出明天上午的PM2.5

0:17:20.525,0:17:23.205
那明天上午的PM2.5，

0:17:23.205,0:17:25.065
你要給它一些資訊，

0:17:25.405,0:17:28.315
它才能夠，它沒有辦法憑空猜出來，

0:17:28.315,0:17:31.055
你要給它一些額外的資訊，

0:17:31.055,0:17:34.015
它才能夠猜出明天上午的PM2.5

0:17:34.015,0:17:36.315
你給他的資訊，可能是

0:17:36.315,0:17:39.465
今天上午的PM2.5，昨天上午的PM2.5等等

0:17:39.465,0:17:41.465
這就是一個function， 它吃的是

0:17:41.465,0:17:42.295
我們給它的

0:17:42.295,0:17:45.625
過去的PM2.5的資料，

0:17:45.665,0:17:48.645
它輸出的是預測未來的PM2.5。

0:17:48.645,0:17:51.645
你要訓練這種machine，

0:17:51.675,0:17:54.755
如同我們剛才在講machine類的framework裡面講的，

0:17:54.755,0:17:57.775
你要準備一些訓練資料。甚麼樣的訓練資料?

0:17:57.775,0:18:00.825
你就告訴他說，今天根據我們過去的，

0:18:00.825,0:18:03.295
從政府的open data上收集來的資料，

0:18:06.015,0:18:08.985
9月1號上午的PM2.5是這個樣子，

0:18:08.985,0:18:11.945
9月2號是這個樣子，9月3號是這個樣子，

0:18:11.945,0:18:14.535
所以一個好的function，輸入這樣子的一個PM2.5，

0:18:14.535,0:18:17.345
它應該輸出這樣的PM2.5。

0:18:17.455,0:18:18.080
給它9月12號PM2.5，

0:18:18.080,0:18:19.575
9月13號PM2.5，

0:18:19.575,0:18:22.625
它應該輸出9月14號的PM2.5。

0:18:22.625,0:18:25.605
收集到夠多這樣的data，

0:18:25.605,0:18:28.345
就可以訓練一個可以做氣象預報的系統。

0:18:29.395,0:18:32.385
剛才講的是regression，

0:18:32.395,0:18:35.365
接下來要講的是classification。

0:18:35.585,0:18:38.615
那regression和classification的差別是，

0:18:38.615,0:18:41.345
我們要機器輸出的東西的

0:18:41.345,0:18:44.035
類型是不一樣的。

0:18:44.035,0:18:46.895
在regression裡面輸出的是一個數值，

0:18:46.895,0:18:49.885
在classification裡面機器輸出的是，classification問題又分成兩種，

0:18:49.885,0:18:52.735
一種叫做Binary classification，

0:18:52.735,0:18:55.685
二元的分類。在二元的分類裡面，

0:18:55.685,0:18:58.415
我們要機器輸出的就是 是或否，

0:18:58.415,0:18:59.415
yes 或 no。

0:19:00.105,0:19:03.145
那另外一類classification的problem叫multi-class 的classification

0:19:03.145,0:19:06.215
在multi-class 的classification裡面，

0:19:06.215,0:19:08.575
機器要做的事情是要做一個選擇題

0:19:08.575,0:19:11.605
你等於是給它數個選項，

0:19:11.605,0:19:13.775
每一個選項就是一個類別。

0:19:13.775,0:19:16.015
它都從數個類別裡面選擇正確的類別，

0:19:16.015,0:19:18.625
這叫multi-class 的classification。

0:19:21.205,0:19:23.905
我們就為binary和multi-class classification

0:19:23.905,0:19:27.275
分別舉一個例子。舉例來說，

0:19:27.275,0:19:29.705
G-mail有做spam filtering 這件事

0:19:29.705,0:19:32.725
它自動偵測出垃圾郵件，

0:19:32.725,0:19:35.635
幫你把它放在垃圾郵件夾內。那它怎麼做到這件事呢?

0:19:35.635,0:19:38.575
其實我們需要的就是一個function。

0:19:38.575,0:19:41.065
這個function的輸入就是一封e-mail。

0:19:41.065,0:19:44.445
當然要怎麼讓一個function吃一個e-mail當作輸入?

0:19:45.375,0:19:48.375
是你自己要想看看的。這個我們未來再講。

0:19:48.375,0:19:51.315
這個function吃一個e-mail當作輸入，

0:19:51.315,0:19:54.325
它的輸出就是，這封e-mail是垃圾郵件，還是不是垃圾郵件?

0:19:54.325,0:19:56.325
你要訓練這樣的function，怎麼做?

0:19:56.325,0:19:58.900
很簡單，你就給它一大堆的data，

0:20:00.425,0:20:03.435
告訴它說，現在輸入這一封郵件，

0:20:03.435,0:20:04.434
你應該說它是垃圾郵件；

0:20:04.434,0:20:04.959
你應該說它是垃圾郵件；

0:20:04.959,0:20:05.560
你應該說它是垃圾郵件；

0:20:05.560,0:20:06.060
輸入這一封郵件，

0:20:06.060,0:20:08.480
輸入這一封郵件，

0:20:08.480,0:20:08.980
你應該說它不是垃圾郵件。

0:20:08.980,0:20:11.260
你給它夠多的這種資料去學，

0:20:11.260,0:20:11.904
它就可以自動找出一個，

0:20:11.904,0:20:12.404
它就可以自動找出一個，

0:20:12.404,0:20:12.904
它就可以自動找出一個，

0:20:12.904,0:20:13.404
它就可以自動找出一個，

0:20:13.404,0:20:13.904
可以偵測垃圾郵件的function。

0:20:13.904,0:20:14.404
可以偵測垃圾郵件的function。

0:20:14.404,0:20:14.904
可以偵測垃圾郵件的function。

0:20:14.904,0:20:15.404
可以偵測垃圾郵件的function。

0:20:15.404,0:20:15.904
可以偵測垃圾郵件的function。

0:20:15.904,0:20:16.404
可以偵測垃圾郵件的function。

0:20:16.404,0:20:17.620
那multi-class classification

0:20:17.620,0:20:18.120
那multi-class classification

0:20:18.120,0:20:18.620
那multi-class classification

0:20:18.620,0:20:19.378
這邊舉一個文章分類的例子。

0:20:19.378,0:20:19.878
這邊舉一個文章分類的例子。

0:20:19.878,0:20:20.378
這邊舉一個文章分類的例子。

0:20:20.378,0:20:20.878
這邊舉一個文章分類的例子。

0:20:20.878,0:20:21.378
現在網路上有非常多的新聞，

0:20:21.378,0:20:21.878
現在網路上有非常多的新聞，

0:20:21.878,0:20:22.378
現在網路上有非常多的新聞，

0:20:22.378,0:20:23.342
也許也有人能把所有的新聞看完。

0:20:23.342,0:20:23.842
也許也有人能把所有的新聞看完。

0:20:23.842,0:20:24.342
也許也有人能把所有的新聞看完。

0:20:24.342,0:20:25.965
也許也有人能把所有的新聞看完。

0:20:25.965,0:20:26.465
也許也有人能把所有的新聞看完。

0:20:26.465,0:20:27.735
那你希望機器自動幫你把新聞做分類，怎麼做呢?

0:20:27.735,0:20:30.255
那你希望機器自動幫你把新聞做分類，怎麼做呢?

0:20:30.255,0:20:33.215
你需要一個function，它的輸入是一則新聞，

0:20:33.215,0:20:36.265
輸出就是這一則新聞，屬於哪一個類別。

0:20:36.265,0:20:38.595
你可以想成每一個類別就是一個選項，

0:20:38.595,0:20:41.445
政治是一個選項，經濟是一個選項，體育是一個選項。

0:20:41.445,0:20:44.505
機器要做的事情就是，解這個選擇題。

0:20:44.645,0:20:47.515
你要訓練這種機器，你就告訴它說，

0:20:47.515,0:20:50.215
你就準備很多訓練資料，

0:20:50.215,0:20:53.085
告訴它說 : 這篇文章叫做體育，

0:20:53.085,0:20:55.975
這篇文章你要選政治，這篇文章你要選財經，

0:20:56.055,0:20:59.505
之後給它新的文章，希望它能給你正確的結果。

0:21:01.620,0:21:03.595
剛才講的，都是你要machine解的任務。

0:21:03.595,0:21:05.465
剛才講的，都是你要machine解的任務。

0:21:07.325,0:21:09.995
再來要講的，在解任務的過程中，

0:21:09.995,0:21:12.765
第一步就是要選一個function的set，那選不同的function set，

0:21:12.765,0:21:16.055
你會得到不同的結果。

0:21:16.175,0:21:19.295
選不同的function set就是選不同的model。

0:21:19.295,0:21:22.325
model很多種，舉例來說，non-linear的model上面。

0:21:22.325,0:21:25.395
最簡單的是linear的model。其中一個大家最耳熟的，

0:21:25.395,0:21:27.635
我們會花很多時間focus在non-linear的model上面。

0:21:27.635,0:21:30.595
那在non-linear的model裡面，

0:21:30.595,0:21:33.005
其中一個今日最耳熟能詳的，

0:21:33.005,0:21:36.275
就是deep learning。

0:21:36.735,0:21:39.545
所謂的deep learning的意思，

0:21:39.545,0:21:42.095
之後我們會再細講deep learning的內容，

0:21:42.095,0:21:45.045
今天只要知道說，在做deep learning的內容時候，

0:21:45.045,0:21:48.075
我們的function是特別複雜的。

0:21:48.315,0:21:49.345
所以它可以做特別複雜的事，舉例來說，

0:21:49.675,0:21:52.765
所以它可以做特別複雜的事，舉例來說，

0:21:52.765,0:21:55.635
它可以做影像的辨識，

0:21:55.635,0:21:57.635
這個特別複雜的function，

0:21:57.635,0:22:01.895
這個特別複雜的function，它可以描述這個peak zone

0:22:02.765,0:22:05.955
和它的class之間的關係。你要找這樣子的function，你就是準備一些訓練資料，

0:22:05.955,0:22:09.165
給機器去學就可以了。

0:22:09.165,0:22:11.165
用deep learning 的技術，你也可以讓機器，

0:22:11.165,0:22:11.960
學會下圍棋。

0:22:11.960,0:22:15.245
那在下一節的task，

0:22:15.245,0:22:18.275
下一節的task其實就是一個分類的問題。

0:22:18.275,0:22:21.415
只是這個分類的問題我們需要一個很複雜的function，

0:22:21.415,0:22:24.385
給它的輸入，是一個棋盤的盤式，

0:22:24.385,0:22:27.695
那輸出就是下一步應該落子的位置。

0:22:27.695,0:22:30.615
我們知道說，

0:22:30.615,0:22:33.475
一個棋盤上就是有19X19的位置是你可以落子的。

0:22:33.475,0:22:36.405
一個棋盤上就是有19X19的位置是你可以落子的。

0:22:36.405,0:22:39.415
所以今天下圍棋這件事情，

0:22:39.415,0:22:42.405
你就可以把它想成是一個19X19個類別的分類問題，

0:22:42.405,0:22:44.120
或者是，

0:22:44.120,0:22:45.475
你可以把它想成是一個，

0:22:45.475,0:22:48.775
有19X19個選項的選擇題。

0:22:48.905,0:22:50.295
有19X19個選項的選擇題。

0:22:50.935,0:22:51.640
那你要怎麼訓練機器

0:22:51.640,0:22:53.895
讓它學會下圍棋呢?

0:22:53.895,0:22:57.085
你要收集訓練資料，

0:22:57.085,0:22:57.980
告訴機器，

0:22:57.980,0:22:59.118
現在這個function的輸入輸出，

0:22:59.118,0:23:02.755
現在這個function的輸入輸出，分別應該是甚麼。

0:23:02.755,0:23:05.765
看到某樣的盤式，我們應該輸出甚麼樣的output。然後大家就非常的訝異；

0:23:05.765,0:23:07.415
看到某樣的盤式，我們應該輸出甚麼樣的output。

0:23:08.915,0:23:11.725
那怎麼收集這種資料呢?

0:23:11.725,0:23:12.340
你可以從人類過去下的棋譜裡面，

0:23:12.340,0:23:14.625
收集這樣子的資料。

0:23:14.625,0:23:17.025
舉例來說，你收集了進藤光和社清春下的那一盤棋譜

0:23:17.025,0:23:19.945
舉例來說，你收集了進藤光和社清春下的那一盤棋譜

0:23:19.945,0:23:22.845
在那一盤棋裡面，

0:23:22.845,0:23:25.525
首先首先社清春出手先下5之五，，

0:23:25.865,0:23:28.895
然後大家就非常的訝異；

0:23:28.895,0:23:32.105
然後進藤光次手再下天元，大家又更加訝異，

0:23:32.105,0:23:35.445
然後社清春第三首在下五之5，大家就非常非常的訝異。

0:23:36.405,0:23:39.505
所以你有了這樣子的棋譜後，你就告訴machine說，

0:23:39.505,0:23:42.625
如果現在棋盤上有人落子在5之五，

0:23:42.845,0:23:43.975
如果現在棋盤上有人落子在5之五，

0:23:44.535,0:23:47.445
那下一步你就落子在天元。

0:23:47.815,0:23:50.565
如果現在5之五和天元都已經有子了來

0:23:50.565,0:23:53.535
那你就落子在另外一個五之5的位置。

0:23:53.535,0:23:55.295
那你就落子在另外一個五之5的位置。

0:23:55.295,0:23:55.900
你給它夠多的棋譜，

0:23:55.900,0:23:58.255
它就可以學會怎麼下圍棋了。

0:24:00.755,0:24:01.480
除了deep learning以外，

0:24:03.765,0:24:06.965
還有很多其他的machine learning的model，

0:24:06.965,0:24:09.905
它也是non-linear的model。

0:24:09.905,0:24:12.280
這學期會請吳老師幫我們講SVM。

0:24:12.280,0:24:12.905
這學期會請吳老師幫我們講SVM。

0:24:12.905,0:24:15.915
這學期會請吳老師幫我們講SVM。

0:24:17.400,0:24:19.635
剛才我們講的都是supervised learning

0:24:19.635,0:24:22.645
supervised learning類的問題是，

0:24:22.645,0:24:23.340
我們需要大量的training data，

0:24:23.340,0:24:25.685
這些training data告訴我們說，

0:24:25.685,0:24:28.525
一個我們要找的function，

0:24:28.525,0:24:31.555
它的input和output之間有甚麼樣的關係。

0:24:31.555,0:24:34.325
它的input和output之間有甚麼樣的關係。

0:24:34.355,0:24:37.365
這個function的output，我們常叫做 label。

0:24:37.365,0:24:39.355
所以常常聽到說做機器學習需要大量的label，

0:24:39.355,0:24:42.275
指的就是說，如果我們用supervised的技術，

0:24:42.275,0:24:45.515
我們是要讓機器在supervised learning的情境中學習。

0:24:45.515,0:24:48.555
我們需要告訴機器，function的input和output是甚麼。

0:24:48.555,0:24:51.605
這個output往往沒辦法用很自然的方式取得，

0:24:51.605,0:24:52.300
這個output往往沒辦法用很自然的方式取得，

0:24:52.300,0:24:54.565
我們必須要憑著人工的力量，

0:24:54.695,0:24:57.635
把它雕塑出來。

0:24:57.635,0:25:00.615
這些function的output叫做label，

0:25:00.615,0:25:01.300
那你要找到這樣的label，

0:25:01.300,0:25:02.415
往往需要很大量的effort。

0:25:03.735,0:25:06.745
有沒有辦法減少label需要的量呢?

0:25:06.745,0:25:08.745
那是有辦法的!

0:25:08.745,0:25:09.875
舉例來說，有另外一個scenario，

0:25:09.875,0:25:12.835
舉例來說，有另外一個scenario，

0:25:12.835,0:25:15.945
叫做semi-supervised learning。

0:25:15.945,0:25:18.765
semi-supervised learning的意思是說，

0:25:18.765,0:25:21.805
舉例來說，你今天想要機器鑑別貓和狗的不同，

0:25:21.805,0:25:24.905
你想要做一個分類器，輸入一張圖片告訴你它是貓或狗

0:25:25.005,0:25:27.215
你有少量的貓和狗的labeled data，

0:25:27.705,0:25:30.605
你有少量的貓和狗的labeled data，

0:25:30.605,0:25:33.625
但是同時你又有大量的unlabeled data。

0:25:33.625,0:25:36.145
你有一大堆貓和狗的圖片，

0:25:36.145,0:25:39.315
但是你沒有力氣去告訴機器說那些是貓那些是狗。

0:25:39.315,0:25:42.575
在semi-supervised learning 的技術裡面，

0:25:42.605,0:25:45.075
這些沒有labeled的data，

0:25:45.745,0:25:48.725
它可能也是對學習有幫助。

0:25:48.725,0:25:51.705
我們之後會再講說，

0:25:51.705,0:25:54.945
為甚麼這些沒有labeled的data會對學習有幫助。

0:25:56.785,0:25:59.905
那另外一個減少data用量的方向是transfer learning，

0:25:59.905,0:26:02.615
那另外一個減少data用量的方向是transfer learning，

0:26:02.615,0:26:05.625
transfer learning的意思是說，假設我們一樣要做貓和狗的分類的問題，

0:26:05.625,0:26:08.675
我們也一樣只有少量的有labeled的data，

0:26:08.675,0:26:11.825
但是我們現在有另外大量的data，

0:26:11.825,0:26:14.615
這些大量的data它可能有labeled，也可能沒有labeled，

0:26:14.615,0:26:17.275
這些大量的data它可能有labeled，也可能沒有labeled，

0:26:17.275,0:26:20.045
但是它跟我們現在要討論的問題是沒有甚麼特別的關係的。

0:26:20.045,0:26:23.095
我們要分別的是貓和狗的不同，

0:26:23.095,0:26:26.115
但是你這邊有一大堆其他動畫的圖片，

0:26:26.115,0:26:28.325
這個是涼宮春日，

0:26:28.325,0:26:31.245
這個是御坂美晴

0:26:31.245,0:26:33.695
你有一大堆不相干的圖片，

0:26:34.265,0:26:37.135
它到底可以帶來甚麼樣的幫助?

0:26:37.135,0:26:38.775
這個就是transfer learning要講的問題。

0:26:42.605,0:26:45.685
更進階的是，unsupervised learning

0:26:45.805,0:26:46.620
在unsupervised learning裡面，

0:26:46.620,0:26:48.375
顧名思義，我們就是希望機器學到無師自通。

0:26:48.375,0:26:51.625
顧名思義，我們就是希望機器學到無師自通。

0:26:52.025,0:26:54.425
如果在完全沒有任何label的情況之下，

0:26:54.565,0:26:57.595
到底機器可以學到甚麼樣的知識?

0:26:57.805,0:27:00.795
舉例來說，如果我們給機器看大量的文章，

0:27:00.795,0:27:03.585
收集大量的文章很容易

0:27:07.075,0:27:09.785
這種機器看過大量的文章以後

0:27:10.355,0:27:13.485
它到底可以學到甚麼事情?

0:27:13.485,0:27:16.565
它能不能夠學會每個詞彙的意思?

0:27:17.705,0:27:20.745
要讓機器學會每個詞彙的意思，

0:27:20.745,0:27:23.685
你可以想成是我們要找一個function，

0:27:23.685,0:27:25.100
然後你把一個詞彙丟進去，

0:27:25.100,0:27:26.695
比如說你把Apple丟進這個function裡面

0:27:26.695,0:27:27.300
比如說你把Apple丟進這個function裡面

0:27:27.300,0:27:29.545
機器要輸出告訴你說，

0:27:29.545,0:27:32.485
這個詞彙是什麼意思。

0:27:32.485,0:27:35.095
也許它用一個向量來表示這個詞彙的，各種不同的特性

0:27:35.095,0:27:36.805
不同的attribute。

0:27:37.495,0:27:40.115
但是現在假如是一個unsupervised learning 的問題，

0:27:40.115,0:27:43.095
你現在只有一大堆的文章，

0:27:43.095,0:27:45.675
也就是你只有詞彙，你只有function的輸入，

0:27:45.675,0:27:46.380
沒有任何的輸出，

0:27:46.380,0:27:48.605
那到底要怎麼解這個問題?

0:27:48.605,0:27:49.605
那到底要怎麼解這個問題?

0:27:49.985,0:27:52.825
或者是我們舉另外一個unsupervised learning的例子，

0:27:53.025,0:27:55.955
假設我們今天帶機器去動物園，讓它看一大堆的動物，

0:27:55.955,0:27:57.585
它能不能在看了一大堆動物之後，

0:27:57.585,0:27:59.585
它能不能在看了一大堆動物之後，

0:27:59.585,0:28:00.575
它就學會自己創造一些動物。

0:28:00.575,0:28:03.435
這個都是真實的例子，

0:28:03.435,0:28:06.295
這是從Ian Goodfellow投影片上載下來的

0:28:06.295,0:28:09.085
仔細看了大量的動物以後，

0:28:09.085,0:28:11.085
它就可以自己畫一些狗出來。

0:28:11.085,0:28:14.160
像它畫的有，眼睛長在身上的狗

0:28:14.160,0:28:15.985
還有乳牛狗這樣子。

0:28:19.595,0:28:20.500
像這樣子的一個task，

0:28:20.500,0:28:22.265
它也是個unsupervised learning 的problem

0:28:22.265,0:28:24.265
它也是個unsupervised learning 的problem

0:28:24.265,0:28:25.565
你的function的輸入，

0:28:25.585,0:28:27.625
不知道是甚麼，

0:28:28.105,0:28:31.455
可能是某一個code，它代表了要輸出圖片的特性。

0:28:31.455,0:28:33.755
那輸出是一張圖片

0:28:34.175,0:28:37.125
你給機器看到的，只有非常大量的圖片

0:28:37.125,0:28:40.365
你只有function的output，沒有function的input

0:28:40.365,0:28:43.395
在這種情況下，機器怎麼學會自己生成新的圖片?

0:28:43.395,0:28:46.305
在這種情況下，機器怎麼學會自己生成新的圖片?

0:28:46.305,0:28:48.485
這個是我們之後會再cover的問題

0:28:50.085,0:28:52.755
接下來，

0:28:52.755,0:28:55.855
我們剛才講的是不同的 learning scenario

0:28:55.855,0:28:56.980
我們剛才講的是不同的 learning scenario

0:28:56.980,0:29:01.875
在machine 要解的任務上，

0:29:01.955,0:29:05.125
我們講了regression的problem，講了classification的problem

0:29:05.125,0:29:08.275
還有一類的問題是你比較少聽過的，

0:29:08.505,0:29:09.180
這類的問題叫做structured learning

0:29:09.180,0:29:11.335
這類的問題叫做structured learning

0:29:11.335,0:29:14.285
甚麼是structured learning呢?

0:29:14.285,0:29:17.435
在structured learning裡面，我們要機器輸出的是

0:29:17.435,0:29:20.535
一個有結構性的東西。

0:29:20.535,0:29:23.135
剛才在regression problem裡面機器輸出幾個數值；

0:29:24.105,0:29:26.735
在分類的問題裡面機器只是輸出一個選項，

0:29:26.815,0:29:29.355
它選一個選項；

0:29:29.545,0:29:32.525
在structured類的problem裡面，

0:29:32.525,0:29:35.255
機器要輸出的是一個複雜的物件。

0:29:35.745,0:29:38.595
舉例來說，在語音辨識裡面，

0:29:38.595,0:29:41.595
機器的輸入是一個聲音訊號，輸出的是一個句子

0:29:41.595,0:29:43.865
句子是由許多詞彙拼湊而成，

0:29:43.865,0:29:47.820
它是一個有結構性的object。

0:29:47.820,0:29:49.995
或者是說在機器翻譯裡面，你說一句話，

0:29:49.995,0:29:53.135
然後你輸入中文，你希望機器翻譯成英文，

0:29:53.135,0:29:55.755
那機器的輸出也是一個句子。

0:29:56.045,0:29:58.615
這也是有結構性的東西。

0:29:58.615,0:30:01.235
或者是說，你今天要做的是人臉辨識，

0:30:01.235,0:30:04.615
你給機器看一張圖片，

0:30:04.655,0:30:07.715
它會知道說，最左邊是長門，中間是涼宮春日，

0:30:07.715,0:30:11.205
最右邊這個，

0:30:11.405,0:30:14.785
這個是朝比奈實玖瑠。

0:30:17.345,0:30:20.345
它要把這些東西標出來，

0:30:20.345,0:30:23.335
這也是個structured learning 的problem

0:30:23.335,0:30:26.635
我知道多數人可能都聽過regression，

0:30:26.845,0:30:29.855
也聽過classification，

0:30:29.855,0:30:32.875
你可能不見得有聽過structured learning

0:30:32.875,0:30:35.965
這時候教授就會直接寫說

0:30:35.965,0:30:39.940
machine learning就是兩大類的問題 : regression的problem還有classification的problem

0:30:39.940,0:30:42.175
但是說machine learning 只有regression和classification problem

0:30:42.175,0:30:45.295
但是說machine learning 只有regression和classification problem

0:30:45.295,0:30:48.485
就好像是告訴你說，這個是我們熟知的世界

0:30:48.485,0:30:50.555
它有五大洲

0:30:51.105,0:30:54.115
事實上這個只是真實的世界一個小部分而已。

0:30:54.115,0:30:57.115
事實上這個只是真實的世界一個小部分而已。

0:30:57.115,0:30:58.575
真正的世界其實是這個樣子的。

0:30:59.155,0:31:00.155
這個是暗黑大陸

0:31:00.255,0:31:02.175
這個是暗黑大陸，

0:31:02.835,0:31:04.745
可是我們這輩子永遠也到不了的

0:31:05.205,0:31:08.215
structured learning就像是暗黑大陸一樣

0:31:08.715,0:31:11.835
這裏面還有很多很多問題是人類無法探究的

0:31:11.835,0:31:12.835
事實上最近有一個很潮的技術叫做GAN，

0:31:12.995,0:31:15.785
事實上最近有一個很潮的技術叫做GAN，

0:31:16.565,0:31:17.445
事實上最近有一個很潮的技術叫做GAN，

0:31:17.445,0:31:20.145
它念起來更像是 ㄍㄢ四聲

0:31:20.375,0:31:23.235
所以最近在路上常常會聽到有人在講ㄍㄢ四聲

0:31:23.235,0:31:24.945
他們其實是在討論這個技術

0:31:27.315,0:31:28.315
這個技術其實就是一個新的structured learning的方法

0:31:28.775,0:31:31.965
這個技術其實就是一個新的structured learning的方法

0:31:31.965,0:31:34.775
這個我們之後也會提到。

0:31:35.445,0:31:37.175
最後還有一個現在大家都耳熟能詳的

0:31:37.725,0:31:40.655
就是reinforcement learning的problem

0:31:40.655,0:31:41.695
就是reinforcement learning的problem

0:31:42.885,0:31:45.665
所謂reinforcement learning的意思是甚麼呢?

0:31:45.665,0:31:48.345
現在大家都或多或少知道，

0:31:48.345,0:31:51.235
至少知道它是一個很潮的東西。

0:31:51.705,0:31:52.975
至少知道它是一個很潮的東西。

0:31:53.935,0:31:56.975
這個reinforcement learning其實是一個發展很久的問題，

0:31:57.185,0:32:00.185
它絕對不是一個新的技術。

0:32:00.185,0:32:00.800
最近會比較受到重視，

0:32:01.195,0:32:02.195
一開始是因為DeepMind

0:32:02.315,0:32:04.305
一開始是因為DeepMind

0:32:04.625,0:32:07.055
拿reinforcement learning的技術去玩Akari的遊戲

0:32:07.055,0:32:10.105
拿reinforcement learning的技術去玩Akari的遊戲

0:32:10.105,0:32:13.355
在小遊戲上可以痛扁人類

0:32:13.395,0:32:16.625
他們現在很厲害會把paper發到Nature上去

0:32:16.625,0:32:17.625
他們現在很厲害會把paper發到Nature上去

0:32:17.655,0:32:19.585
另外第二個大家都知道的例子，

0:32:19.965,0:32:22.655
就是AlphaGo

0:32:22.655,0:32:24.425
我們都知道AlphaGo裡面有用到reinforcement learning的技術

0:32:24.825,0:32:28.065
那reinforcement learning的技術是甚麼呢?

0:32:28.065,0:32:30.725
我們把它跟supervised learning 的技術比較起來是這個樣子

0:32:31.155,0:32:34.105
在supervised learning的技術裡面，

0:32:34.105,0:32:36.285
我們會告訴機器正確答案是甚麼。

0:32:36.865,0:32:38.440
舉例來說，

0:32:38.440,0:32:39.105
假設你要使用supervised的方法來訓練一個聊天機器人

0:32:39.105,0:32:39.615
假設你要使用supervised的方法來訓練一個聊天機器人

0:32:39.615,0:32:42.675
假設你要使用supervised的方法來訓練一個聊天機器人

0:32:42.675,0:32:45.525
那你的訓練方式是這樣，你給機器的data是這樣:

0:32:45.525,0:32:48.255
你就告訴機器說，現在使用者說hello

0:32:48.255,0:32:51.515
你就說hi；現在使用者說bye bye

0:32:51.525,0:32:54.665
你就說 good bye

0:32:54.825,0:32:57.825
所以機器有一個家教在它的旁邊手把手的教它每件事情

0:32:57.825,0:33:00.945
這個是supervised learning

0:33:00.945,0:33:03.955
那reinforcement learning是甚麼呢?

0:33:03.955,0:33:06.945
在reinforcement learning裡面，我們沒有告訴機器正確的答案是甚麼，

0:33:07.085,0:33:10.355
機器所擁有的只有一個分數，

0:33:10.615,0:33:13.565
就是它做的好還是不好。

0:33:13.995,0:33:16.885
舉例來說，

0:33:16.885,0:33:20.025
我們現在要用reinforcement learning的方法來訓練一個聊天機器人的話，

0:33:20.025,0:33:22.805
那它訓練的方法會像是這樣:

0:33:22.805,0:33:23.305
你就把機器放在線上，

0:33:23.305,0:33:24.645
你就把機器放在線上，

0:33:26.245,0:33:29.165
讓它跟隨便進來的客人對話

0:33:29.415,0:33:30.415
講了半天後，

0:33:30.675,0:33:32.865
最後人就勃然大怒，就把電話掛掉了

0:33:33.395,0:33:36.695
機器就學到一件事情: 剛才做錯了

0:33:36.695,0:33:37.805
它不知道哪邊做錯了

0:33:38.125,0:33:41.245
它不知道哪邊做錯了

0:33:41.285,0:33:44.225
它必須自己回去想一下說到底如何改進

0:33:44.225,0:33:46.095
所以一開始就不應該打招呼嗎?還是中間不應該罵髒話呢?

0:33:46.745,0:33:47.745
它不知道，沒有人告訴這件事

0:33:48.045,0:33:49.045
它不知道，沒有人告訴這件事

0:33:49.485,0:33:52.235
它只知道自己做的不好，它要回去反省檢討看看到底是哪一步做的不好

0:33:52.935,0:33:56.365
所以機器要在reinforcement learning的情況下學習，

0:33:56.365,0:33:57.805
它是需要比較強的intelligence。

0:33:58.225,0:33:59.795
它是需要比較強的intelligence。

0:34:00.575,0:34:03.435
所以supervised learning 就是learning from teacher

0:34:03.435,0:34:06.485
機器有老師，老師會告訴它每個問題的答案

0:34:06.485,0:34:09.905
機器有老師，老師會告訴它每個問題的答案

0:34:09.905,0:34:12.855
那reinforcement learning是learning from critics

0:34:12.855,0:34:14.855
它是從評價中去學習的

0:34:14.855,0:34:15.855
它是從評價中去學習的

0:34:15.855,0:34:18.395
它只知道自己做的好或不好，

0:34:18.765,0:34:19.755
但它不知道自己哪裡做得好，

0:34:19.755,0:34:22.465
它不知道哪裡做得不好，它也沒有正確的答案

0:34:22.985,0:34:26.075
reinforcement learning會這麼受到重視就是

0:34:26.075,0:34:28.605
它比較符合我們人類真正學習的情境

0:34:28.605,0:34:31.645
它比較符合我們人類真正學習的情境

0:34:31.645,0:34:34.755
這是你在學校裡面的學習，老師告訴你一個問題的答案；

0:34:35.015,0:34:37.015
這是在真實社會中的學習，你沒有一個正確的答案，

0:34:37.015,0:34:37.915
你只有知道，你做的好還是做得不好

0:34:38.155,0:34:41.175
如果機器可以做到reinforcement learning，

0:34:41.175,0:34:43.995
那它確實是比較intelligent。

0:34:44.445,0:34:47.475
又或者我們用AlphaGo來當做例子

0:34:47.475,0:34:50.355
下圍棋來當作例子，

0:34:50.355,0:34:51.000
supervised learning就是告訴機器說，

0:34:51.615,0:34:54.405
看到這個盤勢你就下5-5，看到這個盤勢你就下3-3

0:34:54.795,0:34:57.835
reinforcement learning就是會跟對手互下

0:34:57.885,0:35:00.755
reinforcement learning就是會跟對手互下

0:35:00.755,0:35:03.695
下了好幾百手後，最後贏了

0:35:03.695,0:35:06.565
還知道說這一局棋下的不錯

0:35:06.565,0:35:07.565
但到底哪一步是關鍵的位置讓它可以贏?

0:35:07.875,0:35:08.875
但到底哪一步是關鍵的位置讓它可以贏?

0:35:10.445,0:35:11.445
它其實不知道，

0:35:12.095,0:35:14.985
它只知道贏了，或者是輸了

0:35:14.985,0:35:15.925
我們知道說AlphaGo其實是用supervised learning

0:35:15.925,0:35:18.925
我們知道說AlphaGo其實是用supervised learning

0:35:18.925,0:35:22.085
加上reinforcement learning的方法去學的

0:35:22.085,0:35:24.905
機器先從棋譜，棋譜就是它的老師，

0:35:24.905,0:35:27.845
有棋譜就可以做supervised 的學習

0:35:27.845,0:35:30.695
但棋譜沒有很多，所以從棋譜做了supervised 的學習以後

0:35:30.695,0:35:33.915
接下來它會做reinforcement learning

0:35:33.915,0:35:36.845
讓它學得更好

0:35:36.845,0:35:40.005
但是reinforcement learning需要一個對手

0:35:40.005,0:35:42.925
你說讓人來當對手太慢了，人又沒有辦法跟機器下很多盤棋

0:35:42.925,0:35:46.095
所以機器的對手是另外一個機器

0:35:46.095,0:35:49.325
大家都知道說AlphaGo就是自己跟自己下棋，

0:35:49.325,0:35:50.325
然後不斷的進步

0:35:50.375,0:35:53.035
指的就是在reinforcement learning的這個步驟，

0:35:53.035,0:35:53.800
機器不是跟人下棋，

0:35:53.800,0:35:55.785
它的對手是另外一個機器。

0:35:55.785,0:35:57.255
它的對手是另外一個機器。

0:35:59.865,0:36:00.865
最後在這個圖上

0:36:01.125,0:36:02.125
最後在這個圖上

0:36:02.345,0:36:05.325
大家注意一下不同的方塊，

0:36:05.365,0:36:08.225
我是用不同的顏色來表示。

0:36:09.225,0:36:12.495
同樣的顏色代表今天這個不同的方塊

0:36:12.645,0:36:16.105
指的是同一個類型的事情。

0:36:16.145,0:36:17.845
這邊的藍色方塊指的是scenario

0:36:18.365,0:36:21.395
這邊的藍色方塊指的是scenario

0:36:21.395,0:36:24.285
指的是學習的情境

0:36:24.285,0:36:27.445
通常學習的情境是你自己沒有辦法控制的

0:36:27.695,0:36:30.775
舉例來說，為甚麼我們要用reinforcement learning

0:36:30.775,0:36:33.445
就是我們沒有data做supervised learning

0:36:33.445,0:36:35.945
所以我們才做reinforcement learning

0:36:35.945,0:36:39.035
我知道reinforcement learning聽起來很潮，因為它用在AlphaGO裡面

0:36:39.035,0:36:42.055
所以現在甚麼樣的task你有用到reinforcement learning

0:36:42.055,0:36:45.235
你就可以到處亂講說:

0:36:45.235,0:36:48.385
"這個AlphaGo is chip；AlphaGo is dialogue"

0:36:48.645,0:36:51.785
其實就是用了reinforcement learning的技術就說AlphaGo is 甚麼東西

0:36:54.725,0:36:57.705
所以就會變成好像要用reinforcement learning比較潮

0:36:57.705,0:37:00.735
所以之前比如說有學生去面試，那個公司就問，

0:37:00.735,0:37:03.720
人家問他說你做甚麼，他說我做的是一個supervised learning 的task

0:37:03.720,0:37:06.955
人家說: "你怎麼不做reinforcement learning呢?reinforcement learning就是比較厲害啊"

0:37:07.285,0:37:08.895
這個時候你就應該要嗆爆他說:

0:37:09.365,0:37:11.625
如果我今天可以做supervised learning的task，

0:37:11.935,0:37:15.025
我其實就不應該做reinforcement learning的task

0:37:15.025,0:37:18.395
reinforcement learning是

0:37:18.465,0:37:21.135
我們沒有辦法做supervised learning 的task的時候，

0:37:21.135,0:37:22.995
我們才做reinforcement learning。

0:37:23.875,0:37:26.005
不過你面試若這樣講，你大概就不會被錄取就是了

0:37:27.875,0:37:31.085
所以這些是不同的scenario

0:37:31.085,0:37:32.245
不同的scenario通常不是你自己可以控制的

0:37:32.655,0:37:33.655
看你手上有什麼樣的data，

0:37:34.235,0:37:36.385
決定你有甚麼樣的scenario。

0:37:37.825,0:37:39.515
那紅色的呢?

0:37:39.515,0:37:42.575
紅色的是指你的task，

0:37:42.595,0:37:43.665
你要解的問題

0:37:44.015,0:37:45.285
那你要解的這個問題，

0:37:45.745,0:37:47.285
隨著你要找的function的output不同

0:37:48.005,0:37:51.045
有regression，有classification，有structured learning

0:37:51.045,0:37:52.845
structured learning你就想成不是regression，不是classification的問題就是structured learning，

0:37:53.155,0:37:56.605
structured learning你就想成不是regression，不是classification的問題就是structured learning，

0:37:56.605,0:37:57.795
簡單這樣想就好了!

0:37:58.125,0:38:01.175
所以今天在不同的情境下，

0:38:01.175,0:38:04.365
你都可能要解這個task，

0:38:04.385,0:38:07.715
解這個task

0:38:07.715,0:38:08.935
如果今天在supervised類的情況下你有這些task，

0:38:09.325,0:38:10.735
但是在semi-supervised learning, transfer learning, unsupervised learning和reinforcement learning的情況下

0:38:11.125,0:38:14.155
但是在semi-supervised learning, transfer learning, unsupervised learning和reinforcement learning的情況下。

0:38:14.155,0:38:17.535
你也都需要去解這些的task

0:38:20.125,0:38:21.125
最後在這些task裡面都有不同的model

0:38:21.655,0:38:22.785
最後在這些task裡面都有不同的model

0:38:23.275,0:38:24.800
或者是不同的方法。

0:38:25.285,0:38:27.585
這邊用綠色的方塊表示

0:38:28.845,0:38:31.415
他這邊的意思是說，同樣的task，

0:38:31.985,0:38:35.085
我們用不同的方法來解它。

0:38:35.085,0:38:38.355
所以今天supervised learning它畫得比較大塊，

0:38:39.105,0:38:40.805
這個裡面的東西在這四個task裡面也都有出現

0:38:41.525,0:38:44.075
這個裡面的東西在這四個task裡面也都有出現，

0:38:44.585,0:38:46.335
classification畫得比較大塊，它裡面綠色的這些box，在這些紅色的box裡面都有出現。

0:38:46.825,0:38:50.235
classification畫得比較大塊，它裡面綠色的這些box，在這些紅色的box裡面都有出現。

0:38:50.235,0:38:53.465
希望大家可以了解這些machine learning不同的技術，

0:38:53.685,0:38:54.685
他們之間的關聯性。

0:38:54.685,0:38:56.685
臺灣大學人工智慧中心
科技部人工智慧技術暨全幅健康照護聯合研究中心
http://aintu.tw
