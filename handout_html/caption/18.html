<head><meta http-equiv='Content-Type' content='text/html; charset=utf-8'></head>
﻿0:00:00.000,0:00:02.000<br>
臺灣大學人工智慧中心<br>
科技部人工智慧技術暨全幅健康照護聯合研究中心<br>
http://aintu.tw<br>
<br>
0:00:02.000,0:00:02.700<br>
supervised learning 的話呢，有哪些 suggestion<br>
<br>
0:00:02.700,0:00:04.480<br>
所以，就算我們上課還沒有講到<br>
<br>
0:00:04.480,0:00:07.140<br>
也沒有關係，我相信對大家來說<br>
<br>
0:00:07.140,0:00:08.460<br>
應該不是一個問題<br>
<br>
0:00:08.460,0:00:10.320<br>
我們今天唯一需要做的就是<br>
<br>
0:00:10.320,0:00:13.280<br>
講完 CNN 的部分<br>
<br>
0:00:15.400,0:00:19.860<br>
我們都知道說，CNN 它常常被用在<br>
<br>
0:00:19.860,0:00:21.840<br>
影像處理上<br>
<br>
0:00:21.840,0:00:25.380<br>
如果你今天用 CNN 來做影像處理<br>
<br>
0:00:25.380,0:00:26.940<br>
比如說，你用 CNN 來<br>
<br>
0:00:26.940,0:00:29.000<br>
我當然可以用<br>
<br>
0:00:29.000,0:00:30.500<br>
一般的 neural network<br>
<br>
0:00:30.500,0:00:33.580<br>
來做影像處理，不一定要用 CNN<br>
<br>
0:00:33.580,0:00:36.060<br>
比如說，你想要做影像的分類<br>
<br>
0:00:36.060,0:00:37.660<br>
那你就是 train 一個 neural network<br>
<br>
0:00:37.660,0:00:40.120<br>
input 是一張圖片<br>
<br>
0:00:40.120,0:00:44.100<br>
那這張圖片你就把它表示成裡面的 pixel<br>
<br>
0:00:44.100,0:00:46.280<br>
也就是一個很長很長的 vector<br>
<br>
0:00:46.280,0:00:49.020<br>
那 output 就是看你，假設你有 1000 個類別<br>
<br>
0:00:49.020,0:00:51.060<br>
output 就是 1000 個 dimension<br>
<br>
0:00:51.060,0:00:54.200<br>
那我相信，根據剛才那堂課的內容，大家<br>
<br>
0:00:54.200,0:00:57.480<br>
應該都可以給你 training data，大概就可以秒做出來<br>
<br>
0:00:58.000,0:00:59.320<br>
但是<br>
<br>
0:00:59.320,0:01:02.760<br>
我們現在會遇到的問題是這樣子<br>
<br>
0:01:04.520,0:01:08.680<br>
實際上，如果我們 train neural network 的時候<br>
<br>
0:01:08.680,0:01:13.520<br>
我們會期待說，在這個 network 的 structure 裡面<br>
<br>
0:01:13.520,0:01:18.060<br>
每一個 neuron，其實就代表了一個最基本的 classifier<br>
<br>
0:01:18.060,0:01:19.820<br>
事實上，在文獻上呢<br>
<br>
0:01:19.820,0:01:22.800<br>
根據訓練的結果，也有很多人得到這樣的結論<br>
<br>
0:01:22.800,0:01:25.500<br>
舉例來說，第一層的 classifier<br>
<br>
0:01:25.500,0:01:26.920<br>
第一層的 neuron<br>
<br>
0:01:26.920,0:01:28.580<br>
它是最簡單的 classifier<br>
<br>
0:01:28.580,0:01:31.100<br>
它做的事情就是 detect 有沒有綠色出現<br>
<br>
0:01:31.100,0:01:34.100<br>
有沒有黃色出現，有沒有斜的條紋<br>
<br>
0:01:34.100,0:01:36.720<br>
那第二個 layer，它做的事情是<br>
<br>
0:01:36.720,0:01:38.100<br>
detect 更複雜的東西<br>
<br>
0:01:38.100,0:01:39.760<br>
根據第一個 layer 的 output<br>
<br>
0:01:39.760,0:01:41.740<br>
它如果看到直線橫線<br>
<br>
0:01:41.740,0:01:43.420<br>
就是窗框的一部分<br>
<br>
0:01:43.420,0:01:45.900<br>
如果看到棕色的直條紋就是木紋<br>
<br>
0:01:45.900,0:01:49.020<br>
看到斜條紋加灰色的<br>
<br>
0:01:49.020,0:01:52.620<br>
這個有可能是很多東西，比如說，輪胎的一部分等等<br>
<br>
0:01:53.100,0:01:56.600<br>
再根據第二個 hidden layer 的 output<br>
<br>
0:01:56.600,0:01:58.860<br>
第三個 hidden layer 會做更複雜的事情<br>
<br>
0:01:58.860,0:02:00.800<br>
比如說，它可以知道說<br>
<br>
0:02:00.800,0:02:03.260<br>
某一個 neuron 看到蜂巢，它就被 activate<br>
<br>
0:02:03.260,0:02:05.140<br>
某一個 neuron 看到車子，就被 activate<br>
<br>
0:02:05.140,0:02:07.500<br>
某一個 neuron 看到人的上半身<br>
<br>
0:02:07.500,0:02:08.680<br>
就被 activate<br>
<br>
0:02:08.680,0:02:10.920<br>
那現在的問題是這樣子<br>
<br>
0:02:10.920,0:02:13.180<br>
當我們直接用一般的<br>
<br>
0:02:13.180,0:02:15.860<br>
fully connected 的 feedforward network 來做影像處理<br>
<br>
0:02:15.860,0:02:18.620<br>
的時候，往往我們會需要太多的參數<br>
<br>
0:02:18.620,0:02:19.740<br>
舉例來說<br>
<br>
0:02:19.740,0:02:23.280<br>
假設這是一張 100*100 的彩色圖片<br>
<br>
0:02:23.280,0:02:26.460<br>
它解析度才 100*100，那這已經是很小張的 image 了<br>
<br>
0:02:26.460,0:02:28.520<br>
那你把它拉成一個 vector<br>
<br>
0:02:28.520,0:02:30.440<br>
它有多少的 pixel<br>
<br>
0:02:30.440,0:02:32.280<br>
它有 100*100*3<br>
<br>
0:02:32.280,0:02:34.120<br>
對不對，每個 pixel 其實需要<br>
<br>
0:02:34.120,0:02:37.180<br>
3 個 value 來描述它，如果是彩色的圖的話<br>
<br>
0:02:37.180,0:02:42.780<br>
是三萬維，那 input vector 如果是三萬維<br>
<br>
0:02:42.780,0:02:47.040<br>
這個 hidden layer 假設 1000 個 neuron 就好了<br>
<br>
0:02:47.040,0:02:49.700<br>
你的這個第一層 hidden layer 的參數<br>
<br>
0:02:49.700,0:02:51.600<br>
就已經有 30000*1000 了<br>
<br>
0:02:51.600,0:02:53.980<br>
這樣太多了<br>
<br>
0:02:53.980,0:02:57.640<br>
所以，CNN 它做的事情其實是<br>
<br>
0:02:57.640,0:03:01.740<br>
我們來簡化這個 neural network 的架構<br>
<br>
0:03:01.740,0:03:05.360<br>
我們把這裡面一些，根據人的知識<br>
<br>
0:03:05.360,0:03:08.020<br>
我們根據我們對影像處理的理解，就知道說<br>
<br>
0:03:08.020,0:03:10.800<br>
某些 weight 其實是用不上的，我們一開始<br>
<br>
0:03:10.800,0:03:12.380<br>
就把它濾掉<br>
<br>
0:03:12.380,0:03:15.980<br>
我們一開始就想一些辦法，<br>
不要用 fully connected network<br>
<br>
0:03:15.980,0:03:17.580<br>
而是用比較少的參數<br>
<br>
0:03:17.580,0:03:19.940<br>
來做影像處理這件事情<br>
<br>
0:03:19.940,0:03:22.960<br>
所以，CNN 其實是比一般的 DNN<br>
<br>
0:03:22.960,0:03:25.200<br>
還要更簡單的<br>
<br>
0:03:25.200,0:03:27.780<br>
等一下，我們講完以後你就會發現說<br>
<br>
0:03:27.780,0:03:29.480<br>
你可能覺得說，CNN 看起來<br>
<br>
0:03:29.480,0:03:31.100<br>
它的運作很複雜<br>
<br>
0:03:31.100,0:03:32.900<br>
它應該是個比較複雜的東西<br>
<br>
0:03:32.900,0:03:35.060<br>
但事實上，它的模型呢<br>
<br>
0:03:35.060,0:03:38.320<br>
是比 DNN 還要更簡單的<br>
<br>
0:03:38.320,0:03:40.220<br>
我們就是用 prior knowledge<br>
<br>
0:03:40.220,0:03:43.540<br>
去把原來 fully connected 的 layer 裡面的一些參數拿掉<br>
<br>
0:03:43.540,0:03:45.100<br>
就變成 CNN<br>
<br>
0:03:46.120,0:03:48.980<br>
我們先講一下，為甚麼<br>
<br>
0:03:48.980,0:03:52.220<br>
我們有可能把一些參數拿掉<br>
<br>
0:03:52.220,0:03:54.840<br>
為甚麼我們有可能只用比較少的參數<br>
<br>
0:03:54.840,0:03:56.860<br>
就來做影像處理這件事情<br>
<br>
0:03:56.860,0:04:00.020<br>
那這邊有幾個觀察，第一個是<br>
<br>
0:04:00.460,0:04:02.000<br>
在影像處理裡面<br>
<br>
0:04:02.000,0:04:04.900<br>
如果我們說，第一層的 hidden layer<br>
<br>
0:04:04.900,0:04:08.460<br>
那些 neuron 要做的事情就是偵測某一種 pattern<br>
<br>
0:04:08.460,0:04:11.040<br>
有沒有某一種東西，有沒有某一種 pattern 出現<br>
<br>
0:04:11.040,0:04:15.140<br>
那大部分的 pattern 其實是比整張 image 還要小<br>
<br>
0:04:15.140,0:04:16.820<br>
所以，對一個 neuron 來說<br>
<br>
0:04:16.820,0:04:19.460<br>
假設它要知道說，一張 image 裡面<br>
<br>
0:04:19.460,0:04:21.320<br>
有沒有某一個 pattern 出現<br>
<br>
0:04:21.320,0:04:23.700<br>
它其實不需要看整張 image<br>
<br>
0:04:23.700,0:04:25.420<br>
它只要看 image 的一小部分<br>
<br>
0:04:25.420,0:04:27.640<br>
它就可以決定這件事情了<br>
<br>
0:04:27.640,0:04:28.960<br>
舉例來說<br>
<br>
0:04:28.960,0:04:32.060<br>
假設我們現在，有一張圖片<br>
<br>
0:04:32.060,0:04:34.760<br>
那第一個 hidden layer 的某一個 neuron<br>
<br>
0:04:34.760,0:04:35.960<br>
它的工作是<br>
<br>
0:04:35.960,0:04:38.920<br>
要偵測有沒有鳥嘴的存在<br>
<br>
0:04:38.920,0:04:40.500<br>
那你可能<br>
<br>
0:04:40.500,0:04:42.260<br>
有一些 neuron 偵測有沒有鳥嘴的存在<br>
<br>
0:04:42.260,0:04:43.960<br>
有一些 neuron 偵測有沒有爪子的存在<br>
<br>
0:04:43.960,0:04:46.360<br>
有一些 neuron 偵測有沒有翅膀的存在<br>
<br>
0:04:46.360,0:04:48.060<br>
有沒有尾巴的存在，之後合起來<br>
<br>
0:04:48.060,0:04:50.240<br>
就可以偵測，圖片中有沒有一隻鳥<br>
<br>
0:04:50.240,0:04:52.620<br>
假設有某一個 neuron 它的工作是<br>
<br>
0:04:52.620,0:04:55.180<br>
要偵測有沒有鳥嘴的存在<br>
<br>
0:04:55.180,0:04:57.620<br>
那它其實並不需要看整張圖<br>
<br>
0:04:57.620,0:04:59.640<br>
因為，其實我們只要給<br>
<br>
0:04:59.640,0:05:02.080<br>
neuron 看這樣一個小的部分<br>
<br>
0:05:02.080,0:05:04.280<br>
這個小的紅色框框裡面的區域<br>
<br>
0:05:04.280,0:05:06.300<br>
它其實就可以知道說<br>
<br>
0:05:06.300,0:05:08.180<br>
它是不是一個鳥嘴<br>
<br>
0:05:08.180,0:05:10.800<br>
對人來說也是一樣，只要看這個小的區域你就會知道說<br>
<br>
0:05:10.800,0:05:14.920<br>
這是鳥嘴，不需要看整張圖才知道這件事情<br>
<br>
0:05:15.340,0:05:18.260<br>
所以，每一個 neuron 其實只要連接到<br>
<br>
0:05:18.260,0:05:21.320<br>
一個小塊的區域就好，它不需要連接到<br>
<br>
0:05:21.320,0:05:22.840<br>
整張完整的圖<br>
<br>
0:05:24.280,0:05:26.220<br>
那第二個觀察是這樣子<br>
<br>
0:05:26.740,0:05:29.560<br>
同樣的這個 pattern<br>
<br>
0:05:29.560,0:05:32.380<br>
在 image 裡面，它可能會出現在<br>
<br>
0:05:32.380,0:05:35.080<br>
image 的不同的部分<br>
<br>
0:05:35.080,0:05:38.120<br>
它會出現在 image 的不同的部分<br>
<br>
0:05:38.120,0:05:41.860<br>
但是，它們代表的是同樣的含意，它們也有同樣的形狀<br>
<br>
0:05:41.860,0:05:44.940<br>
它們可以用同樣的 neuron<br>
<br>
0:05:44.940,0:05:47.560<br>
同樣的參數，然後，detector 就可以偵測出來<br>
<br>
0:05:47.560,0:05:51.060<br>
比如說，在這張圖裡面，有一個在左上角的鳥嘴<br>
<br>
0:05:51.060,0:05:53.660<br>
那這張圖裡面，有一個在<br>
<br>
0:05:53.660,0:05:55.220<br>
中央的鳥嘴<br>
<br>
0:05:55.220,0:05:59.340<br>
但是，你並不需要說，我去訓練兩個不同的 detector<br>
<br>
0:05:59.340,0:06:01.500<br>
一個是專門偵測左上角有沒有鳥嘴<br>
<br>
0:06:01.560,0:06:03.940<br>
一個是偵測中央有沒有鳥嘴<br>
<br>
0:06:03.940,0:06:05.540<br>
如果這樣做的話呢，它就<br>
<br>
0:06:05.540,0:06:09.280<br>
太冗了，所以，我們要 cost down<br>
<br>
0:06:09.280,0:06:13.480<br>
所以，它不需要太多的冗員，因為這個<br>
<br>
0:06:13.480,0:06:16.080<br>
這個 neuron，偵測左上角鳥嘴的 neuron<br>
<br>
0:06:16.080,0:06:18.600<br>
跟中央的偵測有沒有鳥嘴的 neuron，他們<br>
<br>
0:06:18.600,0:06:21.420<br>
做的事情，其實可能就是一樣的<br>
<br>
0:06:21.420,0:06:23.760<br>
所以，我們並不需要有兩個 neuron<br>
<br>
0:06:23.760,0:06:26.380<br>
兩組參數，來做<br>
<br>
0:06:26.380,0:06:29.700<br>
duplicate 的事情，所以，我們可以<br>
<br>
0:06:29.700,0:06:34.060<br>
要求這兩個 neuron，他們就用同一組參數<br>
<br>
0:06:34.060,0:06:37.260<br>
它們就 share 它們的參數，它們就共用同一組參數<br>
<br>
0:06:37.260,0:06:41.040<br>
這樣你就可以減少，你需要的參數的量<br>
<br>
0:06:41.640,0:06:44.700<br>
那第三個，是我們知道一個 image<br>
<br>
0:06:44.700,0:06:47.200<br>
你可以對它做 subsampling<br>
<br>
0:06:47.200,0:06:50.020<br>
你把一張 image 的奇數行<br>
<br>
0:06:50.020,0:06:51.600<br>
偶數列的 pixel 拿掉<br>
<br>
0:06:51.600,0:06:54.500<br>
變成原來的 1/10 的大小<br>
<br>
0:06:54.500,0:06:57.720<br>
它其實部會影響人對這張 image 的理解<br>
<br>
0:06:57.720,0:07:00.600<br>
對你來說，這張 image 跟這張 image<br>
<br>
0:07:00.600,0:07:02.340<br>
看起來可能沒有太大差別<br>
<br>
0:07:02.340,0:07:04.480<br>
你都可以辨識裡面有甚麼物件<br>
<br>
0:07:04.480,0:07:06.900<br>
所以，做 subsampling 這件事情<br>
<br>
0:07:06.900,0:07:11.220<br>
對影像辨識來說，能是沒有太大的影響的<br>
<br>
0:07:11.220,0:07:16.600<br>
所以，我們可以用這個概念把 image 變小<br>
<br>
0:07:16.600,0:07:19.480<br>
這樣，你就可以減少你需要用的參數<br>
<br>
0:07:19.480,0:07:22.180<br>
所以，整個 CNN 的架構是這樣<br>
<br>
0:07:22.180,0:07:24.560<br>
等一下，我們會一個一個解釋<br>
<br>
0:07:24.560,0:07:26.420<br>
在 CNN 的整個架構裡面<br>
<br>
0:07:26.420,0:07:29.460<br>
每一個 block 它做的事情是什麼<br>
<br>
0:07:32.080,0:07:34.660<br>
首先，input 一張 image 以後呢<br>
<br>
0:07:34.660,0:07:36.360<br>
首先，這個 image 會通過<br>
<br>
0:07:36.360,0:07:38.320<br>
convolution 的 layer<br>
<br>
0:07:38.320,0:07:41.820<br>
然後，接下來，做 Max pooling 這件事<br>
<br>
0:07:41.820,0:07:43.820<br>
那這每一件事，我們等一下都會解釋<br>
<br>
0:07:43.820,0:07:45.820<br>
然後，再做 convolution 這件事<br>
<br>
0:07:45.820,0:07:48.240<br>
然後，再做 Max Pooling 這件事<br>
<br>
0:07:48.240,0:07:51.340<br>
那這個 process 可以反覆數次<br>
<br>
0:07:51.340,0:07:53.800<br>
那反覆的次數，你覺得夠多以後呢<br>
<br>
0:07:53.800,0:07:56.200<br>
但反覆幾次這個你要事先決定<br>
<br>
0:07:56.200,0:07:59.060<br>
它就是 network 的架構，就好像 network 有幾層一樣<br>
<br>
0:07:59.060,0:08:01.660<br>
你要做幾次 convolution，做幾次 Max Pooling<br>
<br>
0:08:01.660,0:08:04.460<br>
你在定你那個 network的架構時，就要事先決定好<br>
<br>
0:08:05.240,0:08:06.920<br>
那你做完<br>
<br>
0:08:06.920,0:08:09.240<br>
你做完你決定要做的 convolution 和<br>
<br>
0:08:09.240,0:08:11.480<br>
Max Pooling 的次數以後，那你會做另外一件事情<br>
<br>
0:08:11.480,0:08:13.140<br>
你要做一件事情叫 Flatten<br>
<br>
0:08:13.140,0:08:15.560<br>
那做完 Flatten 以後，你把 Flatten output<br>
<br>
0:08:15.560,0:08:18.720<br>
丟到一般的 fully connected 的 network 裡面去<br>
<br>
0:08:18.720,0:08:22.180<br>
然後，得到最後影像辨識的結果<br>
<br>
0:08:22.720,0:08:24.180<br>
那我們剛才講說<br>
<br>
0:08:24.180,0:08:26.660<br>
這個我們基於<br>
<br>
0:08:26.660,0:08:29.200<br>
3 個對影像處理的觀察<br>
<br>
0:08:29.200,0:08:31.360<br>
所以，設計了 CNN 這樣的架構<br>
<br>
0:08:31.360,0:08:33.060<br>
那第一個觀察是<br>
<br>
0:08:33.060,0:08:34.060<br>
同樣的 pattern<br>
<br>
0:08:34.060,0:08:36.700<br>
要偵測一個 pattern，你不需要看整張 image<br>
<br>
0:08:36.700,0:08:38.700<br>
你只要看 image 的一個小部分<br>
<br>
0:08:38.700,0:08:40.580<br>
第二個是，同一個 pattern 它<br>
<br>
0:08:40.580,0:08:43.480<br>
不出現在一張圖片的不同的區域<br>
<br>
0:08:43.480,0:08:45.600<br>
第三個是，我們可以做 subset<br>
<br>
0:08:45.600,0:08:47.600<br>
前面這兩個 property 呢<br>
<br>
0:08:47.600,0:08:49.720<br>
它就是用 convolution 的 layer<br>
<br>
0:08:49.720,0:08:50.760<br>
來處理掉<br>
<br>
0:08:50.760,0:08:52.320<br>
最後這個 property<br>
<br>
0:08:52.320,0:08:55.480<br>
是用 Max Pooling<br>
<br>
0:08:55.480,0:08:58.640<br>
來處理，那等一下，我們就要介紹一下<br>
<br>
0:08:58.640,0:09:01.820<br>
每一個 layer 在做的事情<br>
<br>
0:09:01.820,0:09:05.700<br>
那我們就先從 convolution 開始看起<br>
<br>
0:09:07.440,0:09:09.320<br>
假設現在<br>
<br>
0:09:09.320,0:09:14.520<br>
我們的 network 的 input 是一張 6*6 的 image<br>
<br>
0:09:14.520,0:09:16.900<br>
假設這是黑白的<br>
<br>
0:09:16.900,0:09:20.400<br>
如果是黑白的，每一個 pixel 就只需要用一個 value<br>
<br>
0:09:20.400,0:09:21.540<br>
來描述它<br>
<br>
0:09:21.540,0:09:23.960<br>
比如說，1 就代表有塗墨水<br>
<br>
0:09:23.960,0:09:27.200<br>
0 就代表，沒有塗到墨水<br>
<br>
0:09:27.200,0:09:30.240<br>
那在 convolution layer 裡面<br>
<br>
0:09:30.240,0:09:33.340<br>
它有一組 Filter<br>
<br>
0:09:33.340,0:09:34.980<br>
它有一堆 filter<br>
<br>
0:09:34.980,0:09:37.540<br>
那這邊的每一個 filter<br>
<br>
0:09:37.540,0:09:40.360<br>
我等一下會講說，它其實就等同於是<br>
<br>
0:09:40.360,0:09:42.760<br>
fully connected layer 裡面的一個 neuron<br>
<br>
0:09:42.760,0:09:45.660<br>
我們等一下會講，現在先想說，我們有<br>
<br>
0:09:45.660,0:09:47.500<br>
一組 filter<br>
<br>
0:09:47.500,0:09:51.080<br>
那每一個 filter，其實就是一個 matrix<br>
<br>
0:09:51.080,0:09:52.680<br>
比如說，這邊的每一個 filter<br>
<br>
0:09:52.680,0:09:55.180<br>
都是 3*3 的 matrix<br>
<br>
0:09:55.580,0:09:58.780<br>
那這邊的每一個 filter 裡面的參數<br>
<br>
0:09:58.780,0:10:01.540<br>
這個 matrix 裡面的每一個 element 的值<br>
<br>
0:10:01.540,0:10:03.360<br>
就是 network 的 parameter<br>
<br>
0:10:03.360,0:10:07.480<br>
它就跟那些 neuron 的 weight 跟 bias 一樣，它們是<br>
<br>
0:10:07.480,0:10:09.660<br>
network 的 parameter<br>
<br>
0:10:09.660,0:10:11.820<br>
它們是必須學出來的<br>
<br>
0:10:11.820,0:10:14.080<br>
根據 training data 學出來，並不是人去設計的<br>
<br>
0:10:14.180,0:10:15.600<br>
所以，每一個 filter<br>
<br>
0:10:15.600,0:10:17.040<br>
它裡面的值是做甚麼<br>
<br>
0:10:17.040,0:10:18.840<br>
它裡面的值是什麼，要做甚麼事情<br>
<br>
0:10:18.840,0:10:20.360<br>
也是自動被學出來的<br>
<br>
0:10:21.380,0:10:23.400<br>
這邊呢，我們<br>
<br>
0:10:23.400,0:10:26.360<br>
每一個 filter，如果你是 3*3 的 size<br>
<br>
0:10:26.360,0:10:29.140<br>
意味著它就是在偵測<br>
<br>
0:10:29.140,0:10:32.440<br>
一個 3*3 的 pattern<br>
<br>
0:10:32.440,0:10:34.760<br>
它在偵測一個 pattern 的時候，它不看整張 image<br>
<br>
0:10:34.760,0:10:37.280<br>
它只看一個 3*3 的範圍內<br>
<br>
0:10:37.280,0:10:40.200<br>
就可以決定有沒有某一個 pattern 的出現<br>
<br>
0:10:40.200,0:10:43.220<br>
這個就是我們考慮的第一個 property<br>
<br>
0:10:43.220,0:10:46.360<br>
整個 pattern 其實比整張 image 還要小<br>
<br>
0:10:47.400,0:10:50.700<br>
那這個 filter 怎麼跟這個 image<br>
<br>
0:10:50.700,0:10:52.360<br>
做 operation 呢<br>
<br>
0:10:52.360,0:10:55.280<br>
這個 operation 的 process 是這樣<br>
<br>
0:10:55.280,0:10:57.300<br>
首先，你有第一個 filter<br>
<br>
0:10:57.300,0:11:00.480<br>
它是一個 3*3 的 matrix<br>
<br>
0:11:00.480,0:11:05.580<br>
那你把這個 filter 放在 image 的左上角<br>
<br>
0:11:05.580,0:11:07.820<br>
那我猜你可能會很困惑說<br>
<br>
0:11:07.820,0:11:11.160<br>
突然出現甚麼 filter 阿，放在左上角阿<br>
<br>
0:11:11.160,0:11:13.080<br>
跟我們之前講的 neural network 都不一樣<br>
<br>
0:11:13.080,0:11:15.880<br>
等一下其實會告訴你說，這個就是一個 neural network<br>
<br>
0:11:15.880,0:11:18.680<br>
那 training 就跟之前那個 Backpropagation 是一模一樣的<br>
<br>
0:11:18.680,0:11:22.400<br>
那我們現在只是從 convolution 的角度來看<br>
<br>
0:11:22.400,0:11:23.620<br>
它是怎麼運作的<br>
<br>
0:11:23.620,0:11:25.160<br>
它運作的方式是這樣<br>
<br>
0:11:25.160,0:11:29.540<br>
我們把一個 filter 放在一個 image 的左上角<br>
<br>
0:11:29.540,0:11:32.020<br>
然後，你把這 9 個值<br>
<br>
0:11:32.020,0:11:33.760<br>
跟這 9 個值<br>
<br>
0:11:33.760,0:11:35.400<br>
做內積<br>
<br>
0:11:35.400,0:11:38.180<br>
所以，內積的結果，這邊是 1, 1, 1<br>
<br>
0:11:38.180,0:11:41.340<br>
這邊是1, 1, 1，內積的結果你就得到 3<br>
<br>
0:11:42.200,0:11:45.540<br>
接下來，你挪動一下，你的 filter 的位置<br>
<br>
0:11:45.540,0:11:48.600<br>
那至於要挪多少，這個你要事先決定好<br>
<br>
0:11:48.600,0:11:51.380<br>
那這個挪動的距離<br>
<br>
0:11:51.380,0:11:54.200<br>
欸，大家有問題嗎？<br>
<br>
0:11:54.200,0:11:56.960<br>
講道這邊，如果大家沒有問題的話，我們就繼續<br>
<br>
0:11:56.960,0:11:58.440<br>
這個挪動的距離<br>
<br>
0:11:58.440,0:12:00.860<br>
叫做 stride<br>
<br>
0:12:00.860,0:12:03.840<br>
這個 stride 等於多少，你要自己設啦<br>
<br>
0:12:03.840,0:12:05.240<br>
所以，你設 stride = 1<br>
<br>
0:12:05.240,0:12:07.640<br>
那 filter 就放在這邊，所以，1, 1, 1<br>
<br>
0:12:07.640,0:12:09.280<br>
乘上 -1, -1, 1<br>
<br>
0:12:09.280,0:12:11.160<br>
心算一下，得到是 -1<br>
<br>
0:12:11.420,0:12:13.040<br>
你可以設 stride = 2<br>
<br>
0:12:13.040,0:12:15.320<br>
stride = 2 的話，你就得到 -3<br>
<br>
0:12:15.320,0:12:17.260<br>
那 filter 移到這邊，1, 1, 1<br>
<br>
0:12:17.260,0:12:19.240<br>
-1, -1, -1 得到 -3<br>
<br>
0:12:20.400,0:12:22.960<br>
那我們等一下就設 stride = 1<br>
<br>
0:12:22.960,0:12:24.320<br>
所以，設 stride = 1<br>
<br>
0:12:24.320,0:12:27.400<br>
你把 filter 往右移一格，得到 -1<br>
<br>
0:12:27.400,0:12:30.860<br>
往右移一格，得到 -1；再往右移一格，得到 -3<br>
<br>
0:12:30.860,0:12:32.960<br>
再往右移一格，得到<br>
<br>
0:12:32.960,0:12:36.700<br>
這邊是 1, 1, 1，這邊是  -1, 1, -1，得到  -1<br>
<br>
0:12:36.700,0:12:40.340<br>
然後，你接下來往下移一格<br>
<br>
0:12:40.920,0:12:43.160<br>
得到 -3，就這樣，以此類推<br>
<br>
0:12:43.160,0:12:45.640<br>
把這件事情，就每一次都<br>
<br>
0:12:45.640,0:12:48.280<br>
stride = 1，就每次都移動一格<br>
<br>
0:12:48.280,0:12:50.700<br>
那最後，你就會得到一個<br>
<br>
0:12:50.700,0:12:53.680<br>
最後，直到你把 filter 移到右下角的時候<br>
<br>
0:12:53.680,0:12:55.960<br>
這邊是 1, 1, 1，這邊是 -1, 1, -1<br>
<br>
0:12:56.400,0:12:58.700<br>
你就得到 -1<br>
<br>
0:12:58.700,0:13:01.000<br>
所以，做這件事情以後<br>
<br>
0:13:01.000,0:13:03.340<br>
本來是一個 6*6 的 matrix<br>
<br>
0:13:03.340,0:13:06.420<br>
經過這個 convolution process，就得到一個<br>
<br>
0:13:06.420,0:13:08.120<br>
4*4 的 matrix<br>
<br>
0:13:08.460,0:13:10.720<br>
如果你看這個 filter 的值<br>
<br>
0:13:10.720,0:13:13.400<br>
它的斜對角的地方是 1, 1, 1<br>
<br>
0:13:13.400,0:13:16.680<br>
所以，它的工作就是 detect 有沒有 1, 1, 1<br>
<br>
0:13:16.680,0:13:19.740<br>
有沒有這個連續的，左上到右下的 1, 1, 1<br>
<br>
0:13:19.740,0:13:21.860<br>
出現在這個 image 裡面<br>
<br>
0:13:21.860,0:13:24.900<br>
比如說，它出現在這個地方<br>
<br>
0:13:24.900,0:13:28.000<br>
比如說，它出現在這個地方<br>
<br>
0:13:28.000,0:13:30.260<br>
所以，這個 filter 就會告訴你說<br>
<br>
0:13:30.260,0:13:33.560<br>
你看現在左上跟左下<br>
<br>
0:13:33.560,0:13:35.020<br>
出現最大的值<br>
<br>
0:13:35.020,0:13:37.200<br>
就代表說，這個 filter 要偵測的 pattern<br>
<br>
0:13:37.200,0:13:39.920<br>
它出現在這個 image 的左上角<br>
<br>
0:13:40.380,0:13:43.500<br>
所以，左上角最大值跟左下角<br>
<br>
0:13:43.500,0:13:45.580<br>
有最大的值，這件事情呢<br>
<br>
0:13:45.580,0:13:47.260<br>
就考慮了 property 2<br>
<br>
0:13:47.260,0:13:49.000<br>
因為，同一個 pattern<br>
<br>
0:13:49.000,0:13:52.360<br>
它出現在左上角的位置，跟出現在左下角的位置<br>
<br>
0:13:52.360,0:13:54.900<br>
我們都用 filter 1 就可以<br>
<br>
0:13:54.900,0:13:58.080<br>
偵測出來，我們不需要用不同的 filter 來做這件事情<br>
<br>
0:13:58.080,0:14:00.840<br>
我們用同一個 filter 就可以把它偵測出來<br>
<br>
0:14:01.740,0:14:04.960<br>
在一個 convolution 的 layer 裡面，它會有<br>
<br>
0:14:04.960,0:14:07.360<br>
一打 filter，它會有一大堆的 filter<br>
<br>
0:14:07.360,0:14:09.500<br>
那剛才只是一個 filter 的結果<br>
<br>
0:14:09.500,0:14:12.800<br>
會有另外一個 filter，它裡面會有不一樣的參數<br>
<br>
0:14:12.800,0:14:14.380<br>
比如說，這裡會有一個 filter 2<br>
<br>
0:14:14.380,0:14:17.460<br>
會有不一樣的參數，那它也做跟 filter 1<br>
<br>
0:14:17.460,0:14:19.060<br>
一模一樣的事情<br>
<br>
0:14:19.060,0:14:21.240<br>
你就先把 filter 2 放在左上角<br>
<br>
0:14:21.240,0:14:23.340<br>
再做 inner product 得到 -1<br>
<br>
0:14:23.340,0:14:28.880<br>
再挪動一格，得到  -1，就這樣，以此類推<br>
<br>
0:14:29.420,0:14:33.060<br>
所以，你把 filter 2 跟 input 的 image<br>
<br>
0:14:33.060,0:14:35.020<br>
做完 convolution 以後<br>
<br>
0:14:35.020,0:14:39.260<br>
你就得到另外一個 4*4 的 matrix<br>
<br>
0:14:39.260,0:14:41.480<br>
你就得到另外一個 4*4 的 matrix<br>
<br>
0:14:41.480,0:14:43.620<br>
那這個紅色的 4*4 的 matrix 跟<br>
<br>
0:14:43.620,0:14:45.600<br>
藍色的 4*4 的 matrix 合起來<br>
<br>
0:14:45.600,0:14:48.560<br>
就叫做，他們叫做 Feature Map<br>
<br>
0:14:48.560,0:14:50.040<br>
這個東西叫做 Feature Map<br>
<br>
0:14:50.040,0:14:55.980<br>
那看你有幾個 filter，你就會得到多少的 image<br>
<br>
0:14:55.980,0:15:00.200<br>
比如說，你有 100 個 filter<br>
<br>
0:15:00.200,0:15:04.440<br>
那這邊你會得到 100 個 image<br>
<br>
0:15:04.440,0:15:07.380<br>
講到這邊大家有沒有甚麼問題想要問呢？<br>
<br>
0:15:17.180,0:15:20.820<br>
沒錯，因為現在每一個 filter size 都是一樣的<br>
<br>
0:15:20.820,0:15:23.340<br>
意味著說，如果你今天有同一個 pattern<br>
<br>
0:15:23.340,0:15:25.800<br>
它有不同的 size，有大的鳥嘴，也有小的鳥嘴<br>
<br>
0:15:25.800,0:15:27.480<br>
它必須要用<br>
<br>
0:15:27.480,0:15:31.700<br>
如果你可以事先知道的話，你當然可以用 normalize<br>
<br>
0:15:31.700,0:15:34.100<br>
但是，input 一張 image，你沒有辦法事先知道<br>
<br>
0:15:34.100,0:15:35.720<br>
知道它是大的鳥嘴還是小的鳥嘴，所以<br>
<br>
0:15:35.720,0:15:37.160<br>
你也沒辦法 normalize<br>
<br>
0:15:37.160,0:15:41.460<br>
所以，CNN 並不能夠自動處理這個問題<br>
<br>
0:15:41.460,0:15:43.300<br>
對它來說，這種不同 scale 的東西，它其實<br>
<br>
0:15:43.300,0:15:44.680<br>
不見得能夠處理<br>
<br>
0:15:44.680,0:15:48.760<br>
那你其實可以看看這個<br>
<br>
0:15:50.340,0:15:52.480<br>
DeepMind 最近有解一篇 paper<br>
<br>
0:15:52.480,0:15:55.480<br>
是當你 input 一張 image 的時候<br>
<br>
0:15:55.480,0:15:58.220<br>
它在 CNN 前面，再接另外一個 network<br>
<br>
0:15:58.220,0:15:59.940<br>
這個 network 做的事情是甚麼呢？<br>
<br>
0:15:59.940,0:16:01.460<br>
這個 network 做的事情是<br>
<br>
0:16:01.460,0:16:02.720<br>
它 output 一些 scalar<br>
<br>
0:16:02.720,0:16:05.200<br>
告訴你說，它要把這個 image 的<br>
<br>
0:16:05.200,0:16:06.620<br>
裡面的哪些位置<br>
<br>
0:16:06.620,0:16:08.560<br>
做旋轉、縮放<br>
<br>
0:16:08.560,0:16:10.100<br>
然後，再丟到 CNN 裡面<br>
<br>
0:16:10.100,0:16:12.360<br>
這樣你其實會得到比較好的結果<br>
<br>
0:16:14.000,0:16:15.920<br>
大家還有甚麼問題嗎？<br>
<br>
0:16:18.320,0:16:20.400<br>
那剛才舉的例子是<br>
<br>
0:16:20.400,0:16:24.020<br>
黑白的 image，所以你 input 的是一個 matrix<br>
<br>
0:16:24.280,0:16:26.940<br>
如果今天是彩色的 image 怎麼樣呢？<br>
<br>
0:16:26.940,0:16:28.900<br>
我們知道彩色的 image 就是<br>
<br>
0:16:28.900,0:16:30.480<br>
RGB 組成的<br>
<br>
0:16:30.480,0:16:32.560<br>
對不對，RGB 組成的<br>
<br>
0:16:34.840,0:16:38.940<br>
所以一個彩色的 image，它就是好幾個 matrix 疊在一起<br>
<br>
0:16:38.940,0:16:41.580<br>
它就是一個立方體<br>
<br>
0:16:41.580,0:16:44.260<br>
如果我今天要處理彩色的 image<br>
<br>
0:16:44.260,0:16:46.080<br>
我們要怎麼做呢？<br>
<br>
0:16:46.080,0:16:49.060<br>
這個時候你的 filter，就不是一個 matrix<br>
<br>
0:16:49.060,0:16:51.560<br>
你的 filter 也是一個立方體<br>
<br>
0:16:51.560,0:16:56.880<br>
如果你今天是 RGB 這三個顏色來表示<br>
<br>
0:16:56.880,0:16:58.520<br>
一個 pixel 的話<br>
<br>
0:16:58.520,0:17:01.620<br>
那你的 input 就是 3*6*6<br>
<br>
0:17:01.620,0:17:04.380<br>
那你的 filter 就是 3*3*3<br>
<br>
0:17:04.380,0:17:06.480<br>
你的 filter 的高就是 3<br>
<br>
0:17:06.480,0:17:08.600<br>
你的 filter 高就是 3<br>
<br>
0:17:08.600,0:17:10.960<br>
你在做這個 convolution 的時候<br>
<br>
0:17:10.960,0:17:13.900<br>
你就是把這個 filter 的 9 個值<br>
<br>
0:17:13.900,0:17:17.260<br>
跟這個 image 裡面的 9 個值<br>
<br>
0:17:17.260,0:17:18.780<br>
做內積<br>
<br>
0:17:18.780,0:17:23.040<br>
了解嗎？我們並不是把每一個<br>
<br>
0:17:23.040,0:17:26.120<br>
把每一個 RGB 顏色都分開算<br>
<br>
0:17:26.120,0:17:28.280<br>
那其實這個在影像上，我們叫做 channel<br>
<br>
0:17:28.280,0:17:30.920<br>
並不是把每一個 channel 分開來算<br>
<br>
0:17:30.920,0:17:33.080<br>
而是，合在一起算<br>
<br>
0:17:33.080,0:17:35.000<br>
每一個 filter 同時就考慮了<br>
<br>
0:17:35.380,0:17:38.520<br>
不同顏色所代表的 channel<br>
<br>
0:17:38.520,0:17:40.920<br>
講道這邊大家聽得懂嗎？<br>
<br>
0:17:41.700,0:17:45.380<br>
那我們現在要講的東西就是<br>
<br>
0:17:45.380,0:17:48.620<br>
這個 convolution 跟 fully connected<br>
<br>
0:17:48.620,0:17:50.020<br>
有什麼關係？<br>
<br>
0:17:50.020,0:17:52.460<br>
你可能覺得說，它是一個很特別的 operation<br>
<br>
0:17:52.460,0:17:54.520<br>
感覺跟 neural network 沒半毛錢的關係<br>
<br>
0:17:54.520,0:17:57.160<br>
其實，它就是一個 neural network<br>
<br>
0:17:57.460,0:17:59.620<br>
怎麼說呢？我現在要講的就是<br>
<br>
0:17:59.620,0:18:02.220<br>
這個 convolution，這件事情<br>
<br>
0:18:02.220,0:18:04.440<br>
其實，它就是一個<br>
<br>
0:18:04.440,0:18:07.780<br>
fully connected 的 layer 把一些 weight 拿掉而已<br>
<br>
0:18:07.780,0:18:08.960<br>
怎麼說呢？<br>
<br>
0:18:08.960,0:18:11.560<br>
我們假設這邊這個 output<br>
<br>
0:18:11.560,0:18:13.080<br>
這個 feature map 的 output<br>
<br>
0:18:13.080,0:18:15.100<br>
其實就是<br>
<br>
0:18:15.100,0:18:18.280<br>
一個 hidden layer 的 neuron 的 output<br>
<br>
0:18:18.280,0:18:21.440<br>
如果你把這兩個東西 link 在一起的話<br>
<br>
0:18:21.440,0:18:25.240<br>
這個 convolution 其實就是一個<br>
<br>
0:18:25.240,0:18:28.280<br>
fully connected 的 layer 拿掉一些 weight 的結果<br>
<br>
0:18:28.280,0:18:29.900<br>
怎麼說呢？<br>
<br>
0:18:29.900,0:18:32.500<br>
我們在做 convolution 的時候<br>
<br>
0:18:32.500,0:18:35.600<br>
我們把 filter，假設我們今天考慮 filter 1<br>
<br>
0:18:35.600,0:18:37.800<br>
我們把 filter 1 放在左上角<br>
<br>
0:18:37.800,0:18:40.920<br>
然後，你做 inner product，得到一個值 3<br>
<br>
0:18:40.920,0:18:42.960<br>
這件事情等同於<br>
<br>
0:18:42.960,0:18:45.680<br>
我們現在把這個 6*6 的 image 拉直<br>
<br>
0:18:45.680,0:18:47.260<br>
拉直變成這樣子<br>
<br>
0:18:49.480,0:18:54.240<br>
然後，你有一個 neuron 的 output 是 3<br>
<br>
0:18:54.240,0:18:56.640<br>
那這個 neuron 的 output 怎麼來的呢？<br>
<br>
0:18:56.640,0:18:59.280<br>
這個 neuron 的 output 它是考慮了<br>
<br>
0:18:59.280,0:19:00.700<br>
你看這個 filter<br>
<br>
0:19:00.700,0:19:02.520<br>
它把它放在左上角<br>
<br>
0:19:02.520,0:19:04.240<br>
它在左上角<br>
<br>
0:19:04.240,0:19:07.500<br>
所以，這個 filter，它考慮的 pixel<br>
<br>
0:19:07.500,0:19:11.060<br>
是 1, 2, 3、1, 2, 3<br>
<br>
0:19:11.060,0:19:12.660<br>
這邊是 4, 5, 6<br>
<br>
0:19:12.660,0:19:13.860<br>
欸，不是 4, 5, 6<br>
<br>
0:19:13.860,0:19:16.560<br>
這邊 1, 2, 3, 4, 5, 6，所以這邊是 7, 8, 9<br>
<br>
0:19:16.560,0:19:17.380<br>
這邊是 7, 8, 9<br>
<br>
0:19:17.480,0:19:21.060<br>
這邊是 13, 14, 15<br>
<br>
0:19:21.060,0:19:25.420<br>
假設你把這一個 6*6 的 image 的 36 個 pixel 拉成<br>
<br>
0:19:25.420,0:19:26.620<br>
直的<br>
<br>
0:19:26.620,0:19:29.380<br>
那這 9 個 pixel 分別就是<br>
<br>
0:19:29.380,0:19:32.100<br>
編號 1, 2, 3 的 pixel 跟 7, 8, 9 的 pixel<br>
<br>
0:19:32.100,0:19:33.640<br>
跟 13, 14, 15 的 pixel<br>
<br>
0:19:33.640,0:19:37.220<br>
那如果我們說這個 filter 做 inner product 以後的 output 3<br>
<br>
0:19:37.220,0:19:39.440<br>
就是某一個 neuron 的 output 3 的話<br>
<br>
0:19:39.440,0:19:41.460<br>
就代表說有 1 個 neuron<br>
<br>
0:19:41.460,0:19:42.480<br>
這個 neuron 的 weight<br>
<br>
0:19:42.480,0:19:44.820<br>
只連接到 1, 2, 3<br>
<br>
0:19:44.820,0:19:47.300<br>
7, 8, 9 跟 13, 14, 15<br>
<br>
0:19:47.300,0:19:49.340<br>
這 3 個 pixel 而已<br>
<br>
0:19:49.340,0:19:52.480<br>
而這個 neuron 它的這 9 個 weight<br>
<br>
0:19:52.480,0:19:55.880<br>
就是 filter 這個 matrix 裡面的這 9 個 weight<br>
<br>
0:19:55.880,0:19:59.040<br>
花很多時間故意把它用同樣的顏色<br>
<br>
0:19:59.040,0:20:01.500<br>
這樣看的出來嗎？這個 1 是<br>
<br>
0:20:01.500,0:20:03.960<br>
框棕色，所以這邊才是棕色的<br>
<br>
0:20:03.960,0:20:06.780<br>
這個框紅色，這真的搞很久，所以這是紅色<br>
<br>
0:20:06.780,0:20:08.980<br>
這個橙色的<br>
<br>
0:20:08.980,0:20:12.040<br>
這邊有 9 個不同的顏色，所以<br>
<br>
0:20:12.040,0:20:15.540<br>
這 9 個不同顏色裡面框起來的 weight<br>
<br>
0:20:15.540,0:20:19.020<br>
分別就是這 9 個不同的 weight<br>
<br>
0:20:19.020,0:20:21.060<br>
大家看的懂嗎？<br>
<br>
0:20:21.740,0:20:23.480<br>
所以，現在是這樣子的<br>
<br>
0:20:23.480,0:20:25.580<br>
我們應該在 fully connected 的 layer 裡面<br>
<br>
0:20:25.580,0:20:28.940<br>
一個 neuron，照理說是連接到所有的 input<br>
<br>
0:20:28.940,0:20:32.060<br>
你有 36 個 pixel 當作 input<br>
<br>
0:20:32.060,0:20:36.460<br>
那這個 neuron 本來應該連接到 36 個 input<br>
<br>
0:20:36.460,0:20:39.520<br>
但是，我們現在只連接 9 個 input<br>
<br>
0:20:39.520,0:20:41.900<br>
只連接 9 個 input，因為我們知道說<br>
<br>
0:20:41.900,0:20:44.200<br>
要 detect 一個 pattern，我們不需要看整張 image<br>
<br>
0:20:44.200,0:20:46.300<br>
我就看 9 個 input 就好<br>
<br>
0:20:46.300,0:20:49.920<br>
所以，當我們這麼做的時候，你就用了<br>
<br>
0:20:49.920,0:20:53.380<br>
比較少的參數，你就用了比較少的參數<br>
<br>
0:20:54.080,0:20:59.040<br>
當我們移動一格，把 filter 做 stride = 1 的移動的時候<br>
<br>
0:20:59.040,0:21:00.120<br>
發生甚麼事呢？<br>
<br>
0:21:00.120,0:21:01.920<br>
我們得到另外一個值 -1<br>
<br>
0:21:01.920,0:21:05.680<br>
我們假設這個 -1 是另外一個<br>
<br>
0:21:05.680,0:21:07.800<br>
neuron 的 output<br>
<br>
0:21:07.800,0:21:10.940<br>
那這個 neuron 連接到哪些 input 的 weight 呢<br>
<br>
0:21:10.940,0:21:13.560<br>
這一個框起來的地方啊<br>
<br>
0:21:13.560,0:21:18.420<br>
這個框起來的地方，它正好就對應到 pixel 2, 3, 4<br>
<br>
0:21:18.420,0:21:22.180<br>
2, 3, 4，這個是 8, 9, 10<br>
<br>
0:21:22.180,0:21:25.200<br>
8, 9, 10 跟 14, 15, 16<br>
<br>
0:21:25.200,0:21:27.540<br>
跟 14, 15, 16，你會發現說這邊呢<br>
<br>
0:21:27.540,0:21:31.120<br>
同樣的 weight 代表同一個顏色，所以<br>
<br>
0:21:31.120,0:21:33.340<br>
這 9 個 matrix<br>
<br>
0:21:33.340,0:21:36.460<br>
這 9 個在這個 filter 所對應的matrix 裡面的 weight<br>
<br>
0:21:36.460,0:21:39.840<br>
就是這個圖上 9 個不同的顏色<br>
<br>
0:21:39.840,0:21:43.040<br>
所以，當我們做這件事情的時候，意味著說<br>
<br>
0:21:43.040,0:21:44.380<br>
這裡個 neuron<br>
<br>
0:21:44.380,0:21:46.500<br>
本來在 fully connected layer 裡面<br>
<br>
0:21:46.500,0:21:49.100<br>
每一個 neuron 都有獨立、自己的 weight<br>
<br>
0:21:49.100,0:21:51.800<br>
但是，當我們做這個<br>
<br>
0:21:51.800,0:21:54.180<br>
convolution 的時候<br>
<br>
0:21:54.180,0:21:58.420<br>
首先，我們把每一個 neuron 它前面連接的 weight 減少<br>
<br>
0:21:58.420,0:22:00.320<br>
再來，我們強迫說<br>
<br>
0:22:00.320,0:22:02.300<br>
某些 neuron、這兩個 neuron<br>
<br>
0:22:02.300,0:22:04.840<br>
他們一定要共用同一組 weight<br>
<br>
0:22:04.840,0:22:06.940<br>
他們的 weight 永遠都必須是一樣的<br>
<br>
0:22:06.940,0:22:09.900<br>
它連接到 pixel 1 的 weight<br>
<br>
0:22:09.900,0:22:13.860<br>
要等於它連接到 pixel 2 的 weight<br>
<br>
0:22:13.860,0:22:15.600<br>
它連接到 pixel 2 的 weight<br>
<br>
0:22:15.600,0:22:17.840<br>
要等於它連接到 pixel 3 的 weight<br>
<br>
0:22:17.840,0:22:20.400<br>
它連接到 pixel 3 的 weight，<br>
要等於它連接到 pixel 4 的 weight<br>
<br>
0:22:20.400,0:22:23.980<br>
我故意用同樣的顏色來表示，希望你可以看的出來<br>
<br>
0:22:24.820,0:22:27.860<br>
這件事情叫做 weight 的 sharing<br>
<br>
0:22:27.860,0:22:30.540<br>
當我們做這件事情的時候，我們用<br>
<br>
0:22:30.540,0:22:32.140<br>
用的這個參數呢<br>
<br>
0:22:32.140,0:22:34.680<br>
又比原來又更少<br>
<br>
0:22:34.680,0:22:36.300<br>
我們強迫一些 weight<br>
<br>
0:22:36.300,0:22:37.860<br>
一定要 share 在一起<br>
<br>
0:22:37.860,0:22:40.020<br>
我們用的 weight 就更少<br>
<br>
0:22:41.020,0:22:43.200<br>
這邊有一些事情是投影片上沒有講的<br>
<br>
0:22:43.200,0:22:44.300<br>
可能會問說<br>
<br>
0:22:44.300,0:22:46.260<br>
這怎麼 train<br>
<br>
0:22:46.260,0:22:49.200<br>
首先，第一件事情就是這都是用 toolkit 做的<br>
<br>
0:22:49.200,0:22:50.320<br>
所以，你大概不會自己寫<br>
<br>
0:22:50.320,0:22:51.820<br>
如果你要自己寫的話<br>
<br>
0:22:51.820,0:22:54.620<br>
它的做法就是，你就跟原來的 Backpropagation<br>
<br>
0:22:54.620,0:22:56.100<br>
用一模一樣的作法<br>
<br>
0:22:56.100,0:22:57.760<br>
只是有一些 weight<br>
<br>
0:22:57.760,0:23:00.020<br>
就永遠是 0，你就不 train 它，它就永遠是 0<br>
<br>
0:23:00.460,0:23:01.460<br>
然後，再來呢<br>
<br>
0:23:01.460,0:23:04.900<br>
你說怎麼讓這個 weight 的值永遠都是一樣的<br>
<br>
0:23:04.900,0:23:07.560<br>
你就用一般的 Backpropagation 的方法<br>
<br>
0:23:07.560,0:23:10.080<br>
然後，這個 weight 你算出一個 gradient<br>
<br>
0:23:10.080,0:23:11.580<br>
這個 weight 你算出一個 gradient<br>
<br>
0:23:11.580,0:23:13.440<br>
再把本來要 tight 在一起<br>
<br>
0:23:13.440,0:23:16.440<br>
要 share weight 的那些 weight 的  gradient 平均<br>
<br>
0:23:16.440,0:23:19.440<br>
然後，他們 update 同樣的值，就結束了<br>
<br>
0:23:20.560,0:23:21.900<br>
你聽不懂沒有關係，因為<br>
<br>
0:23:21.900,0:23:24.100<br>
你大概沒有機會自己實作這個東西<br>
<br>
0:23:26.780,0:23:29.500<br>
如果你真的有空的話，等一下下課可以跟我討論<br>
<br>
0:23:32.320,0:23:33.380<br>
這件事情呢<br>
<br>
0:23:33.380,0:23:36.280<br>
再來，接下來要做 Max pooling<br>
<br>
0:23:36.280,0:23:37.540<br>
Max pooling 是甚麼呢？<br>
<br>
0:23:37.540,0:23:39.980<br>
相較於 convolution，max pooling 是比較簡單的<br>
<br>
0:23:39.980,0:23:41.600<br>
它就是做 subsampling<br>
<br>
0:23:41.600,0:23:43.000<br>
根據 filter 1<br>
<br>
0:23:43.000,0:23:46.500<br>
我們得到一個 4*4 的 matrix<br>
<br>
0:23:46.500,0:23:49.460<br>
根據 filter 2，你得到另外一個 4*4 的 matrix<br>
<br>
0:23:49.460,0:23:51.200<br>
接下來，我們做甚麼事呢？<br>
<br>
0:23:51.200,0:23:54.180<br>
我們說，把這個<br>
<br>
0:23:54.180,0:23:56.940<br>
output，4 個一組，4 個一組<br>
<br>
0:23:56.940,0:23:58.400<br>
4 個一組，4 個一組<br>
<br>
0:23:58.400,0:24:01.580<br>
每一組裡面，你可以選他們的平均<br>
<br>
0:24:01.580,0:24:03.760<br>
或者是你可以選最大，其實都可以<br>
<br>
0:24:03.760,0:24:08.080<br>
你就是把原來 4 個 value 合成 1 個 value<br>
<br>
0:24:08.080,0:24:10.160<br>
那你可以用自己想要的方法來做這件事情<br>
<br>
0:24:10.160,0:24:12.420<br>
這件事情就可以讓你的 image 縮小<br>
<br>
0:24:12.420,0:24:15.520<br>
比如說，假設我們現在就是選 4 個裡面<br>
<br>
0:24:15.520,0:24:17.300<br>
最大的那個保留下來<br>
<br>
0:24:17.300,0:24:20.140<br>
所以，3, -1, 3, 1，我就選 3<br>
<br>
0:24:21.080,0:24:24.560<br>
就選最大的保留下來，那你這邊可能會有一個問題就是<br>
<br>
0:24:24.560,0:24:27.940<br>
把這個東西放到 network 裡面，你不就沒辦法微分了嗎<br>
<br>
0:24:28.100,0:24:30.480<br>
max 這個東西，感覺不能微分阿<br>
<br>
0:24:30.480,0:24:32.220<br>
它其實可以的<br>
<br>
0:24:32.220,0:24:34.380<br>
我們之後講 Maxout network 的時候，再來跟大家講<br>
<br>
0:24:34.380,0:24:38.820<br>
這個，其實有辦法用微分的方式來處理它<br>
<br>
0:24:40.420,0:24:42.880<br>
所以，結論是這樣<br>
<br>
0:24:42.880,0:24:44.040<br>
結論是這樣<br>
<br>
0:24:44.040,0:24:48.060<br>
我們現在，這邊有 4 個值，這邊有 4 個值<br>
<br>
0:24:48.060,0:24:50.600<br>
所以，做完一次 convolution<br>
<br>
0:24:50.600,0:24:52.120<br>
加一次 Max pooling<br>
<br>
0:24:52.120,0:24:54.760<br>
我們就把原來 6*6 的 image<br>
<br>
0:24:54.760,0:24:57.340<br>
變成一個 2*2 的 image<br>
<br>
0:24:57.340,0:25:01.080<br>
至於這一個 2*2 的 image，它每一個 pixel 的深度<br>
<br>
0:25:01.080,0:25:02.620<br>
它的這個深度<br>
<br>
0:25:02.620,0:25:05.180<br>
每一個 pixel 用幾個 value 來表示<br>
<br>
0:25:05.180,0:25:07.920<br>
depend on 你有幾個 filter，如果你有 50 個 filter<br>
<br>
0:25:07.920,0:25:09.420<br>
這邊就是 50 維<br>
<br>
0:25:09.420,0:25:12.080<br>
兩個 filter，這邊就 2 維<br>
<br>
0:25:12.080,0:25:13.680<br>
所以，這個就是一個<br>
<br>
0:25:13.680,0:25:16.700<br>
新的，但是比較小的 image<br>
<br>
0:25:16.700,0:25:19.400<br>
那每一個 filter 就代表了一個 channel<br>
<br>
0:25:19.400,0:25:22.900<br>
這一件是可以 repeat 很多次<br>
<br>
0:25:22.900,0:25:25.100<br>
你得到一個、你通過一個 convolution<br>
<br>
0:25:25.100,0:25:27.240<br>
再加一個 Max pooling<br>
<br>
0:25:27.240,0:25:31.600<br>
你就得到一個新的 image<br>
<br>
0:25:31.600,0:25:33.280<br>
你就得到一個新的 image<br>
<br>
0:25:33.280,0:25:36.640<br>
那它是一個比較小的 image<br>
<br>
0:25:36.640,0:25:40.240<br>
所以，你可以把這個比較小的 image，再做一樣的事情<br>
<br>
0:25:40.240,0:25:41.700<br>
再通過 convolution<br>
<br>
0:25:41.700,0:25:46.280<br>
再通過 Max pooling，再得到一個更小的 image<br>
<br>
0:25:46.280,0:25:47.660<br>
那我這邊舉的例子<br>
<br>
0:25:47.660,0:25:49.220<br>
input image 已經夠小了<br>
<br>
0:25:49.220,0:25:51.100<br>
所以，再做一次就不見了<br>
<br>
0:25:51.100,0:25:52.540<br>
我就沒有再做一次<br>
<br>
0:25:52.700,0:25:56.340<br>
講到這邊，大家可以了解我意思嗎？<br>
<br>
0:25:56.340,0:25:57.940<br>
有甚麼問題要問的嗎？<br>
<br>
0:25:58.640,0:26:00.800<br>
其實我講到這邊的時候，我常常會<br>
<br>
0:26:00.800,0:26:03.220<br>
被問到、遇到一個問題<br>
<br>
0:26:03.220,0:26:05.300<br>
大概是我講 deep learning 的 talk 已經太多了<br>
<br>
0:26:05.300,0:26:08.780<br>
我都可以 predict 聽眾的問題<br>
<br>
0:26:08.780,0:26:12.240<br>
這邊每次都會有人問我一個問題，就是<br>
<br>
0:26:14.160,0:26:16.400<br>
如果我這邊有 25 個 filter<br>
<br>
0:26:16.400,0:26:18.820<br>
我得到 25 個<br>
<br>
0:26:18.820,0:26:20.100<br>
feature map<br>
<br>
0:26:20.100,0:26:22.440<br>
假設我第一個 convolution 有 25 個 filter<br>
<br>
0:26:22.440,0:26:24.100<br>
我得到 25 個 feature map<br>
<br>
0:26:24.100,0:26:26.340<br>
第二個 convolution 也有 25 個 filter<br>
<br>
0:26:26.340,0:26:28.000<br>
那這樣做完，我是不是得到<br>
<br>
0:26:28.000,0:26:30.220<br>
25 平方個 feature map<br>
<br>
0:26:31.180,0:26:32.620<br>
是這樣嗎？<br>
<br>
0:26:33.840,0:26:35.860<br>
其實不是這樣，就是說<br>
<br>
0:26:35.860,0:26:39.000<br>
你這邊做完一次 convolution，你得到 25 個 feature map<br>
<br>
0:26:39.000,0:26:42.240<br>
你這邊做完，還是得到 25 個 feature map<br>
<br>
0:26:42.240,0:26:45.280<br>
這樣大家了解我意思嗎？因為你在這邊<br>
<br>
0:26:45.280,0:26:46.780<br>
假設你這邊有<br>
<br>
0:26:46.780,0:26:48.920<br>
第一層 filter 有兩個好了<br>
<br>
0:26:49.780,0:26:52.320<br>
那第二層的 filter<br>
<br>
0:26:52.320,0:26:55.400<br>
它在考慮這個 input 的時候<br>
<br>
0:26:55.400,0:26:57.060<br>
它是會考慮深度的<br>
<br>
0:26:57.060,0:26:59.660<br>
它並不是每一個 channel 分開考慮<br>
<br>
0:26:59.660,0:27:01.820<br>
它是一次考慮所有的 channel<br>
<br>
0:27:01.820,0:27:04.440<br>
所以，你 convolution 這邊有多少個 filter<br>
<br>
0:27:04.440,0:27:05.460<br>
你 output 就有多少個 filter<br>
<br>
0:27:05.460,0:27:06.720<br>
你這的25 個 filter<br>
<br>
0:27:06.720,0:27:07.780<br>
output 就 25 個 filter<br>
<br>
0:27:07.780,0:27:10.880<br>
你這邊有 25 個 filter，output 還是 25 個 filter<br>
<br>
0:27:10.880,0:27:12.840<br>
只是這邊的每一個 25 個 filter<br>
<br>
0:27:12.840,0:27:15.100<br>
它都是一個 cubic<br>
<br>
0:27:15.100,0:27:16.520<br>
它都是一個立方體<br>
<br>
0:27:16.520,0:27:21.040<br>
它的高有 25 個 value 那麼高<br>
<br>
0:27:21.040,0:27:23.780<br>
這樣大家有問題嗎？<br>
<br>
0:27:25.160,0:27:27.460<br>
如果大家沒有問題的話呢<br>
<br>
0:27:27.460,0:27:29.620<br>
我們就繼續<br>
<br>
0:27:29.620,0:27:32.300<br>
然後，有一個，再來就是<br>
<br>
0:27:32.300,0:27:34.700<br>
最後這個 flatten 跟 fully connected 的部分<br>
<br>
0:27:34.700,0:27:36.840<br>
這個就很簡單，這個怎麼做呢？<br>
<br>
0:27:36.840,0:27:39.100<br>
flatten 的意思就是，我把<br>
<br>
0:27:39.100,0:27:41.340<br>
這個 feature map 拉直<br>
<br>
0:27:41.340,0:27:43.760<br>
這邊完全沒有學問在，我就把它拉直<br>
<br>
0:27:43.760,0:27:47.300<br>
拉直以後，你就把它丟到一個 fully connected 的<br>
<br>
0:27:47.300,0:27:50.100<br>
feedforward network，然後<br>
<br>
0:27:50.100,0:27:52.360<br>
就沒有然後，就結束了<br>
<br>
0:27:53.040,0:27:56.420<br>
接下來，剩下一點時間，我就要<br>
<br>
0:27:56.420,0:27:59.140<br>
秒講一下，怎麼用 Keras<br>
<br>
0:27:59.140,0:28:01.600<br>
來 implement CNN<br>
<br>
0:28:01.600,0:28:05.680<br>
那在 training, compile 跟 fitting 的部分<br>
<br>
0:28:05.680,0:28:06.700<br>
其實是一模一樣<br>
<br>
0:28:06.700,0:28:08.820<br>
你唯一需要改的只有說<br>
<br>
0:28:08.820,0:28:11.540<br>
你要改一下你的 network structure<br>
<br>
0:28:11.540,0:28:12.780<br>
還有 input 的 format<br>
<br>
0:28:12.780,0:28:15.720<br>
本來在原來的 DNN 裡面，input 是一個 vector<br>
<br>
0:28:15.720,0:28:17.600<br>
現在如果是 CNN 的話<br>
<br>
0:28:17.600,0:28:20.940<br>
它是會考慮 input 的 image 的幾何空間的<br>
<br>
0:28:20.940,0:28:22.480<br>
所以，不能 input 給它一個 vector<br>
<br>
0:28:22.480,0:28:28.160<br>
你要 input 給它一個 tensor 這樣<br>
<br>
0:28:28.160,0:28:30.200<br>
tensor 就是高維的 vector 啦<br>
<br>
0:28:30.200,0:28:31.500<br>
你要給它一個三維的 vector<br>
<br>
0:28:31.500,0:28:33.040<br>
為什麼三維的 vector 呢<br>
<br>
0:28:33.040,0:28:35.580<br>
因為一個 image 的長寬各是一維<br>
<br>
0:28:35.580,0:28:37.880<br>
如果它是彩色的話，RGB 就是第三維<br>
<br>
0:28:37.880,0:28:39.780<br>
所以，你要給它三維的 vector<br>
<br>
0:28:39.780,0:28:42.020<br>
你 assign 一個三維的 matrix<br>
<br>
0:28:42.020,0:28:45.260<br>
這個高維的 matrix 就叫做 tensor<br>
<br>
0:28:45.820,0:28:49.160<br>
那怎麼 implement 一個 convolution 的 layer 呢<br>
<br>
0:28:49.160,0:28:50.820<br>
你就這麼做<br>
<br>
0:28:50.820,0:28:52.300<br>
model.add<br>
<br>
0:28:52.300,0:28:56.400<br>
剛才是 dense，現在就改成 convolution2D<br>
<br>
0:28:56.400,0:28:58.900<br>
它其實也有 1D 的，現在就改成 2D<br>
<br>
0:29:00.220,0:29:03.260<br>
然後，這邊 25, 3, 3 是甚麼意思呢？<br>
<br>
0:29:03.260,0:29:05.160<br>
這邊 25, 3, 3 的意思就是說<br>
<br>
0:29:05.160,0:29:06.420<br>
你有 25 個<br>
<br>
0:29:06.420,0:29:08.240<br>
25 代表 25 個 filter<br>
<br>
0:29:08.240,0:29:12.220<br>
後面的 3, 3 就代表，你的 filter 是一個 3*3 的 matrix<br>
<br>
0:29:12.220,0:29:15.700<br>
你的 filter 都是 3*3 的 size<br>
<br>
0:29:16.460,0:29:17.560<br>
那 input 呢？<br>
<br>
0:29:17.560,0:29:19.360<br>
你要告訴它 input shape 要是甚麼樣子<br>
<br>
0:29:19.360,0:29:21.420<br>
假設我現在是要做手寫數字辨識<br>
<br>
0:29:21.420,0:29:23.340<br>
input 是 28*28 的 image<br>
<br>
0:29:23.340,0:29:25.600<br>
它的每一個 pixel 都是<br>
<br>
0:29:26.120,0:29:28.420<br>
都是只有單一顏色<br>
<br>
0:29:28.420,0:29:32.500<br>
所以，你 input 的 shape 就是 1*28*28<br>
<br>
0:29:32.500,0:29:35.560<br>
前面這個 1 阿，如果你是黑白的話，它就是 1<br>
<br>
0:29:35.560,0:29:39.500<br>
如果你是彩色的圖，每個 pixel 用 3 個值來表示<br>
<br>
0:29:39.500,0:29:43.820<br>
這邊你就要放 3，代表 RGB 3 個顏色<br>
<br>
0:29:43.820,0:29:48.140<br>
那 28*28 就代表這個 image 總共 28*28 個 pixel<br>
<br>
0:29:48.140,0:29:49.960<br>
那 Max pooling 也很簡單<br>
<br>
0:29:49.960,0:29:52.480<br>
就 add 一個 Max pooling 的 layer<br>
<br>
0:29:52.480,0:29:54.600<br>
那這邊的 (2, 2) 的意思是說呢<br>
<br>
0:29:54.600,0:29:59.260<br>
我們把 2*2 的這個<br>
<br>
0:29:59.260,0:30:01.660<br>
feature map 裡面的 pixel 拿出來<br>
<br>
0:30:01.660,0:30:05.060<br>
然後，每次就選最大的那一個<br>
<br>
0:30:06.400,0:30:09.780<br>
所以，假設我們 input 是一個<br>
<br>
0:30:09.780,0:30:11.920<br>
1*28*28 的 image<br>
<br>
0:30:11.920,0:30:15.040<br>
那你就這樣寫 add(Convolution2D(25, 3, 3,<br>
<br>
0:30:15.040,0:30:17.100<br>
input_shape = (1, 28, 28)))<br>
<br>
0:30:17.100,0:30:20.380<br>
那通過 convolution 以後<br>
<br>
0:30:20.380,0:30:23.460<br>
你得到的東西是甚麼呢？<br>
<br>
0:30:23.460,0:30:25.600<br>
你得到的 output 是甚麼呢？<br>
<br>
0:30:25.600,0:30:28.020<br>
你得到的 output，首先，你這個<br>
<br>
0:30:28.020,0:30:29.500<br>
channel 的數目會是 25<br>
<br>
0:30:29.500,0:30:30.900<br>
也就是 25 個 filter<br>
<br>
0:30:30.900,0:30:33.920<br>
你得到的 channel 的數目就是 25<br>
<br>
0:30:33.920,0:30:36.860<br>
然後，因為你現在的 filter 的 size 是 3<br>
<br>
0:30:36.860,0:30:39.040<br>
所以，本來 28*28 的 image<br>
<br>
0:30:39.040,0:30:40.640<br>
通過 3, 3 的 filter<br>
<br>
0:30:40.640,0:30:43.540<br>
就假設你那個邊邊的地方沒有考慮的話<br>
<br>
0:30:43.540,0:30:46.120<br>
就會變成 26*26<br>
<br>
0:30:46.120,0:30:47.580<br>
這樣大家了解我意思嗎？<br>
<br>
0:30:47.580,0:30:48.860<br>
當然你也可以考慮邊邊啦<br>
<br>
0:30:48.860,0:30:50.220<br>
如果你想要考慮邊邊的話<br>
<br>
0:30:50.220,0:30:52.400<br>
你就在原來的 image 旁邊<br>
<br>
0:30:52.400,0:30:54.340<br>
補 0，把它變成比較大的 image<br>
<br>
0:30:56.620,0:31:00.040<br>
然後，接下來你做 Max pooling<br>
<br>
0:31:00.040,0:31:03.180<br>
你做 Max pooling，把 2*2 的<br>
<br>
0:31:03.180,0:31:05.500<br>
這個 pixel 一組<br>
<br>
0:31:05.500,0:31:06.860<br>
然後，裡面選一個最大的<br>
<br>
0:31:06.860,0:31:09.980<br>
做完以後，你就變成 25*13*13<br>
<br>
0:31:09.980,0:31:12.400<br>
變 25*13*13<br>
<br>
0:31:13.640,0:31:15.780<br>
然後，接下來<br>
<br>
0:31:15.780,0:31:19.000<br>
你再做一次 convolution，假設我這次選<br>
<br>
0:31:19.000,0:31:20.280<br>
50 個 filter<br>
<br>
0:31:20.280,0:31:22.820<br>
然後，每個 filter size 是 3*3 的話<br>
<br>
0:31:22.820,0:31:26.640<br>
那現在變成 output 的 channel 就有 50 個<br>
<br>
0:31:26.640,0:31:28.400<br>
那 13*13 的 image<br>
<br>
0:31:28.400,0:31:30.040<br>
通過 3*3 的 filter<br>
<br>
0:31:30.040,0:31:32.660<br>
就會變成 11*11<br>
<br>
0:31:32.660,0:31:35.820<br>
我們剛才舉的例子，裡面是 6*6 的 image<br>
<br>
0:31:35.820,0:31:39.080<br>
通過 3*3 的 filter，變成 4*4<br>
<br>
0:31:39.080,0:31:42.380<br>
所以，你通過 3*3 的 filter 都會是<br>
<br>
0:31:42.380,0:31:44.420<br>
長跟寬都會減 2<br>
<br>
0:31:44.420,0:31:47.460<br>
所以，本來是 13*13 的 image<br>
<br>
0:31:47.460,0:31:50.620<br>
通過 3*3 的 filter，就變成 11*11<br>
<br>
0:31:50.620,0:31:54.500<br>
然後，你接下來再做 Max pooling<br>
<br>
0:31:54.500,0:31:56.980<br>
2*2 的 Max pooling 變成 50*5*5<br>
<br>
0:31:58.920,0:32:02.800<br>
那這邊呢，就問一下大家<br>
<br>
0:32:02.800,0:32:06.400<br>
在第一個 convolution<br>
<br>
0:32:06.400,0:32:08.280<br>
的 layer 裡面<br>
<br>
0:32:08.280,0:32:11.560<br>
每一個 filter，它有多少個參數呢？<br>
<br>
0:32:11.560,0:32:12.940<br>
它有多少個參數<br>
<br>
0:32:12.940,0:32:15.080<br>
是不是 9 個參數<br>
<br>
0:32:15.080,0:32:18.440<br>
因為，它就是一個 3*3 的 matrix 嘛，就是 9 個參數<br>
<br>
0:32:18.440,0:32:21.500<br>
但是，在第二個 convolution layer 裡面<br>
<br>
0:32:21.500,0:32:23.400<br>
雖然，你每一個 neuron<br>
<br>
0:32:23.400,0:32:26.780<br>
每一個 filter 都是 3*3，但它其實不是<br>
<br>
0:32:26.780,0:32:28.660<br>
3*3 個參數<br>
<br>
0:32:28.660,0:32:31.080<br>
因為，它 input 的 channel 有 25 個<br>
<br>
0:32:31.080,0:32:33.880<br>
所以，它的參數是 3*3*25<br>
<br>
0:32:33.880,0:32:37.960<br>
它的高是 25，所以這邊是 225<br>
<br>
0:32:37.960,0:32:40.000<br>
這樣大家有問題嗎？<br>
<br>
0:32:43.100,0:32:45.900<br>
如果大家沒有問題的話<br>
<br>
0:32:45.900,0:32:47.160<br>
我們就繼續看下去<br>
<br>
0:32:47.160,0:32:51.420<br>
所以，通過兩次 convolution、兩次 Max pooling<br>
<br>
0:32:51.420,0:32:53.800<br>
原來 input 是 28*28<br>
<br>
0:32:53.800,0:32:56.280<br>
做完這些事以後，變成 50*5*5<br>
<br>
0:32:56.280,0:32:57.600<br>
50*5*5<br>
<br>
0:32:57.600,0:32:59.040<br>
那做 flatten 就是<br>
<br>
0:32:59.040,0:33:01.340<br>
把這一個東西拉直<br>
<br>
0:33:01.340,0:33:03.780<br>
那你只要 call 一個 add flatten 就好<br>
<br>
0:33:03.780,0:33:04.820<br>
把它拉直<br>
<br>
0:33:04.820,0:33:08.260<br>
拉直以後就變成一個 1250 維的 vector<br>
<br>
0:33:08.260,0:33:10.280<br>
你再把 1250 維的 vector<br>
<br>
0:33:10.280,0:33:12.840<br>
丟到一個 fully connected 的 network 裡面<br>
<br>
0:33:12.840,0:33:17.160<br>
fully connected 的 network 大家應該都很熟悉，就跟<br>
<br>
0:33:17.160,0:33:19.540<br>
我們剛才 demo 的是一樣的<br>
<br>
0:33:19.540,0:33:22.180<br>
然後就得到 output，我們就現場實作<br>
<br>
0:33:22.180,0:33:24.480<br>
秒做一下 CNN 這樣<br>
<br>
0:33:24.480,0:33:27.080<br>
那這 code 你只要再胡亂改一下，就可以交作業三<br>
<br>
0:33:30.440,0:33:32.560<br>
我們的 CNN 的架構<br>
<br>
0:33:32.560,0:33:37.200<br>
我們很快、非常非常快地來複習一下<br>
<br>
0:33:37.200,0:33:40.580<br>
比如說，我們現在要做手寫數字辨識<br>
<br>
0:33:40.580,0:33:44.620<br>
那 input 呢，哦，忘了開聲音<br>
<br>
0:33:51.420,0:33:54.660<br>
假設我們要做手寫數字辨識，input 是一張<br>
<br>
0:33:54.660,0:33:57.600<br>
28*28 的影像<br>
<br>
0:33:57.600,0:34:00.540<br>
然後，通過 convolution layer 以後呢<br>
<br>
0:34:00.540,0:34:06.200<br>
假設我們現在有 25 個 filter<br>
<br>
0:34:06.200,0:34:09.760<br>
然後，每個 filter 的 size 是 3*3<br>
<br>
0:34:09.760,0:34:13.260<br>
那 input 28*28 的 image，它的 output 呢<br>
<br>
0:34:13.260,0:34:15.720<br>
通過 3*3 的 filter 以後<br>
<br>
0:34:15.720,0:34:19.040<br>
你得到 image size 就是 26*26<br>
<br>
0:34:19.040,0:34:22.500<br>
那這個 26*26 的 image，它的每一個 pixel<br>
<br>
0:34:22.500,0:34:25.920<br>
都是由一個 25 維的 vector 來表示<br>
<br>
0:34:25.920,0:34:28.100<br>
如果你有 25 個 filter 的話呢<br>
<br>
0:34:28.100,0:34:30.160<br>
這是 25 維的 vector<br>
<br>
0:35:12.540,0:35:14.500<br>
然後做 Max poling<br>
<br>
0:35:14.500,0:35:18.320<br>
就把原來 26*26 的 image 變成 13*13<br>
<br>
0:35:18.320,0:35:21.880<br>
然後，你可以再加另外一層 convolution<br>
<br>
0:35:21.880,0:35:25.340<br>
另外一層 convolution，假設它是 3*3 的話<br>
<br>
0:35:25.340,0:35:27.700<br>
做完 convolution 就是 11*11<br>
<br>
0:35:27.700,0:35:29.980<br>
因為有 50 個 filter，所以<br>
<br>
0:35:29.980,0:35:33.440<br>
你的每一個 pixel 現在是用 50 個 value 來描述<br>
<br>
0:35:33.440,0:35:35.240<br>
然後，你可以再做 pooling 等等<br>
<br>
0:35:35.240,0:35:39.960<br>
最後，把這個結果接進一個 fully connected layer 得到<br>
<br>
0:35:39.960,0:35:42.060<br>
最後的 output，上次也示範說<br>
<br>
0:35:42.060,0:35:44.440<br>
如果你要用一個 Keras 來實作一個 CNN 的話<br>
<br>
0:35:44.440,0:35:47.100<br>
你要怎麼秒做<br>
<br>
0:35:47.100,0:35:49.220<br>
接下來，我想要講的是<br>
<br>
0:35:49.220,0:35:51.080<br>
大家、很多人常會說<br>
<br>
0:35:51.080,0:35:54.400<br>
deep learning 就是一個黑盒子<br>
<br>
0:35:54.400,0:36:00.340<br>
然後，你 learn 完以後，你不知道它得到了甚麼<br>
<br>
0:36:00.340,0:36:02.400<br>
所以，有很多人不喜歡這種方法<br>
<br>
0:36:02.400,0:36:05.640<br>
其實，我是覺得，今天有一個方法<br>
<br>
0:36:05.640,0:36:07.740<br>
它可以讓你輕易地理解<br>
<br>
0:36:07.740,0:36:10.260<br>
它為甚麼會下這樣子的判斷<br>
<br>
0:36:10.260,0:36:12.660<br>
為甚麼個方法會下這樣子的決策的話<br>
<br>
0:36:12.660,0:36:15.900<br>
那其實這個方法，你就會覺得它不夠 intelligent<br>
<br>
0:36:15.900,0:36:17.640<br>
因為你可以輕易地理解它<br>
<br>
0:36:17.640,0:36:20.340<br>
那今天如果它非常 intelligent 的話<br>
<br>
0:36:20.340,0:36:24.700<br>
它就必須要是你無法理解的東西<br>
<br>
0:36:24.700,0:36:28.520<br>
這樣，它才夠 intelligent，至少你會感覺它夠 intelligent<br>
<br>
0:36:28.520,0:36:31.760<br>
所以，大家常說 deep learning<br>
<br>
0:36:31.760,0:36:35.120<br>
就是一個黑盒子，你 learn 出來以後，你根本不知道<br>
<br>
0:36:35.120,0:36:36.620<br>
為甚麼是這樣子<br>
<br>
0:36:36.620,0:36:39.080<br>
但是，其實還是有很多方法可以分析的<br>
<br>
0:36:39.080,0:36:41.200<br>
比如說，今天這邊我們來示範一下<br>
<br>
0:36:41.200,0:36:43.840<br>
怎麼分析 CNN<br>
<br>
0:36:43.840,0:36:47.480<br>
它到底學到了甚麼<br>
<br>
0:36:47.480,0:36:51.300<br>
那我今天的例子，不一樣就是做在 MNIST 上面<br>
<br>
0:36:51.300,0:36:53.120<br>
那你其實可以在你的作業三<br>
<br>
0:36:53.160,0:36:56.940<br>
在 CIFAR-10 上面呢，複製看看<br>
(一個語料庫的名字)<br>
<br>
0:36:56.940,0:36:58.820<br>
你能不能看到類似的結果<br>
<br>
0:36:58.820,0:37:02.480<br>
那要分析第一個 input layer 的 filter 是比較不容易的<br>
<br>
0:37:02.480,0:37:04.400<br>
因為第一個 layer 裡面，每一個 filter<br>
<br>
0:37:04.400,0:37:06.940<br>
它就是一個 3*3 的 matrix<br>
<br>
0:37:06.940,0:37:10.680<br>
它對應到 3*3 的範圍內的 9 個 pixel<br>
<br>
0:37:10.680,0:37:14.060<br>
所以，你只要看這個 filter 的值，就可以知道說<br>
<br>
0:37:14.060,0:37:16.220<br>
它在 detect 甚麼東西<br>
<br>
0:37:16.220,0:37:18.900<br>
所以，第一層的 filter 是很容易理解的<br>
<br>
0:37:18.900,0:37:22.460<br>
但是，你比較沒有辦法想像它在做甚麼事情的<br>
<br>
0:37:22.460,0:37:23.900<br>
是第二層的 filter<br>
<br>
0:37:23.900,0:37:27.180<br>
在第二層，我們也是 3*3 的 filter，有 50 個<br>
<br>
0:37:27.180,0:37:31.440<br>
但是，這些 filter 的 input 並不是 pixel<br>
<br>
0:37:31.440,0:37:33.440<br>
這些 filter 的 9 個 input<br>
<br>
0:37:33.440,0:37:36.260<br>
它的 3*3 的 input 並不是 pixel<br>
<br>
0:37:36.260,0:37:40.000<br>
而是做完 convolution，再做 Max pooling 的結果<br>
<br>
0:37:40.000,0:37:44.560<br>
所以，這個 3*3 的 filter，你就算把它的 weight 拿出來<br>
<br>
0:37:44.560,0:37:47.620<br>
你也不知道它在做甚麼<br>
<br>
0:37:47.620,0:37:51.540<br>
另外這個 3*3 的 filter，它考慮的範圍並不是<br>
<br>
0:37:51.540,0:37:54.740<br>
3*3 個 pixel，並不是 9 個 pixel<br>
<br>
0:37:54.740,0:37:57.180<br>
而是比 9 個 pixel 更大的範圍<br>
<br>
0:37:57.180,0:37:58.380<br>
不要忘了它的 input<br>
<br>
0:37:58.380,0:38:00.380<br>
這 3*3 個 element 的 input<br>
<br>
0:38:00.380,0:38:04.540<br>
是做完 convolution 再加 Max pooling 的結果<br>
<br>
0:38:04.540,0:38:07.760<br>
所以，它實際上在 image 上看到的範圍<br>
<br>
0:38:07.760,0:38:09.720<br>
是比 3*3 還要更大的<br>
<br>
0:38:09.720,0:38:16.060<br>
那我們怎麼來分析一個 filter 它做的事情是甚麼呢？<br>
<br>
0:38:16.060,0:38:18.040<br>
以下，是一個方法<br>
<br>
0:38:18.040,0:38:19.940<br>
那你可以這樣做<br>
<br>
0:38:20.440,0:38:22.180<br>
我們知道說<br>
<br>
0:38:22.180,0:38:26.480<br>
現在在這 convolution layer 裡面的<br>
<br>
0:38:26.480,0:38:27.760<br>
50 個 filter<br>
<br>
0:38:27.760,0:38:30.300<br>
每一個 filter 的 output<br>
<br>
0:38:30.300,0:38:33.180<br>
就是一個 matrix，對不對？<br>
<br>
0:38:33.180,0:38:38.080<br>
每一個 filter 的 output 就是 11*11 的 matrix<br>
<br>
0:38:38.080,0:38:43.800<br>
假設，我們現在把第 k 個 filter 拿出來<br>
<br>
0:38:43.800,0:38:47.880<br>
我們把 input 一張 image 的第 k 個 output 拿出來<br>
<br>
0:38:47.880,0:38:52.060<br>
它可能長這樣子，是一個 11*11 的 matrix<br>
<br>
0:38:52.060,0:38:53.620<br>
那裡面每一個 element<br>
<br>
0:38:53.620,0:38:58.880<br>
我們就叫它 a上標 k，下標 i, j<br>
<br>
0:38:58.880,0:39:01.760<br>
上標 k 的意思是說，這是第 k 個 filter<br>
<br>
0:39:01.760,0:39:04.480<br>
i, j 代表說它在這個 matrix 裡面的<br>
<br>
0:39:04.480,0:39:06.780<br>
第 i 個 row，第 j個 column<br>
<br>
0:39:06.780,0:39:09.560<br>
接下來，我們訂一個東西叫做<br>
<br>
0:39:09.560,0:39:13.340<br>
Degree of activation of the k-th filter<br>
<br>
0:39:13.340,0:39:15.140<br>
我們訂一個值代表說<br>
<br>
0:39:15.140,0:39:17.880<br>
現在的第 k 個 filter<br>
<br>
0:39:17.880,0:39:22.060<br>
它有多被 activate、它有多被啟動<br>
<br>
0:39:22.060,0:39:26.260<br>
現在 input 的東西<br>
<br>
0:39:26.260,0:39:29.360<br>
跟第 k 個 activate 有多相近<br>
<br>
0:39:29.360,0:39:31.780<br>
有多 match<br>
<br>
0:39:31.780,0:39:36.060<br>
那這個第 k 個 filter 呢<br>
<br>
0:39:36.060,0:39:39.340<br>
第 k 個 filter，它被啟動的 degree 呢<br>
<br>
0:39:39.340,0:39:40.860<br>
我們這邊就定義成<br>
<br>
0:39:40.860,0:39:44.780<br>
它的 11*11 matrix 裡面的<br>
<br>
0:39:44.780,0:39:48.480<br>
這些全部 element 的 summation<br>
<br>
0:39:48.480,0:39:50.120<br>
這個 filter 呢<br>
<br>
0:39:50.120,0:39:52.100<br>
就我們 input 一張 image<br>
<br>
0:39:52.100,0:39:55.580<br>
然後，看這個 filter 它 output 的 11*11 個值<br>
<br>
0:39:55.580,0:39:56.800<br>
把它全部加起來<br>
<br>
0:39:56.800,0:40:01.120<br>
當作說，現在這個 filter 被 activate 的程度<br>
<br>
0:40:01.700,0:40:04.140<br>
接下來，我們要做的事情是這樣子<br>
<br>
0:40:04.140,0:40:05.720<br>
我們想要知道<br>
<br>
0:40:05.720,0:40:08.260<br>
這個第 k 個 filter 它的作用是甚麼<br>
<br>
0:40:08.260,0:40:10.920<br>
所以我們想要找一張 image<br>
<br>
0:40:10.920,0:40:14.580<br>
這一張 image 它可以讓第 k 個filter<br>
<br>
0:40:14.580,0:40:17.580<br>
被 activate 的程度最大<br>
<br>
0:40:17.580,0:40:19.280<br>
怎麼做到這件事情呢？<br>
<br>
0:40:19.280,0:40:23.260<br>
假設 input 的 image 我們稱之為 x<br>
<br>
0:40:23.260,0:40:26.240<br>
那我們現在要解的問題就是<br>
<br>
0:40:26.240,0:40:29.040<br>
找一個 x<br>
<br>
0:40:29.040,0:40:32.220<br>
它可以讓，現在我們定義的這個<br>
<br>
0:40:32.220,0:40:35.200<br>
activation 的 degree a, 上標 k<br>
<br>
0:40:35.200,0:40:38.960<br>
它可以讓我們定義的這個 activation 的 degree 最大<br>
<br>
0:40:38.960,0:40:40.940<br>
那這件事情要怎麼做到呢？<br>
<br>
0:40:40.940,0:40:43.040<br>
你其實就是用 gradient descent<br>
<br>
0:40:43.040,0:40:44.960<br>
因為我們現在要 maximize<br>
<br>
0:40:44.960,0:40:46.600<br>
如果是 minimize，你可以用 gradient descent<br>
<br>
0:40:46.600,0:40:48.580<br>
那 maximize，你用 gradient ascent<br>
<br>
0:40:48.580,0:40:51.240<br>
你就可以做到這件事了<br>
<br>
0:40:51.240,0:40:52.500<br>
就結束了<br>
<br>
0:40:52.500,0:40:54.560<br>
這樣大家聽得懂嗎？<br>
<br>
0:40:54.560,0:40:56.800<br>
我覺得還頗神妙<br>
<br>
0:40:56.800,0:41:01.960<br>
因為，我們現在是把 x 當作我們要找的參數<br>
<br>
0:41:01.960,0:41:05.880<br>
對它去用 gradient descent 或 gradient ascent<br>
<br>
0:41:05.880,0:41:07.560<br>
做 update<br>
<br>
0:41:07.560,0:41:09.440<br>
原來在 train 這個 CNN<br>
<br>
0:41:09.440,0:41:10.980<br>
在 train neural network 的時候<br>
<br>
0:41:10.980,0:41:12.500<br>
input 是固定的<br>
<br>
0:41:12.500,0:41:15.260<br>
那你的這個 model 的參數<br>
<br>
0:41:15.260,0:41:17.800<br>
是要用 gradient descent 去找出來的<br>
<br>
0:41:17.800,0:41:20.640<br>
用 gradient descent 找一組參數<br>
<br>
0:41:20.640,0:41:22.740<br>
可以讓你的 loss 可以被 minimize<br>
<br>
0:41:22.740,0:41:25.520<br>
但是，現在這個立場是被反過來的<br>
<br>
0:41:25.520,0:41:27.320<br>
現在，在這個 task 裡面呢<br>
<br>
0:41:27.320,0:41:29.360<br>
model 的參數是固定的<br>
<br>
0:41:29.360,0:41:33.000<br>
那我們要用這個 gradient descent 去 update 這個 x<br>
<br>
0:41:33.000,0:41:35.260<br>
或是，我們用 gradient ascent 去 update 這個 x<br>
<br>
0:41:35.260,0:41:39.420<br>
我們 update 這個 x，讓它可以讓這個<br>
<br>
0:41:39.420,0:41:42.260<br>
activation function 的這個 degree of activation<br>
<br>
0:41:42.260,0:41:43.540<br>
是最大的<br>
<br>
0:41:43.540,0:41:45.940<br>
這邊大家有問題嗎？<br>
<br>
0:41:45.940,0:41:49.120<br>
沒有哦，這個還滿神妙的<br>
<br>
0:41:49.120,0:41:52.240<br>
這個是得到的結果，如果我們<br>
<br>
0:41:52.240,0:41:56.280<br>
隨便取 12 個 filter 出來的話<br>
<br>
0:41:56.280,0:41:59.800<br>
那每一個 filter 呢，我們說我們對每一個 filter<br>
<br>
0:41:59.800,0:42:01.920<br>
都去找一張 image<br>
<br>
0:42:01.920,0:42:04.440<br>
這個 image 可以讓那個 filter<br>
<br>
0:42:04.440,0:42:05.920<br>
它的 activation 最大<br>
<br>
0:42:05.920,0:42:07.720<br>
那現在有 50 個 filter<br>
<br>
0:42:07.720,0:42:10.540<br>
所以，理論上可以找 50 張 image<br>
<br>
0:42:10.540,0:42:13.680<br>
它可以讓這些 filter 的 activation 最大<br>
<br>
0:42:13.680,0:42:17.800<br>
那我就隨便取了前 12 個 filter<br>
<br>
0:42:17.800,0:42:20.520<br>
可以讓它最 activate 的 image 出來<br>
<br>
0:42:20.520,0:42:23.180<br>
可以看它的結果長這樣子<br>
<br>
0:42:23.180,0:42:26.280<br>
那這些 image 它有一個共同的特徵就是<br>
<br>
0:42:26.280,0:42:29.340<br>
它是某種 texture<br>
<br>
0:42:29.340,0:42:31.340<br>
它是某種紋路<br>
<br>
0:42:31.340,0:42:33.920<br>
在圖上不斷地反覆<br>
<br>
0:42:33.920,0:42:36.520<br>
為甚麼呢？為甚麼會這樣呢<br>
<br>
0:42:36.520,0:42:39.600<br>
比如說，我們看看<br>
<br>
0:42:39.600,0:42:41.680<br>
這一張 image 好了<br>
<br>
0:42:41.680,0:42:44.520<br>
這一張 image 上面，第三張圖上面呢<br>
<br>
0:42:44.520,0:42:47.360<br>
它都是小小的斜條紋<br>
<br>
0:42:47.360,0:42:50.000<br>
這意味著甚麼事？這意味著<br>
<br>
0:42:50.000,0:42:52.900<br>
第三個 filter 它的工作就是 detect 圖上<br>
<br>
0:42:52.900,0:42:55.180<br>
有沒有斜的條紋<br>
<br>
0:42:55.180,0:42:57.660<br>
那不要忘了說，現在每一個 filter<br>
<br>
0:42:57.660,0:43:01.700<br>
其實它考慮的範圍，都是每一個圖上的<br>
<br>
0:43:01.700,0:43:03.160<br>
小小的範圍而已<br>
<br>
0:43:03.160,0:43:05.820<br>
所以，今天一個圖上如果出現一個<br>
<br>
0:43:05.820,0:43:08.680<br>
小小的，隨便一個斜的條紋的話<br>
<br>
0:43:08.680,0:43:10.960<br>
這一個 filter<br>
<br>
0:43:10.960,0:43:13.780<br>
就會被 activate，這個 filter output 的值<br>
<br>
0:43:13.780,0:43:16.520<br>
就會比較大、就會很大<br>
<br>
0:43:16.520,0:43:19.160<br>
如果，今天讓圖上<br>
<br>
0:43:19.160,0:43:22.740<br>
所有的範圍通通出現這個小小的斜條紋的話<br>
<br>
0:43:22.740,0:43:25.260<br>
那這個時候，它的 activation<br>
<br>
0:43:25.260,0:43:27.640<br>
它的 degree of activation 會是最大<br>
<br>
0:43:27.640,0:43:32.220<br>
因為它的工作就是，偵測有沒有一個斜的條紋<br>
<br>
0:43:32.220,0:43:35.160<br>
所以你給它一個完整的數字的時候，它不會最興奮<br>
<br>
0:43:35.160,0:43:38.620<br>
你給它通通都是斜的條紋的時候，這個時候它最興奮<br>
<br>
0:43:38.620,0:43:40.240<br>
雖然，它完全不是一個數字<br>
<br>
0:43:40.240,0:43:43.140<br>
所以，你就會發現說，每一個 filter 它的工作就是<br>
<br>
0:43:43.140,0:43:45.220<br>
detect 某一種 pattern<br>
<br>
0:43:45.220,0:43:47.400<br>
detect 某一種線條<br>
<br>
0:43:47.400,0:43:50.820<br>
比如說，第 3 個圖它 detect 斜的線條<br>
<br>
0:43:50.820,0:43:53.600<br>
第四個圖 detect 短的、直的線條<br>
<br>
0:43:53.600,0:43:57.300<br>
這個 detect 這個方向斜的線條<br>
<br>
0:43:57.300,0:43:59.520<br>
這個 detect 這個方向斜的線條<br>
<br>
0:43:59.520,0:44:01.320<br>
這個也是 detect 這個方向斜的線條<br>
<br>
0:44:01.320,0:44:03.440<br>
不過跟這個 degree 可能有點不一樣<br>
<br>
0:44:03.440,0:44:04.960<br>
它這個 degree 比較正，這個也是<br>
<br>
0:44:04.960,0:44:06.720<br>
detect 斜的線條，但是它比較平<br>
<br>
0:44:06.720,0:44:09.420<br>
這個 detect 是直的線條，等等<br>
<br>
0:44:09.420,0:44:11.760<br>
你會發現每一個 filter 做的事情<br>
<br>
0:44:11.760,0:44:15.100<br>
就是 detect 不同角度的線條<br>
<br>
0:44:15.100,0:44:17.320<br>
如果今天 input 有不同線條的話<br>
<br>
0:44:17.320,0:44:19.800<br>
你就會讓某一個 activation function<br>
<br>
0:44:19.800,0:44:23.380<br>
某一個 filter 它 output 的值最大<br>
<br>
0:44:27.480,0:44:30.080<br>
我們接下來可以分析這個<br>
<br>
0:44:30.080,0:44:31.700<br>
fully connected 的 layer<br>
<br>
0:44:31.700,0:44:35.820<br>
我們做完 convolution 和 Max pooling 以後呢<br>
<br>
0:44:35.820,0:44:38.440<br>
接下來，我們會做一件事情叫做 flatten<br>
<br>
0:44:38.440,0:44:40.200<br>
然後，把 flatten 以後的結果<br>
<br>
0:44:40.200,0:44:41.740<br>
丟到 neural network 裡面去<br>
<br>
0:44:41.740,0:44:45.060<br>
那我們也會想要知道說，在這個 neural network 裡面<br>
<br>
0:44:45.060,0:44:48.280<br>
每一個 neuron 它的工作是什麼<br>
<br>
0:44:48.280,0:44:50.740<br>
所以，我們就如法炮製剛才的作法<br>
<br>
0:44:50.740,0:44:52.520<br>
我們要做的事情是這樣子<br>
<br>
0:44:52.520,0:44:55.960<br>
我們定義第 j 個 neuron<br>
<br>
0:44:55.960,0:44:58.660<br>
它的 output 叫做 a_j<br>
<br>
0:44:59.020,0:45:00.800<br>
接下來，我們要做的事情就是<br>
<br>
0:45:00.800,0:45:02.260<br>
找一張 image x<br>
<br>
0:45:02.260,0:45:04.980<br>
用 gradient descent 的方法去找一張 image x<br>
<br>
0:45:04.980,0:45:08.620<br>
這個 image x，你把它丟到這個 neural network 裡面去<br>
<br>
0:45:08.620,0:45:12.140<br>
它可以讓 a_j 的值被 maximize<br>
<br>
0:45:12.140,0:45:13.880<br>
那找到甚麼樣的結果呢<br>
<br>
0:45:13.880,0:45:15.660<br>
我們找到的結果就是這樣<br>
<br>
0:45:15.660,0:45:19.620<br>
就是隨便取前 9 個 neuron 出來<br>
<br>
0:45:19.620,0:45:21.520<br>
隨便取 9 個 neuron 出來<br>
<br>
0:45:21.520,0:45:26.400<br>
那甚麼樣的圖丟到 CNN 裡面，可以讓這 9 個 neuron<br>
<br>
0:45:26.400,0:45:29.300<br>
最被 activate，output 的值最大呢？<br>
<br>
0:45:29.300,0:45:32.280<br>
就是這 9 張圖<br>
<br>
0:45:32.280,0:45:35.740<br>
你會發現說，跟剛才的<br>
<br>
0:45:35.740,0:45:38.460<br>
filter 所觀察到的情形，是很不一樣的<br>
<br>
0:45:38.460,0:45:40.820<br>
在剛才的 filter 裡面，我們觀察到的是<br>
<br>
0:45:40.820,0:45:43.160<br>
類似紋路的東西<br>
<br>
0:45:43.160,0:45:45.360<br>
在整張圖上，反覆同樣的紋路<br>
<br>
0:45:45.360,0:45:48.260<br>
那是因為每一個 filter，它考慮的只是一個<br>
<br>
0:45:48.260,0:45:51.360<br>
小小的 vision，圖上的一部份的 vision<br>
<br>
0:45:51.360,0:45:53.340<br>
所以，它 detect 是某一種 texture<br>
<br>
0:45:53.340,0:45:55.340<br>
但是，現在每一個 neuron<br>
<br>
0:45:55.340,0:45:58.020<br>
在你做 flatten 以後，每一個 neuron 它的工作<br>
<br>
0:45:58.020,0:46:00.040<br>
就是去看整張圖<br>
<br>
0:46:00.040,0:46:02.560<br>
它不再是只看整張圖的一小部分<br>
<br>
0:46:02.560,0:46:05.420<br>
它現在的工作是看整張圖<br>
<br>
0:46:05.420,0:46:09.720<br>
所以，每一個 neuron 你可以讓它最 activate 的圖<br>
<br>
0:46:09.720,0:46:13.840<br>
並不再是 texture 那個樣子，而是一個完整的圖形<br>
<br>
0:46:13.840,0:46:16.660<br>
而是一個完整的圖形，雖然它看起來完全<br>
<br>
0:46:16.660,0:46:19.520<br>
不像數字，比如說，這個看起來像是<br>
<br>
0:46:19.520,0:46:21.140<br>
千年眼這個樣子<br>
<br>
0:46:21.140,0:46:24.480<br>
算了，沒有人知道我在說甚麼<br>
<br>
0:46:25.480,0:46:29.980<br>
就是，某一個 neuron，像這個 neuron<br>
<br>
0:46:29.980,0:46:31.960<br>
這個會偵測千年眼的 neuron 呢<br>
<br>
0:46:31.960,0:46:33.460<br>
它的工作其實就是<br>
<br>
0:46:33.460,0:46:35.580<br>
看到這樣子的線條<br>
<br>
0:46:35.580,0:46:37.160<br>
或到這樣子的線條<br>
<br>
0:46:37.160,0:46:38.900<br>
或看到小小的圓圈<br>
<br>
0:46:38.900,0:46:40.480<br>
就可以讓它被 activate<br>
<br>
0:46:40.480,0:46:44.140<br>
所以，它偵測的也是一個完整的數字<br>
<br>
0:46:44.140,0:46:47.840<br>
是一個比較大的 pattern<br>
<br>
0:46:49.840,0:46:52.520<br>
接下來，我就會想要知道說<br>
<br>
0:46:52.520,0:46:54.600<br>
如果我們考慮的是 output 呢<br>
<br>
0:46:54.600,0:46:56.780<br>
如果我們今天考慮的是 output 呢<br>
<br>
0:46:56.780,0:46:59.920<br>
如果我們今天把，output 就是 10 維嘛<br>
<br>
0:46:59.920,0:47:01.820<br>
把每一維都對應到一個 digit<br>
<br>
0:47:01.820,0:47:05.760<br>
那我們把某一維拿出來<br>
<br>
0:47:05.760,0:47:07.820<br>
然後，我們說找一張 image<br>
<br>
0:47:07.820,0:47:10.800<br>
讓那一個維度的 output 最大<br>
<br>
0:47:10.800,0:47:13.000<br>
那我們會得到甚麼樣的 image 呢<br>
<br>
0:47:13.460,0:47:15.620<br>
你可以想像說，現在既然<br>
<br>
0:47:15.620,0:47:17.440<br>
每一個 output 的每一個 dimension<br>
<br>
0:47:17.440,0:47:19.920<br>
就對應到某一個數字<br>
<br>
0:47:19.920,0:47:23.740<br>
那我們現在如果把對應到數字 1 的那張圖<br>
<br>
0:47:23.740,0:47:26.300<br>
我們如果先找一張 image<br>
<br>
0:47:26.300,0:47:29.700<br>
它可以讓對應到數字 1 的那個 output layer 的 neuron<br>
<br>
0:47:29.700,0:47:31.820<br>
它的 output 最大<br>
<br>
0:47:31.820,0:47:35.300<br>
那一張 image 顯然看起來像是個數字 1<br>
<br>
0:47:35.300,0:47:37.420<br>
對不對，這樣大家了解我意思嗎？<br>
<br>
0:47:37.420,0:47:40.660<br>
你可以期待說，搞不好我們用這個方法就可以<br>
<br>
0:47:40.660,0:47:43.960<br>
讓 machine 自動畫出數字<br>
<br>
0:47:43.960,0:47:47.200<br>
但是，實際上我們得到的結果是這樣子<br>
<br>
0:47:47.200,0:47:49.200<br>
得出來的結果是這樣子<br>
<br>
0:47:49.200,0:47:51.320<br>
那這邊呢，每一張圖<br>
<br>
0:47:51.320,0:47:55.440<br>
分別代表數字 0, 1, 2 到 8<br>
<br>
0:47:55.440,0:47:58.520<br>
我就只畫了 9 個，實際上 output 有 10 個<br>
<br>
0:47:58.520,0:48:01.920<br>
我就只畫了 9 個，實際上 output 有 10 個<br>
<br>
0:48:01.920,0:48:05.700<br>
也就是說，我們找出來可以讓<br>
<br>
0:48:05.700,0:48:07.760<br>
對應到 0 的那個<br>
<br>
0:48:07.760,0:48:10.560<br>
output layer 裡面對應到 0 的那個 neuron<br>
<br>
0:48:10.560,0:48:14.400<br>
它的 output 最大的 image 其實是長這個樣子<br>
<br>
0:48:14.400,0:48:17.680<br>
可以讓 1 的 neuron output 最大的 image 其實是長這樣<br>
<br>
0:48:17.680,0:48:20.580<br>
2 的其實是長這樣，以此類推，每張看起來都差不多<br>
<br>
0:48:20.580,0:48:22.740<br>
都像是電視壞掉的樣子<br>
<br>
0:48:23.380,0:48:27.500<br>
你可就會有個疑惑，為甚麼會這樣<br>
<br>
0:48:27.500,0:48:29.660<br>
是不是程式有 bug<br>
<br>
0:48:29.660,0:48:32.760<br>
為了確定程式沒有 bug，所以我就再做了一個實驗是<br>
<br>
0:48:32.760,0:48:34.780<br>
我把這每一張 image<br>
<br>
0:48:34.780,0:48:37.640<br>
都真的丟到 CNN 裡面<br>
<br>
0:48:37.640,0:48:41.140<br>
然後，看說它 classify 的結果是什麼<br>
<br>
0:48:41.140,0:48:43.220<br>
那 CNN 確實就是說<br>
<br>
0:48:43.220,0:48:46.100<br>
它 classify 說這個是 0、這個是 1、這個是 2<br>
<br>
0:48:46.100,0:48:48.240<br>
一直到這個是 8，CNN 就覺得說<br>
<br>
0:48:48.240,0:48:49.880<br>
你如果拿這張 image<br>
<br>
0:48:49.880,0:48:53.640<br>
我們 train  出來的正確率有 98.2 給 CNN 看<br>
<br>
0:48:53.640,0:48:57.120<br>
它就會說，這個東西就叫做 8<br>
<br>
0:48:57.120,0:48:59.980<br>
所以，很神奇吧<br>
<br>
0:48:59.980,0:49:06.960<br>
所以，這個結果，其實已經在很多地方都被觀察到了<br>
<br>
0:49:06.960,0:49:10.760<br>
就是今天這個 neural network，它所學到的東西<br>
<br>
0:49:10.760,0:49:14.300<br>
跟我們人類是不太一樣的<br>
<br>
0:49:14.300,0:49:15.960<br>
那它所學到的東西<br>
<br>
0:49:15.960,0:49:19.620<br>
跟我們人類一般所想像認知是不一樣的<br>
<br>
0:49:19.620,0:49:24.120<br>
你可以看一下這段 video，那它也有對應的 paper<br>
<br>
0:49:24.120,0:49:27.140<br>
那裡面呢，machine 會把各種你看起來<br>
<br>
0:49:27.140,0:49:30.200<br>
不像企鵝的東西也是企鵝，<br>
看起來不像公車的東西也是公車<br>
<br>
0:49:30.520,0:49:33.060<br>
不然像我們這邊看起來，這完全不像一個數字<br>
<br>
0:49:33.060,0:49:36.660<br>
但對 machine 來說，它就是這個數字 8<br>
<br>
0:49:37.940,0:49:41.260<br>
所以，這個 machine 它學到的東西<br>
<br>
0:49:41.260,0:49:44.460<br>
和我們人類，是非常不一樣的<br>
<br>
0:49:45.780,0:49:49.420<br>
我們就想說，那這樣我們沒有辦法畫一個數字<br>
<br>
0:49:49.420,0:49:52.700<br>
所以我們要把這個數字，我們有沒有辦法<br>
<br>
0:49:52.700,0:49:57.480<br>
讓這個圖看起來更像數字呢？<br>
<br>
0:49:57.480,0:50:00.380<br>
所以，這邊的想法是這個樣子<br>
<br>
0:50:00.380,0:50:03.800<br>
因為，我們知道說<br>
<br>
0:50:03.800,0:50:06.360<br>
一張圖是不是一個數字，它有一些<br>
<br>
0:50:06.360,0:50:08.300<br>
基本的假設<br>
<br>
0:50:08.300,0:50:12.360<br>
比如說，這些東西就算是<br>
<br>
0:50:12.360,0:50:16.900<br>
你不知道它是甚麼數字，<br>
你也會知道說它顯然就不是一個 digit<br>
<br>
0:50:16.900,0:50:20.600<br>
人類手寫出來的東西，就不是長這個樣子<br>
<br>
0:50:20.600,0:50:25.940<br>
所以，我們應該對這個 y 做一些 Regularization<br>
<br>
0:50:25.940,0:50:28.640<br>
做一些 constraint，我們應該告訴 machine 說<br>
<br>
0:50:28.640,0:50:34.280<br>
說錯了，不是 y，我們應該對 x 做一些 constraint<br>
<br>
0:50:34.280,0:50:37.500<br>
我們應該對找出來的 x 做一些 constraint<br>
<br>
0:50:37.500,0:50:39.220<br>
我們應該告訴 machine 說<br>
<br>
0:50:39.220,0:50:43.200<br>
有一些 x，它雖然可以讓你的 y 很大<br>
<br>
0:50:43.200,0:50:45.900<br>
但是，它不是數字<br>
<br>
0:50:45.900,0:50:49.580<br>
我們天生、根據我們人的 required knowledge 就知道說<br>
<br>
0:50:49.580,0:50:52.580<br>
這些 x，它不可能是一個數字<br>
<br>
0:50:52.580,0:50:55.120<br>
那我們可以加上甚麼樣的 constraint 呢<br>
<br>
0:50:55.120,0:50:57.060<br>
比如說，最簡單的想法是說<br>
<br>
0:50:57.060,0:51:00.020<br>
今天這個圖上阿<br>
<br>
0:51:00.020,0:51:01.460<br>
白色的亮點<br>
<br>
0:51:01.460,0:51:05.820<br>
畫這個圖的時候，白色代表是有墨水的<br>
<br>
0:51:05.820,0:51:09.180<br>
有墨水就是有 ink、有筆畫的地方<br>
<br>
0:51:09.180,0:51:12.320<br>
是白色的，希望大家可以想像<br>
<br>
0:51:12.320,0:51:14.480<br>
對一個 digit 來說呢<br>
<br>
0:51:14.480,0:51:18.320<br>
塗白的部分，其實是有限的<br>
<br>
0:51:18.320,0:51:20.420<br>
塗白的部分不會太多<br>
<br>
0:51:20.420,0:51:23.980<br>
你整張圖都是白白的，它一定不是一個數字<br>
<br>
0:51:23.980,0:51:25.280<br>
那對數字來說<br>
<br>
0:51:25.280,0:51:28.480<br>
只有一整張圖的某一個小部分<br>
<br>
0:51:28.480,0:51:30.080<br>
會有筆畫<br>
<br>
0:51:30.080,0:51:34.000<br>
所以，我們應該要對這一個 x 做一些限制<br>
<br>
0:51:34.000,0:51:37.100<br>
對 x 做一些限制<br>
<br>
0:51:37.100,0:51:40.420<br>
比如說，這邊的限制是<br>
<br>
0:51:40.420,0:51:43.100<br>
我發現呢，我寫錯了<br>
<br>
0:51:43.100,0:51:45.020<br>
因為這邊是 max<br>
<br>
0:51:45.020,0:51:48.580<br>
所以，這邊這個加號應該是減號<br>
<br>
0:51:48.580,0:51:52.200<br>
不好意思，這邊加號應該是減號<br>
<br>
0:51:52.200,0:51:55.160<br>
因為我們這邊要做的事情是這樣子<br>
<br>
0:51:55.160,0:51:57.980<br>
假設這個 image 裡面的每一個 pixel<br>
<br>
0:51:57.980,0:52:00.160<br>
我們用 x_ij 來表示<br>
<br>
0:52:00.160,0:52:03.520<br>
所以，每一個 image 有 28*28 個 pixel<br>
<br>
0:52:03.520,0:52:06.300<br>
i 就是 1~28，j 就是 1~28<br>
<br>
0:52:06.300,0:52:11.120<br>
我們把所有的 pixel 的值<br>
<br>
0:52:11.120,0:52:16.060<br>
我們把所有今天 image 上面的 x_ij 的值呢<br>
<br>
0:52:16.060,0:52:20.840<br>
取絕對值加起來，如果你熟悉 machine learning 的話呢<br>
<br>
0:52:20.840,0:52:24.580<br>
這一項就是 L1 的 Regularization<br>
<br>
0:52:24.580,0:52:27.260<br>
那我們把這個 pixel 的值<br>
<br>
0:52:27.260,0:52:30.640<br>
全部加起來<br>
<br>
0:52:30.640,0:52:34.300<br>
然後，我們希望說，我們再找一個 x<br>
<br>
0:52:34.300,0:52:36.860<br>
它可以讓 y_i 最大的同時<br>
<br>
0:52:36.860,0:52:39.620<br>
這邊其實應該要是減號<br>
<br>
0:52:39.620,0:52:43.800<br>
它同時應該要讓 x_ij 的 summation<br>
<br>
0:52:43.940,0:52:45.440<br>
越小越好<br>
<br>
0:52:45.440,0:52:47.400<br>
也就是說，我們希望找出來的 image<br>
<br>
0:52:47.400,0:52:50.420<br>
大部分的地方，是沒有塗顏色的<br>
<br>
0:52:50.420,0:52:52.140<br>
沒有塗白色的、沒有筆畫的<br>
<br>
0:52:52.140,0:52:53.980<br>
只有非常少的地方<br>
<br>
0:52:53.980,0:52:55.660<br>
是有塗筆畫的<br>
<br>
0:52:55.660,0:52:58.220<br>
那如果我們加上這個 constraint 以後呢<br>
<br>
0:52:58.220,0:53:01.880<br>
我們得到的結果看起來就像是這樣<br>
<br>
0:53:01.880,0:53:04.420<br>
其實，跟左邊的圖比起來呢<br>
<br>
0:53:04.420,0:53:08.240<br>
你已經有些隱約可以看出來<br>
<br>
0:53:08.240,0:53:10.760<br>
它是一個數字，比如說<br>
<br>
0:53:10.760,0:53:14.040<br>
這個就有一點點像 6<br>
<br>
0:53:14.040,0:53:17.820<br>
雖然說，它這邊還多了一條，但它有一點點像 6<br>
<br>
0:53:17.820,0:53:20.400<br>
這個，有一點點像 8<br>
<br>
0:53:20.400,0:53:25.540<br>
這個，它好像找到了 5 的第一個筆劃<br>
<br>
0:53:25.540,0:53:28.060<br>
這個好像找到了 7 的第一個筆劃<br>
<br>
0:53:28.060,0:53:31.160<br>
等等，所以你加上了這些 constraint 以後呢<br>
<br>
0:53:31.160,0:53:34.700<br>
你看起來得到的結果<br>
<br>
0:53:34.700,0:53:36.280<br>
就比較像數字了<br>
<br>
0:53:36.280,0:53:38.480<br>
講到這邊，你可能會問一個問題<br>
<br>
0:53:38.480,0:53:42.440<br>
首先，我們還沒有講過 L1 的 Regularization<br>
<br>
0:53:42.440,0:53:44.000<br>
但是，我們等一下會講<br>
<br>
0:53:44.000,0:53:47.040<br>
再來你可能會有另外一個問題，這個有絕對值阿<br>
<br>
0:53:47.040,0:53:49.520<br>
怎麼微分，其實這個是可以微分的啦<br>
<br>
0:53:49.520,0:53:52.440<br>
這個我們下一堂課會講到<br>
<br>
0:53:52.440,0:53:54.980<br>
講到這邊，大家有沒有甚麼問題呢？<br>
<br>
0:53:58.120,0:54:02.260<br>
其實，我覺得說如果你再加上一些額外的 constraint<br>
<br>
0:54:02.260,0:54:06.300<br>
比如說，你希望相鄰的 pixel 是同樣的顏色等等<br>
<br>
0:54:06.300,0:54:08.860<br>
你應該可以得到更好的結果<br>
<br>
0:54:08.860,0:54:11.840<br>
不過，其實有更多很好的方法可以<br>
<br>
0:54:11.840,0:54:13.600<br>
讓我們自動去 generate<br>
<br>
0:54:13.600,0:54:15.780<br>
數字，或是 generate 它看到的東西<br>
<br>
0:54:15.780,0:54:18.560<br>
所以，這邊我就沒有興致再把它做得更好<br>
<br>
0:54:18.800,0:54:22.240<br>
其實，這個東西、這個想法<br>
<br>
0:54:22.240,0:54:25.400<br>
就是 Deep Dream 的精神<br>
<br>
0:54:25.400,0:54:27.540<br>
不知道大家知不知道 Deep Dream 是甚麼呢？<br>
<br>
0:54:27.540,0:54:31.060<br>
Deep Dream 是說，如果你給 machine 一張 image<br>
<br>
0:54:31.060,0:54:35.480<br>
它會在這個 image 裡面，加上它看到的東西<br>
<br>
0:54:36.500,0:54:38.520<br>
怎麼做這件事情呢<br>
<br>
0:54:38.520,0:54:40.360<br>
擬就找一張 image<br>
<br>
0:54:40.360,0:54:44.880<br>
這個是我，後面這個不是 photoshop 上去的<br>
<br>
0:54:45.600,0:54:48.120<br>
然後，這邊我擺了一個很做作的姿勢<br>
<br>
0:54:48.120,0:54:52.420<br>
然後，你把這張相片丟到 CNN 裡面去<br>
<br>
0:54:53.160,0:54:56.420<br>
然後，你把它的某一個 hidden layer<br>
<br>
0:54:56.420,0:54:59.480<br>
你把某一個 layer 裡面的<br>
<br>
0:54:59.480,0:55:02.440<br>
filter，或是 fully connected layer 裡面<br>
<br>
0:55:02.440,0:55:04.540<br>
的某一個 hidden layer 拿出來<br>
<br>
0:55:04.540,0:55:06.520<br>
那它其實是一個 vector<br>
<br>
0:55:06.520,0:55:08.820<br>
你把某一個 hidden layer 拿出來<br>
<br>
0:55:08.820,0:55:11.700<br>
它其實是一個 vector，假設它這邊是<br>
<br>
0:55:11.700,0:55:14.200<br>
比如說，3.9、-1.5、2.3<br>
<br>
0:55:14.200,0:55:16.800<br>
接下來呢，你把<br>
<br>
0:55:16.800,0:55:19.680<br>
這個 filter 的值調大<br>
<br>
0:55:19.680,0:55:24.500<br>
你把本來是 positive 的 dimension 值調大<br>
<br>
0:55:24.500,0:55:26.320<br>
把 positive 的 dimension 值調大<br>
<br>
0:55:26.320,0:55:28.940<br>
negative 的 dimension 值調小<br>
<br>
0:55:28.940,0:55:32.680<br>
然後，你本來就是正的讓它更正<br>
<br>
0:55:32.680,0:55:33.880<br>
負的讓它更負<br>
<br>
0:55:33.880,0:55:37.140<br>
你把這個東西，當作是<br>
<br>
0:55:37.140,0:55:40.260<br>
新的 image 的目標<br>
<br>
0:55:40.260,0:55:42.080<br>
了解我意思嗎？就是<br>
<br>
0:55:42.080,0:55:45.700<br>
你把這個 3.9 的值變大<br>
<br>
0:55:45.700,0:55:47.420<br>
你把 -1.5 的值變得更負<br>
<br>
0:55:47.420,0:55:50.220<br>
你把 2.3 的值變得更大<br>
<br>
0:55:50.220,0:55:53.500<br>
然後，你找一張 image<br>
<br>
0:55:53.500,0:55:54.860<br>
用 gradient descent 的方法<br>
<br>
0:55:54.860,0:55:56.900<br>
讓它在這個 hidden layer 的 output<br>
<br>
0:55:56.900,0:56:00.120<br>
是你現在設下的 target<br>
<br>
0:56:00.680,0:56:02.780<br>
這樣大家聽得懂嗎？<br>
<br>
0:56:02.780,0:56:04.700<br>
你如果這麼做的話<br>
<br>
0:56:04.700,0:56:07.480<br>
你如果這麼做的話，意思就是說<br>
<br>
0:56:07.480,0:56:11.860<br>
讓 CNN 誇大化它看到的東西<br>
<br>
0:56:11.860,0:56:14.040<br>
它本來已經有看到<br>
<br>
0:56:14.040,0:56:15.660<br>
某一個東西了<br>
<br>
0:56:15.660,0:56:20.100<br>
你讓它看起來更像原來看到的東西<br>
<br>
0:56:20.100,0:56:22.640<br>
你讓它本來看起來是有一點像<br>
<br>
0:56:22.640,0:56:25.660<br>
某一個東西，它讓某一個 filter 呢<br>
<br>
0:56:25.660,0:56:29.220<br>
有被 activate，但你讓它被 activate 的更劇烈<br>
<br>
0:56:29.220,0:56:32.860<br>
就是你讓 CNN 誇大化它現在看到的東西<br>
<br>
0:56:32.860,0:56:35.340<br>
那如果你把這一張 image<br>
<br>
0:56:35.340,0:56:37.260<br>
拿去做 Deep Dream 的話<br>
<br>
0:56:37.260,0:56:40.100<br>
你看到的結果，就會是這樣子<br>
<br>
0:56:40.100,0:56:43.420<br>
背後出現很多念獸，要凝才看的到這樣<br>
<br>
0:56:45.080,0:56:47.520<br>
就是有很多念獸這樣<br>
<br>
0:56:47.520,0:56:49.540<br>
比如說，像這邊<br>
<br>
0:56:49.540,0:56:51.800<br>
這邊有一隻熊<br>
<br>
0:56:51.800,0:56:54.580<br>
你看這個熊，它原來是一個石頭<br>
<br>
0:56:54.580,0:56:57.620<br>
它原來是一個石頭，那你不覺得它這個石頭<br>
<br>
0:56:57.620,0:57:00.180<br>
哇！看起來其實也是有點像熊的嗎？<br>
<br>
0:57:00.180,0:57:03.700<br>
這個是耳朵，這個是眼睛、這個是鼻子<br>
<br>
0:57:03.700,0:57:06.540<br>
那對機器來說，它在看這張圖的時候<br>
<br>
0:57:06.540,0:57:09.100<br>
它本來就覺得，這個有點像熊<br>
<br>
0:57:09.100,0:57:11.500<br>
那你就更強化這件事<br>
<br>
0:57:11.500,0:57:15.420<br>
所，它看起來就真的變成了一隻熊<br>
<br>
0:57:15.980,0:57:18.160<br>
這個是 Deep Dream<br>
<br>
0:57:18.160,0:57:20.380<br>
那 Deep Dream 還有一個進階的版本<br>
<br>
0:57:20.380,0:57:24.020<br>
這個叫做 Deep Style<br>
<br>
0:57:24.020,0:57:26.980<br>
Deep Style 是讓，今天你 input 一張 image<br>
<br>
0:57:26.980,0:57:31.480<br>
你 input 一張相片，然後讓 machine 去修改這張圖<br>
<br>
0:57:31.480,0:57:35.500<br>
讓它有另外一張圖的風格<br>
<br>
0:57:35.500,0:57:38.440<br>
比如說，讓這個相片，看起來像是吶喊<br>
<br>
0:57:38.440,0:57:40.340<br>
那得到的結果就是這樣子<br>
<br>
0:57:40.340,0:57:43.060<br>
這畫的還滿好的<br>
<br>
0:57:43.060,0:57:45.260<br>
這驚人的好<br>
<br>
0:57:45.260,0:57:47.780<br>
那這個東西，是怎麼做的呢<br>
<br>
0:57:47.780,0:57:51.220<br>
這邊就不細講，就列一個 reference 給大家參考<br>
<br>
0:57:51.220,0:57:55.080<br>
那它這個做的精神是這樣子<br>
<br>
0:57:55.080,0:57:58.660<br>
你給它、把原來的 image<br>
<br>
0:57:58.660,0:58:03.020<br>
丟給 CNN，然後得到 CNN 的 filter 的 output<br>
<br>
0:58:03.320,0:58:05.480<br>
CNN 的 filter 的 output<br>
<br>
0:58:05.480,0:58:09.500<br>
代表這一張 image 裡面有甚麼樣的 content<br>
<br>
0:58:10.320,0:58:13.440<br>
然後，接下來你把吶喊這張圖<br>
<br>
0:58:13.440,0:58:15.120<br>
也丟到 CNN 裡面<br>
<br>
0:58:15.120,0:58:18.100<br>
也得到 filter 的 output<br>
<br>
0:58:18.100,0:58:20.540<br>
但是，這個時候我們考慮的不是<br>
<br>
0:58:20.540,0:58:24.060<br>
filter output 的 absolute 的 value<br>
<br>
0:58:24.060,0:58:26.940<br>
我們並不在意一個 filter output 的 value 是什麼<br>
<br>
0:58:26.940,0:58:31.180<br>
而是在意 filter 和 filter 之間 output 的 correlation<br>
<br>
0:58:31.180,0:58:36.320<br>
那這個 correlation 代表了一張 image 的 style<br>
<br>
0:58:36.320,0:58:39.860<br>
接下來，你就用同個 CNN<br>
<br>
0:58:39.860,0:58:42.540<br>
找一張 image，這張 image 呢<br>
<br>
0:58:42.540,0:58:45.660<br>
它的 content 像左邊這張相片<br>
<br>
0:58:45.660,0:58:48.500<br>
比如說，這張 image 它的 filter output 的 value<br>
<br>
0:58:48.500,0:58:50.340<br>
像左邊這張相片<br>
<br>
0:58:50.340,0:58:53.640<br>
同時呢，這張 image 的 style<br>
<br>
0:58:53.640,0:58:55.140<br>
像右邊這張相片<br>
<br>
0:58:55.140,0:58:57.380<br>
所謂的 style 像右邊這張相片是<br>
<br>
0:58:57.380,0:59:00.940<br>
你這個 image output 的 filter 間的 correlation<br>
<br>
0:59:00.940,0:59:02.780<br>
像右邊這張相片<br>
<br>
0:59:02.780,0:59:05.720<br>
那你找一張 image，同時可以<br>
<br>
0:59:05.720,0:59:08.680<br>
maximize 左邊這個東西，<br>
也可以 maximize 右邊這個東西<br>
<br>
0:59:08.680,0:59:11.860<br>
那你得到的結果，就是像這樣子的一個圖<br>
<br>
0:59:11.860,0:59:15.860<br>
那你用的就是，我們剛才講的 gradient descent 的方法<br>
<br>
0:59:15.860,0:59:17.360<br>
找一張 image<br>
<br>
0:59:17.360,0:59:20.120<br>
maximize 這兩個 criteria 的結果，就是左邊這個圖<br>
<br>
0:59:21.660,0:59:26.640<br>
那我們現在知道說，CNN 可以被應用在很多不同的<br>
<br>
0:59:26.640,0:59:30.100<br>
應用上，不是只有影像處理<br>
<br>
0:59:30.100,0:59:32.760<br>
比如說，CNN 現在有一個非常<br>
<br>
0:59:32.760,0:59:36.800<br>
知名的應用，就是用在下圍棋上面<br>
<br>
0:59:37.580,0:59:41.500<br>
為甚麼 CNN 可以用在下圍棋上面呢<br>
<br>
0:59:42.000,0:59:45.200<br>
我們知道說，你要讓<br>
<br>
0:59:45.200,0:59:48.840<br>
machine 來下圍棋，你不見得要用 CNN<br>
<br>
0:59:48.840,0:59:50.980<br>
其實，一般 typical 的 neural network<br>
<br>
0:59:50.980,0:59:53.100<br>
也可以幫我們做到這件事情<br>
<br>
0:59:53.100,0:59:56.360<br>
你只要 learn 一個 network，也就是找一個 function<br>
<br>
0:59:56.360,1:00:02.420<br>
它的 input 是棋盤，output 是棋盤上的位置<br>
<br>
1:00:02.420,1:00:06.280<br>
也就是說，你下一步根據這個棋盤的盤勢<br>
<br>
1:00:06.280,1:00:08.160<br>
如果你下一步要落子的話<br>
<br>
1:00:08.160,1:00:09.600<br>
你應該落子的位置<br>
<br>
1:00:09.600,1:00:12.560<br>
你其實就可以讓 machine 學會下圍棋了<br>
<br>
1:00:13.120,1:00:16.800<br>
所以，你其實用 fully connected 的 feedforward network<br>
<br>
1:00:16.800,1:00:20.380<br>
也可以幫我們做到讓 machine 下圍棋這件事情<br>
<br>
1:00:20.380,1:00:22.820<br>
也就是說，你只要認知告訴它說 input<br>
<br>
1:00:22.820,1:00:24.740<br>
是一個 19*19 的 vector<br>
<br>
1:00:24.740,1:00:28.100<br>
vector 的每一個 dimension 對應到<br>
<br>
1:00:28.100,1:00:30.420<br>
棋盤上的某一個位置<br>
<br>
1:00:30.420,1:00:33.160<br>
如果那一個位置有一個黑子的話，就是 1<br>
<br>
1:00:33.160,1:00:35.800<br>
如果有一個白子的話，就是 -1<br>
<br>
1:00:35.800,1:00:37.760<br>
反之呢，就是 0<br>
<br>
1:00:37.760,1:00:41.360<br>
如果你把棋盤描述成一個 19*19 的 vector<br>
<br>
1:00:41.360,1:00:43.960<br>
丟到一個 fully connected 的 feedforward network<br>
<br>
1:00:43.960,1:00:46.140<br>
output 也是 19*19 個 dimension<br>
<br>
1:00:46.140,1:00:49.720<br>
每一個 dimension 對應到棋盤上的一個位置<br>
<br>
1:00:49.720,1:00:53.180<br>
那 machine 就可以學會下圍棋了<br>
<br>
1:00:55.160,1:00:58.580<br>
但是，實際上如果我們今天在這邊採用<br>
<br>
1:00:58.580,1:01:00.040<br>
CNN 的話<br>
<br>
1:01:00.040,1:01:01.740<br>
我們會得到更好的 performance<br>
<br>
1:01:01.740,1:01:04.420<br>
採用 CNN 是甚麼意思呢？<br>
<br>
1:01:04.420,1:01:09.140<br>
我們之前舉的例子都是把 CNN 用在影像上面<br>
<br>
1:01:09.140,1:01:12.220<br>
也就是 input 是一個 matrix<br>
<br>
1:01:12.220,1:01:15.540<br>
所以，現在你其實只要把 19*19 的 vector<br>
<br>
1:01:15.540,1:01:19.300<br>
表示成一個 19*19 的 matrix<br>
<br>
1:01:19.300,1:01:22.780<br>
一個棋盤可以很自然地表示成一個 19*19 的 matrix<br>
<br>
1:01:22.780,1:01:26.680<br>
對 CNN 來說，就是把它當成一個 image 來看<br>
<br>
1:01:26.680,1:01:30.240<br>
然後，再讓它 output 下一步要落子的位置<br>
<br>
1:01:30.240,1:01:33.380<br>
就結束了<br>
<br>
1:01:33.380,1:01:35.520<br>
那它 training 的 process 呢<br>
<br>
1:01:35.520,1:01:36.660<br>
是這個樣子的<br>
<br>
1:01:37.480,1:01:41.780<br>
這個我們講過，你就蒐集很多棋譜<br>
<br>
1:01:41.780,1:01:44.300<br>
比如說這個是進藤光和社青春的棋譜<br>
<br>
1:01:44.300,1:01:48.740<br>
初手下在 5 之五，然後再下在天元，再下在 5 之五<br>
<br>
1:01:48.740,1:01:51.620<br>
接下來，你就告訴 machine 說，看到落子在 5 之五<br>
<br>
1:01:51.620,1:01:55.620<br>
CNN 的 output 就是天元的地方是 1，其他的 output 是 0<br>
<br>
1:01:55.620,1:01:58.920<br>
看到 5 之五和天元都有子<br>
<br>
1:01:58.920,1:02:01.860<br>
那你的 output 就是 5 之五的地方是 1<br>
<br>
1:02:01.860,1:02:04.060<br>
其他都是 0，這個是<br>
<br>
1:02:04.060,1:02:06.640<br>
supervised 的部分，那其實呢<br>
<br>
1:02:06.640,1:02:10.280<br>
AlphaGo 還有 reinforcement learning 的部分<br>
<br>
1:02:10.280,1:02:12.640<br>
那這個我們就之後再講<br>
<br>
1:02:12.640,1:02:15.280<br>
我們知道說，大家都是<br>
<br>
1:02:15.280,1:02:18.080<br>
大家都說得一口 AlphaGo 啦<br>
<br>
1:02:18.080,1:02:19.560<br>
大家都是懂懂懂這樣子<br>
<br>
1:02:21.620,1:02:24.480<br>
自從 AlphaGo 用了 CNN 以後<br>
<br>
1:02:24.480,1:02:27.480<br>
大家都覺得說，好像 CNN 應該很厲害<br>
<br>
1:02:27.480,1:02:30.500<br>
所以有時候，如果你沒有用 CNN 來處理你的問題<br>
<br>
1:02:30.500,1:02:32.600<br>
人家就會問你說，比如你去面試的時候<br>
<br>
1:02:32.600,1:02:35.100<br>
你的碩士論文裡面沒有用 CNN 來處理問題<br>
<br>
1:02:35.100,1:02:36.940<br>
口試的人可能不知道 CNN 是甚麼<br>
<br>
1:02:36.940,1:02:38.640<br>
但是，他就會問你說為什麼不用 CNN 呢<br>
<br>
1:02:38.640,1:02:40.160<br>
CN N 不是比較強嗎？<br>
<br>
1:02:40.160,1:02:42.240<br>
這個時候你就可以嗆爆他這樣子<br>
<br>
1:02:42.700,1:02:44.960<br>
甚麼時候我們可以用 CNN 呢<br>
<br>
1:02:44.960,1:02:49.020<br>
你要有 image 該有的那些特性<br>
<br>
1:02:49.020,1:02:51.780<br>
我們之前在講 CNN 開頭的時候，我們有說，根據<br>
<br>
1:02:51.780,1:02:57.040<br>
3 個觀察，所以我們設計出了 CNN 這樣的 network 架構<br>
<br>
1:02:57.040,1:02:59.440<br>
它在處理 image 的時候<br>
<br>
1:02:59.440,1:03:01.320<br>
是特別有效的<br>
<br>
1:03:01.320,1:03:04.700<br>
那為甚麼這樣子的架構，也同時可以用在<br>
<br>
1:03:04.700,1:03:05.880<br>
圍棋上面呢<br>
<br>
1:03:05.880,1:03:10.220<br>
那是因為圍棋有一些特性，和影像處理是很相似的<br>
<br>
1:03:10.540,1:03:12.080<br>
第一個是<br>
<br>
1:03:12.080,1:03:16.960<br>
我們說，在 image 上面<br>
<br>
1:03:16.960,1:03:21.400<br>
有一些 pattern 是比整張 image 還要小的多<br>
<br>
1:03:21.400,1:03:25.460<br>
比如說，鳥的喙是比整張 image 還要小的多<br>
<br>
1:03:25.460,1:03:28.240<br>
但是，你只要看到一小個部分，你就會知道說<br>
<br>
1:03:28.240,1:03:29.460<br>
它是不是鳥的喙<br>
<br>
1:03:29.460,1:03:32.840<br>
在圍棋上，可能也有同樣的現象<br>
<br>
1:03:32.840,1:03:34.420<br>
我對圍棋知道得很少<br>
<br>
1:03:34.420,1:03:38.220<br>
知道的知識都沒有超過棋靈王所教我的範圍<br>
<br>
1:03:38.220,1:03:42.320<br>
但是我也知道說，比如說，這個東西、一個白子<br>
<br>
1:03:42.320,1:03:45.540<br>
被 3 個黑子圍住，這個叫做叫吃<br>
<br>
1:03:45.540,1:03:49.080<br>
如果黑子現在落在這邊，就可以把白子提走<br>
<br>
1:03:49.080,1:03:51.860<br>
那白子要接在這邊，才不會被提走<br>
<br>
1:03:51.860,1:03:54.960<br>
總之，這個是一個 pattern，你看到這個 pattern 應該會<br>
<br>
1:03:54.960,1:03:57.860<br>
做一些應收，做一些相應的事情<br>
<br>
1:03:57.860,1:04:00.760<br>
比如說，你會落子在這個地方<br>
<br>
1:04:02.200,1:04:06.180<br>
那現在你只需要看這個小小的範圍<br>
<br>
1:04:06.180,1:04:09.760<br>
你就可以偵測說，這個白子是不是屬於被叫吃的狀態<br>
<br>
1:04:09.760,1:04:13.620<br>
你不需要看整個棋盤，才知道這件事情<br>
<br>
1:04:13.620,1:04:17.580<br>
所以，這件事情跟 image 是有同樣的性質<br>
<br>
1:04:17.580,1:04:21.180<br>
那在 AlphaGo 裡面，它第一個 layer 的 filter<br>
<br>
1:04:21.180,1:04:24.880<br>
其實就是用 5*5 的 filter<br>
<br>
1:04:24.880,1:04:30.060<br>
顯然做這個設計的人，覺得圍棋上最基本的 pattern<br>
<br>
1:04:30.060,1:04:32.440<br>
可能都是在 5*5 的範圍內<br>
<br>
1:04:32.440,1:04:34.060<br>
就可以被偵測出來<br>
<br>
1:04:34.060,1:04:36.100<br>
並不需要看整個棋盤<br>
<br>
1:04:36.100,1:04:37.640<br>
才能夠知道這件事情<br>
<br>
1:04:39.320,1:04:43.380<br>
接下來，我們說 image 還有一個特性是，同樣的 pattern<br>
<br>
1:04:43.380,1:04:48.420<br>
會出現在不同的 region，而它們代表的是同樣的意義<br>
<br>
1:04:48.420,1:04:51.340<br>
在圍棋上，也可能有同樣的現象<br>
<br>
1:04:51.340,1:04:56.080<br>
像這個叫吃的 pattern，它可以出現在棋盤的左上角<br>
<br>
1:04:56.080,1:04:58.320<br>
也可以出現在右下角<br>
<br>
1:04:58.320,1:05:01.320<br>
它們都是叫吃，它們都代表了同樣的意義<br>
<br>
1:05:01.320,1:05:03.740<br>
這些同樣的 pattern，出現在不同的位置<br>
<br>
1:05:03.740,1:05:05.580<br>
它們也都代表同樣的意義<br>
<br>
1:05:05.580,1:05:07.600<br>
所以，你可以用同一個 detector<br>
<br>
1:05:07.600,1:05:11.340<br>
來處理這些在不同位置的同樣的 pattern<br>
<br>
1:05:11.340,1:05:13.060<br>
所以，對圍棋來說呢<br>
<br>
1:05:13.060,1:05:16.120<br>
它在第一個 observation 和第二個 observation<br>
<br>
1:05:16.120,1:05:18.400<br>
是有這個 image 的特性的<br>
<br>
1:05:18.400,1:05:22.120<br>
但是，讓我沒有辦法相通的地方，就是第三點<br>
<br>
1:05:22.580,1:05:25.780<br>
我們說，我們可以對一個 image<br>
<br>
1:05:25.780,1:05:29.040<br>
做 subsampling，你拿掉奇數行、偶數列的 pixel<br>
<br>
1:05:29.040,1:05:31.900<br>
把 image 變成原來的 1/4 的大小<br>
<br>
1:05:31.900,1:05:36.640<br>
但是，也不會影響你看這張圖的樣子<br>
<br>
1:05:36.640,1:05:40.660<br>
但是，因為基於這個觀察，所以<br>
<br>
1:05:40.660,1:05:42.280<br>
有 Max pooling 這個 layer<br>
<br>
1:05:43.380,1:05:45.540<br>
但是，對圍棋來說<br>
<br>
1:05:45.540,1:05:47.700<br>
你可以做這件事情嗎？<br>
<br>
1:05:47.700,1:05:51.460<br>
比如說，你可以對一個棋盤丟掉奇數行和偶數列<br>
<br>
1:05:51.460,1:05:53.320<br>
它還是同一個函式嗎？<br>
<br>
1:05:53.320,1:05:54.480<br>
顯然是不是的<br>
<br>
1:05:54.480,1:05:57.060<br>
就算我對圍棋甚麼都不懂，我也覺得說<br>
<br>
1:05:57.060,1:06:01.380<br>
這顯然不 work，那這件事就讓我相當地困擾<br>
<br>
1:06:01.380,1:06:03.860<br>
那我看網路上一些文章，有一些人覺得說<br>
<br>
1:06:03.860,1:06:07.860<br>
因為 AlphaGo 裡面可能有用了 Max pooling 這樣的架構<br>
<br>
1:06:07.860,1:06:10.420<br>
它是用 CNN ，所以裡面可能有 Max pooling 這樣的架構<br>
<br>
1:06:10.420,1:06:12.140<br>
所以，或許這是一個<br>
<br>
1:06:12.140,1:06:14.740<br>
它的弱點<br>
<br>
1:06:14.740,1:06:17.960<br>
你要針對這個弱點取攻擊它，就可以擊敗它<br>
<br>
1:06:17.960,1:06:20.800<br>
但是，AlphaGo 很強，它可能比李世乭還強<br>
<br>
1:06:20.800,1:06:23.340<br>
它可能比高永夏還強了，所以<br>
<br>
1:06:23.340,1:06:26.240<br>
它顯然沒有這個顯而易見的弱點了<br>
<br>
1:06:26.240,1:06:29.760<br>
它顯然沒有這個顯而易見的弱點了，所以<br>
<br>
1:06:29.760,1:06:32.960<br>
到底是怎麼回事呢，我就覺得相當地困惑<br>
<br>
1:06:33.340,1:06:36.000<br>
有一天，我突然領悟到<br>
<br>
1:06:36.000,1:06:40.060<br>
會不會在這個 AlphaGo 的 CNN 裡面<br>
<br>
1:06:40.060,1:06:41.780<br>
有甚麼特別的地方呢<br>
<br>
1:06:41.780,1:06:44.480<br>
我相信說，大家都讀過 AlphaGo 的 paper<br>
<br>
1:06:44.480,1:06:49.140<br>
這個 paper 也沒幾頁，好像就 6 頁吧，一下就看完了<br>
<br>
1:06:49.140,1:06:51.220<br>
但是，它後面有一個很長的附錄<br>
<br>
1:06:51.220,1:06:52.860<br>
那我們一般都是不看附錄的<br>
<br>
1:06:56.780,1:06:59.760<br>
它的 paper 裡面，從來沒有<br>
<br>
1:06:59.760,1:07:02.320<br>
它只說了一句說，它用 CNN<br>
<br>
1:07:02.320,1:07:06.560<br>
它沒有在正文裡面，仔細地描述它 CNN 的架構<br>
<br>
1:07:06.560,1:07:09.520<br>
會不會實際上它 CNN 的架構裡面有甚麼<br>
<br>
1:07:09.520,1:07:11.080<br>
特別的玄機呢<br>
<br>
1:07:11.080,1:07:12.860<br>
所以，就讀了一下它的附錄<br>
<br>
1:07:12.860,1:07:16.940<br>
附錄裡面，它描述了它 neural network 的 structure<br>
<br>
1:07:16.940,1:07:18.260<br>
它是這樣說的<br>
<br>
1:07:19.200,1:07:23.540<br>
它的 input 是一個 19*19*48 的 image<br>
<br>
1:07:23.540,1:07:26.640<br>
19*19 我們可以理解，因為一個棋盤就是 19*19<br>
<br>
1:07:26.640,1:07:28.740<br>
48 是怎麼來的呢<br>
<br>
1:07:28.740,1:07:31.140<br>
對 AlphaGo 來說呢<br>
<br>
1:07:31.140,1:07:37.280<br>
它把每一個位置都用 48 個 value 來描述它<br>
<br>
1:07:39.620,1:07:42.740<br>
它把每一個位置<br>
<br>
1:07:42.740,1:07:45.880<br>
都用 48 個 value 來描述它<br>
<br>
1:07:45.880,1:07:47.580<br>
那這裡面的 value 呢<br>
<br>
1:07:47.580,1:07:51.700<br>
就我們本來說，我們只要在一個位置描述說<br>
<br>
1:07:51.700,1:07:54.760<br>
它是不是白子，有沒有黑子就可以了<br>
<br>
1:07:54.760,1:07:57.440<br>
那其實 AlphaGo 它有加上了 domain knowledge<br>
<br>
1:07:57.440,1:08:00.380<br>
它不只是說有一個位置，它有沒有白子或黑子<br>
<br>
1:08:00.380,1:08:05.460<br>
它還會看說，這個位置是不是處於<br>
<br>
1:08:05.460,1:08:07.860<br>
叫吃的狀態呢，等等<br>
<br>
1:08:07.860,1:08:12.000<br>
所以，我們如果讀完這段的話，你會發現說<br>
<br>
1:08:12.000,1:08:15.560<br>
第一個 layer，它有做 zero padding<br>
<br>
1:08:15.560,1:08:18.800<br>
也就是說，它把原來 19*19 的 image<br>
<br>
1:08:18.800,1:08:23.960<br>
外圍補上更多 0，讓它變成一張<br>
<br>
1:08:23.960,1:08:25.980<br>
23*23 的 image<br>
<br>
1:08:29.960,1:08:34.220<br>
然後，它的第一個 layer 用的是<br>
<br>
1:08:34.220,1:08:36.700<br>
5*5 的 filter<br>
<br>
1:08:36.700,1:08:40.040<br>
總共有 k 個 filter，k 的值呢<br>
<br>
1:08:40.040,1:08:42.420<br>
它在 paper 裡面用的是 192<br>
<br>
1:08:42.420,1:08:45.180<br>
因為它有試 128 跟 256<br>
<br>
1:08:45.180,1:08:48.160<br>
接下來，它的 stride 是設 1<br>
<br>
1:08:48.160,1:08:51.640<br>
然後，它有用 ReLU 的 activation function<br>
<br>
1:08:51.640,1:08:56.440<br>
接下來，它有 2~12 層<br>
<br>
1:09:00.060,1:09:05.380<br>
apply 5*5 的 filter 以後，它變成 21*21 的 image<br>
<br>
1:09:05.380,1:09:09.200<br>
那接下來的 filter 都是 3*3 的 filter，它的 stride<br>
<br>
1:09:09.200,1:09:11.500<br>
都是 1，然後<br>
<br>
1:09:11.500,1:09:15.780<br>
你就會發現說，其實 AlphaGo 是沒有用 Max pooling 的<br>
<br>
1:09:15.780,1:09:17.120<br>
有沒有很神奇呢<br>
<br>
1:09:17.120,1:09:18.920<br>
它是沒有用 Max Pooling 的<br>
<br>
1:09:18.920,1:09:21.060<br>
所以，這個 neural network 架構的設計<br>
<br>
1:09:21.060,1:09:24.760<br>
是這個應用之道，存乎一心<br>
<br>
1:09:24.760,1:09:27.860<br>
雖然說，在這個 image 裡面<br>
<br>
1:09:27.860,1:09:29.400<br>
我們都會用 Max pooling 這個架構<br>
<br>
1:09:29.400,1:09:32.840<br>
但是，針對圍棋的特性來<br>
設計 neural network 的架構的時候<br>
<br>
1:09:33.520,1:09:36.140<br>
我們是不需要 Max pooling 這個架構的<br>
<br>
1:09:36.140,1:09:39.040<br>
所以在 AlphaGo 裡面，它沒有用 Max pooling 這個架構<br>
<br>
1:09:39.040,1:09:42.540<br>
並不是疏失了甚麼之類的<br>
<br>
1:09:42.540,1:09:46.060<br>
而是，根據圍棋的特性，我們本來就不需要再<br>
<br>
1:09:46.060,1:09:49.220<br>
圍棋的 CNN 裡面，用 Max pooling 這樣的架構<br>
<br>
1:09:50.820,1:09:52.340<br>
那其實 CNN<br>
<br>
1:09:52.340,1:09:55.740<br>
也可以被用在其他的、很多的 task 裡面<br>
<br>
1:09:55.740,1:09:59.720<br>
比如說，CNN 也被用在影像處理上<br>
<br>
1:09:59.720,1:10:01.800<br>
那 CNN 也被用在影像處理上<br>
<br>
1:10:01.800,1:10:05.080<br>
舉例來說，這個是一段聲音<br>
<br>
1:10:05.080,1:10:09.820<br>
你可以把一段聲音表示成所謂的 spectrogram<br>
<br>
1:10:09.820,1:10:11.740<br>
所謂 spectrogram 的意思是說<br>
<br>
1:10:11.740,1:10:14.660<br>
這個橫軸是時間<br>
<br>
1:10:14.660,1:10:19.260<br>
這個縱軸是那一段時間裡面<br>
<br>
1:10:19.260,1:10:21.220<br>
聲音的頻率<br>
<br>
1:10:21.220,1:10:24.600<br>
比如說，假設我們看這一段時間<br>
<br>
1:10:24.600,1:10:28.960<br>
這個偏紅色就代表說，在那一段時間裡面<br>
<br>
1:10:28.960,1:10:32.760<br>
那一個頻率的 energy 是比較大的<br>
<br>
1:10:32.760,1:10:37.800<br>
那在這一段時間裡面，這一個頻率跟這一個頻率<br>
<br>
1:10:37.800,1:10:42.240<br>
跟這一個頻率的能量是比較高的<br>
<br>
1:10:43.380,1:10:46.120<br>
那這一張 image，其實是我說<br>
<br>
1:10:46.120,1:10:49.020<br>
你好，然後看到的 spectrogram<br>
<br>
1:10:49.020,1:10:53.440<br>
所以，這個東西是你，這個東西是好<br>
<br>
1:10:53.440,1:10:57.380<br>
如果有透過訓練的人呢，它其實可以看這張 image<br>
<br>
1:10:57.380,1:11:00.920<br>
就知道說這句話的內容是甚麼<br>
<br>
1:11:00.920,1:11:03.200<br>
我之前在 MIT 做 postdoc 的時候<br>
<br>
1:11:03.200,1:11:06.200<br>
MIT 的語音處理實驗室據說是<br>
<br>
1:11:06.200,1:11:09.580<br>
最早發明 spectrogram reading <br>
<br>
1:11:09.580,1:11:12.260<br>
的團隊，所謂 spectrogram reading 的意思就是<br>
<br>
1:11:12.260,1:11:15.140<br>
練習看這個頻譜，就知道說<br>
<br>
1:11:15.140,1:11:17.360<br>
它裡面內容是甚麼<br>
<br>
1:11:17.360,1:11:20.660<br>
然後，他們經年累月的在練習這件事情<br>
<br>
1:11:20.660,1:11:22.140<br>
就練習的很強<br>
<br>
1:11:22.140,1:11:29.700<br>
他們每周的 group meeting 都要練習做 spectrogram<br>
<br>
1:11:29.700,1:11:32.400<br>
就是老師會拿出一張 spectrogram<br>
<br>
1:11:32.400,1:11:35.760<br>
然後，大家就要判讀這張 spectrogram 的內容<br>
<br>
1:11:37.240,1:11:40.060<br>
老師就會指著一段說<br>
<br>
1:11:40.060,1:11:42.440<br>
這個 spectrogram，這一段聲音<br>
<br>
1:11:42.440,1:11:43.880<br>
你覺得它是哪一個 phone 呢？<br>
<br>
1:11:43.880,1:11:46.340<br>
大家把一段聲音<br>
<br>
1:11:46.340,1:11:48.820<br>
phone 就是類似音標的東西<br>
<br>
1:11:48.820,1:11:52.080<br>
大家把一段聲音的音標解譯出來以後<br>
<br>
1:11:52.080,1:11:55.280<br>
再套 language model 上去，把它解譯成文字<br>
<br>
1:11:55.280,1:11:57.120<br>
是這樣，通常都會答對<br>
<br>
1:11:57.120,1:11:58.360<br>
那你可能會覺得說<br>
<br>
1:11:58.360,1:12:01.940<br>
他們練到最後可能可以看一張 image<br>
<br>
1:12:01.940,1:12:03.720<br>
秒反映說它的結果是甚麼<br>
<br>
1:12:03.720,1:12:05.240<br>
那其實沒有辦法<br>
<br>
1:12:05.240,1:12:08.160<br>
通常這個解譯的過程大概要花一個小時<br>
<br>
1:12:10.360,1:12:14.080<br>
這個東西就像念球遊戲之類的，是個很厲害的技術<br>
<br>
1:12:14.940,1:12:19.840<br>
既然人可以看這個 image，就知道說<br>
<br>
1:12:19.840,1:12:23.180<br>
它是甚麼樣的聲音訊號<br>
<br>
1:12:23.180,1:12:24.520<br>
甚麼樣的 phoneme<br>
<br>
1:12:24.520,1:12:30.240<br>
我們也可以讓機器把這個 spectrogram<br>
<br>
1:12:30.240,1:12:32.060<br>
就當作一張 image<br>
<br>
1:12:32.060,1:12:35.180<br>
然後，用 CNN 來判斷說，input 這張 image<br>
<br>
1:12:35.180,1:12:37.700<br>
它是對應甚麼樣的聲音訊號<br>
<br>
1:12:37.700,1:12:40.000<br>
那這邊通常判斷的單位，比如說是<br>
<br>
1:12:40.000,1:12:43.980<br>
phoneme，類似音標這樣子的單位<br>
<br>
1:12:43.980,1:12:46.380<br>
也有可能是 phoneme之類的<br>
<br>
1:12:46.380,1:12:48.760<br>
但是，這邊神奇的地方就是<br>
<br>
1:12:48.760,1:12:51.020<br>
當我們把一段 spectrogram<br>
<br>
1:12:51.020,1:12:53.680<br>
當作 image，丟到 CNN 裡面的時候<br>
<br>
1:12:53.680,1:12:57.540<br>
在語音上，我們通常只考慮<br>
<br>
1:12:57.540,1:13:00.900<br>
在 frequency 方向上移動的 filter<br>
<br>
1:13:00.900,1:13:03.980<br>
也就是說，我們的 filter 是這樣，是長方形的<br>
<br>
1:13:03.980,1:13:05.600<br>
是長方形的<br>
<br>
1:13:05.600,1:13:08.980<br>
它的寬，就跟我們 image 的寬是一樣的<br>
<br>
1:13:08.980,1:13:12.200<br>
那我們在移動 filter 的時候呢<br>
<br>
1:13:12.200,1:13:14.100<br>
我們是移這個方向<br>
<br>
1:13:14.100,1:13:17.420<br>
我們只移這個方向<br>
<br>
1:13:17.420,1:13:19.300<br>
為甚麼是這樣子呢？<br>
<br>
1:13:19.300,1:13:24.160<br>
當然也有人試過說，把 filter 移時間的方向會怎樣呢<br>
<br>
1:13:24.160,1:13:26.180<br>
結果是沒有太大的幫助<br>
<br>
1:13:26.180,1:13:29.500<br>
會這樣的原因，我覺得是因為在語音裡面<br>
<br>
1:13:29.500,1:13:33.280<br>
這個 CNN 的 output 後面都還會再接別的東西<br>
<br>
1:13:33.280,1:13:36.140<br>
比如說，再接 LSTM 阿，等等<br>
<br>
1:13:36.140,1:13:38.440<br>
他們都已經有考慮 typical 的 information <br>
<br>
1:13:38.440,1:13:41.780<br>
所以你在 CNN 裡面，你再考慮一次時間的 information<br>
<br>
1:13:41.780,1:13:43.520<br>
其實，沒有甚麼特別的幫助<br>
<br>
1:13:43.520,1:13:47.320<br>
但是，為甚麼在頻率上的 filter 有幫助呢<br>
<br>
1:13:47.320,1:13:50.360<br>
想想看，我們說我們用 filter 的目的<br>
<br>
1:13:50.360,1:13:53.320<br>
是為了要 detect 說同樣的 pattern<br>
<br>
1:13:53.320,1:13:54.620<br>
出現在不同的 region<br>
<br>
1:13:54.620,1:13:57.480<br>
我們都可以用同一個 filter 把它 detect 出來<br>
<br>
1:13:57.480,1:13:59.000<br>
但在聲音訊號上面<br>
<br>
1:13:59.000,1:14:02.480<br>
雖然，比如說，男生跟女生發同樣的聲音<br>
<br>
1:14:02.480,1:14:05.260<br>
男生跟女生同樣說你好<br>
<br>
1:14:05.260,1:14:08.420<br>
看起來這個 spectrogram 是非常不一樣的<br>
<br>
1:14:08.420,1:14:12.860<br>
但實際上他們的不同，只是一個頻率的 shift 而已<br>
<br>
1:14:12.860,1:14:15.300<br>
男生說的你好跟女生說的你好<br>
<br>
1:14:15.300,1:14:17.600<br>
他們的 pattern 其實是一樣的<br>
<br>
1:14:17.600,1:14:21.620<br>
比如說，你看這個 spectrogram 變化的情形<br>
<br>
1:14:21.620,1:14:23.180<br>
其實，可能是一樣的<br>
<br>
1:14:23.180,1:14:26.860<br>
那男生跟女生的差別，可能只是頻率上的 shift 而已<br>
<br>
1:14:26.860,1:14:29.000<br>
你就只是把這個 pattern<br>
<br>
1:14:29.000,1:14:31.960<br>
放在 image 上的不同位置而已<br>
<br>
1:14:31.960,1:14:34.660<br>
所以，今天我們把 filter<br>
<br>
1:14:34.660,1:14:38.100<br>
在 frequency 的 direction 上移動是有效的<br>
<br>
1:14:38.100,1:14:40.620<br>
但是，在 time domain 上的移動<br>
<br>
1:14:40.620,1:14:42.820<br>
是沒有必要，是沒有太大幫助的<br>
<br>
1:14:43.940,1:14:46.560<br>
所以，這又是另外一個例子，就是<br>
<br>
1:14:46.560,1:14:50.100<br>
當你把 CNN 用在另一個 application 的時候呢<br>
<br>
1:14:50.100,1:14:51.960<br>
你永遠要想一想說<br>
<br>
1:14:51.960,1:14:54.000<br>
這個 application 的特性是什麼<br>
<br>
1:14:54.000,1:14:56.500<br>
而根據那個 application 的特性<br>
<br>
1:14:56.500,1:14:58.100<br>
來 design 你的 network 的 structure<br>
<br>
1:14:59.000,1:15:00.940<br>
那我們也知道說，CNN 會<br>
<br>
1:15:00.940,1:15:03.720<br>
被用在文字處理上面<br>
<br>
1:15:03.720,1:15:06.000<br>
這個是從 paper 上面截下來的圖<br>
<br>
1:15:06.000,1:15:11.240<br>
在文字處理上面，假設你 input 一張<br>
<br>
1:15:11.240,1:15:14.620<br>
一個 word sequence，假設你要做的事情是<br>
<br>
1:15:14.620,1:15:17.220<br>
讓 machine 偵測說，這個 word sequence<br>
<br>
1:15:17.220,1:15:21.400<br>
它代表的是 positive 的意思還是 negative 的意思<br>
<br>
1:15:21.400,1:15:24.640<br>
首先，input 一個 word sequence<br>
<br>
1:15:24.640,1:15:27.180<br>
你把這個 word sequence 裡面的每一個 word<br>
<br>
1:15:27.180,1:15:30.000<br>
都用一個 vector 來表示<br>
<br>
1:15:30.000,1:15:31.860<br>
那這邊的每一個 vector<br>
<br>
1:15:31.860,1:15:36.300<br>
它代表的這個 word，它本身的 semantic<br>
<br>
1:15:36.300,1:15:38.520<br>
那如果兩個 word 本身涵義越接近的話呢<br>
<br>
1:15:38.520,1:15:43.060<br>
他們的 vector 在高維的空間上<br>
<br>
1:15:43.060,1:15:46.860<br>
就越接近，這個東西叫做 word embedding<br>
<br>
1:15:46.860,1:15:49.100<br>
那如果你不知道 word embedding 是什麼的話<br>
<br>
1:15:49.100,1:15:53.860<br>
也沒有關係，你就記得說現在每一個<br>
<br>
1:15:53.860,1:15:56.860<br>
word 都會用一個 vector 表示<br>
<br>
1:15:56.860,1:15:58.740<br>
都會用一個 vector 表示<br>
<br>
1:15:58.740,1:16:02.440<br>
當你把每一個 word 都用一個 vector 來表示的時候<br>
<br>
1:16:02.440,1:16:06.740<br>
你把一個 sentence 裡面所有的 word 排再一起<br>
<br>
1:16:06.740,1:16:09.260<br>
它就變成一個 image<br>
<br>
1:16:09.260,1:16:11.420<br>
它就變成一張 image<br>
<br>
1:16:11.420,1:16:13.820<br>
那你可以把 CNN<br>
<br>
1:16:13.820,1:16:16.900<br>
套用在這個 image 上面<br>
<br>
1:16:16.900,1:16:19.640<br>
怎麼做呢？<br>
<br>
1:16:19.640,1:16:23.900<br>
當我們要把 CNN 用在文字處理上的時候<br>
<br>
1:16:23.900,1:16:26.460<br>
你的 filter 其實是長這樣子<br>
<br>
1:16:26.460,1:16:28.680<br>
你的 filter 是長這個樣子<br>
<br>
1:16:28.680,1:16:32.100<br>
它的高跟 image 的高<br>
<br>
1:16:32.100,1:16:33.780<br>
是一樣的<br>
<br>
1:16:33.780,1:16:35.900<br>
然後，你把你的 filter<br>
<br>
1:16:35.900,1:16:39.280<br>
沿著 word 的順序<br>
<br>
1:16:39.280,1:16:42.460<br>
沿著句子裡面詞彙的順序來移動<br>
<br>
1:16:42.460,1:16:44.540<br>
然後，你就會得到一個 vector<br>
<br>
1:16:44.540,1:16:47.200<br>
不同的 filter 就會得到不同的 vector<br>
<br>
1:16:47.200,1:16:49.100<br>
然後，接下來做 Max pooling<br>
<br>
1:16:49.100,1:16:52.500<br>
把 Max pooling 的結果丟到 fully connected layer 裡面<br>
<br>
1:16:52.500,1:16:54.780<br>
你就會得到最後的 output<br>
<br>
1:16:54.780,1:16:57.220<br>
那在文字處理上呢<br>
<br>
1:16:57.220,1:17:02.480<br>
這個 filter 只在時間的序列上移動<br>
<br>
1:17:02.480,1:17:07.400<br>
而不在這個 embedding 的 dimension 上移動<br>
<br>
1:17:07.400,1:17:11.520<br>
你不會設計 filter，它移動的方向是<br>
<br>
1:17:11.520,1:17:13.820<br>
這個方向的<br>
<br>
1:17:13.820,1:17:16.080<br>
為甚麼呢？如果你有<br>
<br>
1:17:16.080,1:17:18.540<br>
做過類似的 task<br>
<br>
1:17:18.540,1:17:20.540<br>
如果你有做過文字處理的 task<br>
<br>
1:17:20.540,1:17:23.920<br>
知道這個 embedding 的 dimension 指的是甚麼的話<br>
<br>
1:17:23.920,1:17:25.760<br>
知道 word vector 指的是甚麼的話<br>
<br>
1:17:25.760,1:17:26.860<br>
你就會知道說<br>
<br>
1:17:26.860,1:17:31.000<br>
其實在這個方向上移動，是不 make sense 的<br>
<br>
1:17:31.000,1:17:34.400<br>
因為在 word embedding 裡面呢<br>
<br>
1:17:34.400,1:17:38.700<br>
每一個 dimension 的含意其實是獨立的<br>
<br>
1:17:38.700,1:17:41.620<br>
所以，如果當我們今天使用 CNN 的時候<br>
<br>
1:17:41.620,1:17:45.080<br>
你會假設說，第二個 dimension<br>
<br>
1:17:45.080,1:17:48.080<br>
跟第一個 dimension 有某種特別的關係<br>
<br>
1:17:48.080,1:17:50.880<br>
那第四個 dimension 跟第五個 dimension<br>
<br>
1:17:50.880,1:17:52.440<br>
有某種特別的關係<br>
<br>
1:17:52.440,1:17:56.080<br>
而這個關係，我們是可以被<br>
<br>
1:17:56.080,1:17:59.600<br>
如果這個關係是重複的<br>
<br>
1:17:59.600,1:18:02.100<br>
這個同樣的 pattern 出現在不同的位置<br>
<br>
1:18:02.100,1:18:03.580<br>
它們代表的是同樣的意思<br>
<br>
1:18:03.580,1:18:06.400<br>
但是，在 word embedding 裡面呢<br>
<br>
1:18:06.400,1:18:10.440<br>
不同 dimension，它們是 independent ，它們是獨立的<br>
<br>
1:18:10.440,1:18:12.920<br>
所以，在這個方向上面<br>
<br>
1:18:12.920,1:18:14.840<br>
移動 filter，是沒有意義的<br>
<br>
1:18:14.840,1:18:17.020<br>
所以，如果你在做文字處理的時候<br>
<br>
1:18:17.020,1:18:21.080<br>
你只會在 sentence 的順序上面移動 filter<br>
<br>
1:18:21.080,1:18:24.400<br>
而不會在 word embedding 的 dimension 去移動 filter<br>
<br>
1:18:24.400,1:18:28.700<br>
所以，這個又是另外一個例子<br>
<br>
1:18:28.700,1:18:31.320<br>
雖然，大家覺得 CNN 很 powerful<br>
<br>
1:18:31.320,1:18:34.480<br>
你可以用在各個不同的地方<br>
<br>
1:18:34.480,1:18:36.720<br>
但是，你用在一個新的 task 的時候<br>
<br>
1:18:36.720,1:18:38.920<br>
你要想一想你的新的 task<br>
<br>
1:18:38.920,1:18:42.340<br>
在設計 CNN 的架構的時候，你要怎麼做<br>
<br>
1:18:43.920,1:18:47.420<br>
如果你想要知道更多有關 Regularization 的事情的話<br>
<br>
1:18:47.420,1:18:51.060<br>
以下是一些 reference<br>
<br>
1:18:51.060,1:18:54.360<br>
我們剛才看到說，如果你想要用<br>
<br>
1:18:54.360,1:18:56.920<br>
Deep Dream 的方法<br>
<br>
1:18:56.920,1:19:01.600<br>
來讓 machine 自動產生一個 digit 這件事情<br>
<br>
1:19:01.600,1:19:02.760<br>
是不太成功的<br>
<br>
1:19:02.760,1:19:05.680<br>
但是，有很多其他的方法<br>
<br>
1:19:05.680,1:19:08.300<br>
可以讓 machine 畫出非常清晰的圖<br>
<br>
1:19:08.300,1:19:11.740<br>
而其他方法可以讓 machine 看過 MNIST 裡面的那些<br>
<br>
1:19:11.740,1:19:16.240<br>
數字以後，就學會畫出以假亂真的數字<br>
<br>
1:19:16.240,1:19:20.160<br>
這邊列了幾個方法，比如說有 PixelRNN<br>
<br>
1:19:20.160,1:19:24.120<br>
或者是 VAE, GAN，給大家參考<br>
<br>
1:19:24.120,1:19:28.600<br>
臺灣大學人工智慧中心<br>
科技部人工智慧技術暨全幅健康照護聯合研究中心<br>
http://aintu.tw<br>
