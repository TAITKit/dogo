0:00:00.000,0:00:02.480
臺灣大學人工智慧中心
科技部人工智慧技術暨全幅健康照護聯合研究中心
http://aintu.tw

0:00:02.480,0:00:06.000
好，接下來我要來講一下 Generation 的 model

0:00:06.000,0:00:09.000
有關 Generation 的 model

0:00:09.000,0:00:10.660
你可以看一些很好的 reference

0:00:10.660,0:00:13.360
這個是 OpenAI 寫的一篇科普的文章

0:00:13.360,0:00:14.840
那我把它列在這一邊

0:00:14.840,0:00:16.800
在這篇文章裡面呢

0:00:16.820,0:00:20.780
它開頭是引用費曼的話

0:00:20.780,0:00:23.780
這句話，來歷是什麼呢？

0:00:23.780,0:00:26.080
據說是，費曼過世以後

0:00:26.080,0:00:28.460
有人去他的辦公室，拍一下他的黑板

0:00:28.460,0:00:30.740
他在黑板上留下了這一句話

0:00:30.740,0:00:32.840
這個是他辦公室的黑板

0:00:32.840,0:00:35.880
這一句話寫在左上角 ，他說

0:00:35.880,0:00:39.980
What I cannot create, I do not understand.

0:00:39.980,0:00:42.820
所以，如果一個東西

0:00:42.820,0:00:46.380
他沒有辦法，他不知道怎麼產生它的話

0:00:46.380,0:00:49.500
他就不算是真的完全理解

0:00:49.500,0:00:52.380
所以，對 machine 來說 ，或許也是一樣

0:00:52.380,0:00:56.460
比如說 ，現在 machine 在影像處理上

0:00:56.460,0:00:58.920
machine 可以做到分類

0:00:58.920,0:01:02.400
你可以讓他見識貓和狗的不同

0:01:02.400,0:01:04.720
但他或許並不真的了解

0:01:04.720,0:01:07.180
貓是什麼， 或許它並不真的了解狗是什麼

0:01:07.280,0:01:10.040
也許在未來，有一天

0:01:10.040,0:01:13.280
machine 它可以自己畫出一隻貓的時候

0:01:13.280,0:01:16.260
它對於貓這個東西的概念

0:01:16.260,0:01:17.580
或許就不一樣了

0:01:17.580,0:01:20.140
而這個是現在一個非常熱門的主題

0:01:20.140,0:01:22.800
有很多相關的研究

0:01:22.800,0:01:25.080
我們就來稍微講一下

0:01:25.080,0:01:28.060
我們稍微來 overview 一下

0:01:28.060,0:01:29.300
相關的研究

0:01:29.300,0:01:31.280
在這些研究裡面

0:01:31.280,0:01:34.000
大概可以分成 3 個方法

0:01:34.000,0:01:37.160
這邊分別是 PixelRNN

0:01:37.160,0:01:40.260
VAE (Variational Autoencoder)

0:01:40.260,0:01:42.540
和 Generative Adversarial Network (GAN)

0:01:42.540,0:01:45.900
那這些方法呢，其實都非常的新

0:01:45.900,0:01:48.440
其中最舊的是 VAE

0:01:48.440,0:01:51.140
VAE 是 2013 年提出來的

0:01:51.140,0:01:53.960
像 GAN 是 2014 年提出來

0:01:53.960,0:01:56.140
它提出來還不到兩年

0:01:56.140,0:01:58.160
你知道，我們一般在上課的時候

0:01:58.160,0:01:59.520
尤其是在必修課裡面

0:01:59.520,0:02:01.760
你聽到的每一個東西往往都是，比如說

0:02:01.760,0:02:04.200
50 年前，100 年前 propose 出來的

0:02:04.200,0:02:06.960
但是在 machine learning，這邊這個領域裡面

0:02:06.960,0:02:09.320
它的變化是非常非常快速的

0:02:09.320,0:02:11.680
所以，有很多很多

0:02:11.680,0:02:14.960
未來可能會成為非常經典的方法

0:02:14.960,0:02:18.200
它是這幾年，才不斷地推陳出新

0:02:18.200,0:02:19.800
所以，我試著在課程裡面

0:02:19.800,0:02:22.600
cover 一些比較新的技術

0:02:22.600,0:02:24.220
讓大家知道說

0:02:24.220,0:02:27.580
這個領域它的變化，是非常非常快的

0:02:29.000,0:02:32.660
那我們先來講一下 PixelRNN

0:02:32.660,0:02:34.640
我們今天就先講一下這些方法

0:02:34.640,0:02:36.000
大概是怎麼運作的

0:02:36.000,0:02:38.740
然後下一次，再細講它的原理

0:02:38.740,0:02:40.260
我們來講一下 ，這個 Pixel RNN

0:02:40.260,0:02:42.040
雖然我還沒有講過 RNN 是什麼

0:02:42.040,0:02:45.100
但我相信這個方法，你是可以聽得懂的

0:02:45.100,0:02:48.540
因為它非常的，非常的直覺

0:02:48.540,0:02:50.100
非常的直覺

0:02:50.100,0:02:52.680
假設我們今天要產生一個

0:02:52.680,0:02:56.340
我們今天的目標是要讓 machine 自己畫一張圖出來

0:02:56.340,0:02:59.080
比如說，我們今天要讓 machine 畫出一個

0:02:59.080,0:03:03.160
解析度是 3*3，有 9 個 pixel 的 image

0:03:03.160,0:03:04.300
怎麼做呢？

0:03:04.300,0:03:07.640
我們讓 machine 每一次畫一個 pixel

0:03:07.640,0:03:09.000
它每一次就點一個點

0:03:09.000,0:03:11.720
點完 9 個點，就畫出一張圖了

0:03:11.720,0:03:13.240
那怎麼做呢？

0:03:13.240,0:03:16.820
假設我們先隨機給它第一個

0:03:16.820,0:03:19.620
隨機給這個 image ，塗一個紅色的 pixel

0:03:19.620,0:03:22.700
接下來呢，你就 learn 一個 model

0:03:22.700,0:03:26.020
它 input ，就是已經在圖上的紅色 pixel

0:03:26.020,0:03:29.420
它的 output，就是接下來 

0:03:29.420,0:03:31.120
要吐出什麼顏色的 pixel

0:03:31.120,0:03:34.240
假設，它吐出藍色的 pixel

0:03:34.240,0:03:36.600
那就把藍色的 pixel 再擺到 image 上面

0:03:36.600,0:03:38.340
那你說，怎麼描述一個 pixel 呢？

0:03:38.340,0:03:41.420
一個 pixel 不就是 RGB 三個顏色所構成的嗎？

0:03:41.420,0:03:44.700
所以，一個 pixel 就是一個三維的 vector

0:03:44.700,0:03:46.980
所以，你就是 learn 一個 neural network

0:03:46.980,0:03:49.240
它可以吃一個三維的 vector

0:03:49.240,0:03:51.240
然後，output 另外一個 3 維的 vector

0:03:51.240,0:03:52.680
這個 3 維的 vector，3個值

0:03:52.680,0:03:55.500
就代表了，這個 pixel 的 RGB 3 個值

0:03:55.500,0:03:57.060
你要把這個 neural network 的 output

0:03:57.060,0:04:00.640
轉成一個顏色，然後，把它塗上去就結束了

0:04:00.640,0:04:04.160
接下來，這個圖上有兩個點

0:04:04.160,0:04:07.600
那你就再用同一個 model

0:04:07.600,0:04:10.900
它 input 紅色和藍色的 pixel

0:04:10.900,0:04:14.420
接下來，它就 output 下一個 pixel

0:04:14.420,0:04:16.100
比如說，它是淺藍色的 pixel

0:04:16.100,0:04:18.640
那這邊呢，你可能會有個問題就是

0:04:18.640,0:04:22.320
neural network 不是  input 一個 pixel length  的 vector

0:04:22.320,0:04:24.280
output 另外一個 pixel length 的 vector 嗎？

0:04:24.280,0:04:26.060
比如說，你 input 3 維

0:04:26.060,0:04:28.120
它就固定只能 input 3 維

0:04:28.120,0:04:30.120
你怎麼 input 一個 pixel

0:04:30.120,0:04:32.840
又用同一個 network，input 2個 pixel 呢？

0:04:32.840,0:04:35.680
這個就是 RNN 可以處理的地方

0:04:35.680,0:04:39.060
RNN 它可以處理 variable length 的 input

0:04:39.060,0:04:40.500
因為我們還沒有講過 RNN

0:04:40.500,0:04:42.820
如果，你覺得你無法理解

0:04:42.820,0:04:45.720
怎麼處理一個 variable length 的 pixel 的話

0:04:45.720,0:04:48.200
那你就想像說

0:04:48.200,0:04:50.260
還沒有 pixel 的地方，我就補零

0:04:50.260,0:04:53.600
就想像說，我這一邊空白的地方

0:04:53.600,0:04:57.020
我其實是，就是補一個白色的 pixel 而已

0:04:59.000,0:05:00.660
那接下來呢

0:05:00.660,0:05:04.560
你給它紅色、藍色跟淺藍色的 pixel

0:05:04.560,0:05:07.200
接下來，它吐出一個灰色的 pixel

0:05:07.200,0:05:09.620
那你就再把灰色的 pixel 放到圖上

0:05:09.620,0:05:12.800
接下來，重複剛才的步驟，給它這 4 個 pixel

0:05:12.800,0:05:15.000
然後，把下一個 pixel 再補上去

0:05:15.000,0:05:16.720
那你就把 9 個 pixel 都補完 

0:05:16.720,0:05:18.760
就畫完一張圖了

0:05:18.760,0:05:20.980
那要 train 這種 network 很簡單

0:05:20.980,0:05:22.820
它完全就是 unsupervised

0:05:22.820,0:05:25.840
你不需要任何的 label ，你想在作業 3 裡面

0:05:25.840,0:05:29.000
你要知道某一些 image，它的 label 是什麼

0:05:29.000,0:05:31.340
你才能夠 train 一個 image 的 classifier

0:05:31.340,0:05:34.100
這一邊不用，你就收集一大堆的 image

0:05:34.100,0:05:36.060
然後，machine 就會知道說

0:05:36.060,0:05:38.100
看到第一個 pixel 是這個顏色

0:05:38.100,0:05:39.500
第二個 pixel 應該是甚麼

0:05:39.500,0:05:40.380
看到第一個和第二個 pixel 這個顏色

0:05:40.380,0:05:41.889
第三個應該是甚麼

0:05:41.889,0:05:43.660
看到1, 2, 3 個pixel

0:05:43.660,0:05:44.460
第四個 pixel 應該是甚麼

0:05:44.460,0:05:46.360
這個就叫 PixelRNN

0:05:46.360,0:05:48.640
你可能想說，這招這麼簡單

0:05:48.640,0:05:49.760
它會 work 嗎？

0:05:49.760,0:05:50.880
也讓我蠻驚奇的

0:05:50.880,0:05:53.220
它其實是 work 的

0:05:53.220,0:05:56.200
而且在不同的 generate image 的方法裡面

0:05:56.200,0:05:57.320
現在，就我所知

0:05:57.320,0:05:59.280
應該是 PixelRNN 它產生的圖

0:05:59.280,0:06:00.680
是最清晰的

0:06:00.720,0:06:02.180
其他的方法產生的圖

0:06:02.180,0:06:03.800
沒有辦法像 PixelRNN 這麼清晰

0:06:03.800,0:06:09.380
這個是，DeepMind paper 的一個例子

0:06:09.380,0:06:13.300
這個是真實的 image，就是一隻狗

0:06:13.300,0:06:16.020
如果我們現在把這一隻狗的下半身

0:06:16.020,0:06:17.960
遮掉，把下半身遮掉

0:06:17.960,0:06:20.980
接下來，我們就要讓 machine

0:06:20.980,0:06:24.420
去 predict 說，given 這些 pixel

0:06:24.420,0:06:26.420
接下來這隻狗的下半身

0:06:26.420,0:06:27.900
應該要長什麼樣子

0:06:27.900,0:06:30.480
machine 把狗的下半身畫出來

0:06:30.480,0:06:33.520
那 machine 畫出了這樣子的狗

0:06:33.520,0:06:34.460
還有這樣子的狗

0:06:34.460,0:06:35.640
還有這樣子的狗

0:06:35.640,0:06:38.060
有看起來看像猩猩的狗

0:06:38.060,0:06:39.380
還有看起來像雞的狗這樣

0:06:41.380,0:06:43.080
然後，這個方法

0:06:43.080,0:06:44.600
其實也可以被用在

0:06:44.600,0:06:46.240
不只是影像上

0:06:46.240,0:06:48.620
它也可以被用在語音上

0:06:48.620,0:06:50.340
非常著名的例子呢

0:06:50.340,0:06:52.020
就是 WaveNet

0:06:52.020,0:06:54.800
我們知道 WaveNet 可以做語音合成

0:06:54.800,0:06:56.680
但是 WaveNet 到底是怎麼做的呢？

0:06:56.680,0:06:58.280
其實，它的概念非常簡單

0:06:58.280,0:07:00.720
就是 input 一大堆的

0:07:00.720,0:07:02.800
這邊底下的每一個 node

0:07:02.800,0:07:06.040
藍色的圈圈，代表的就是 wave form

0:07:06.040,0:07:09.620
wave form 大家知道嗎？就是

0:07:09.620,0:07:11.820
反正，你就把聲音取進來

0:07:11.820,0:07:13.780
然後，直接去取樣

0:07:13.780,0:07:15.740
然後看它的 amplitude

0:07:15.740,0:07:17.700
等於完全不用做任何 feature transform

0:07:17.700,0:07:20.540
通通都不要，這邊每一個藍色的點

0:07:20.540,0:07:23.220
就是聲音訊號上面的一個 sample

0:07:24.240,0:07:27.120
好，那今天就是這樣

0:07:27.120,0:07:29.040
我們等這個動畫跑完

0:07:29.540,0:07:34.460
給定前面一段的聲音訊號

0:07:34.460,0:07:37.640
然後，predict下一個 sample 的結果

0:07:37.640,0:07:39.560
然後把它放下來，再 predict 下一個 sample

0:07:39.560,0:07:41.040
再放下來，再 predict 下一個 sample

0:07:41.040,0:07:42.980
再放下來 ，就這樣

0:07:42.980,0:07:44.480
然後接下來就是

0:07:44.480,0:07:47.200
硬 train 下去，就結束了

0:07:47.200,0:07:50.480
然後，你就可以合出一段聲音

0:07:50.480,0:07:54.280
這個是在語音上的應用

0:07:54.280,0:07:56.780
在影像上也有應用

0:07:56.780,0:07:58.500
在 影像上，你也可以做一樣的事情

0:07:58.500,0:08:00.240
只要讓 machine 看過很多的 video

0:08:00.240,0:08:01.720
然後，它就可以 predict 說

0:08:01.720,0:08:04.620
給它一段 video，接下來會發生甚麼事情

0:08:04.620,0:08:06.660
比如說， 在 Google 的 demo 裡面

0:08:06.660,0:08:08.400
它會 DEMO 說

0:08:08.400,0:08:11.000
它的那些影像都是機器人手背上的影像

0:08:11.000,0:08:15.000
它在機器人手背上裝了一個攝影機

0:08:15.000,0:08:16.558
所以，它可以錄說

0:08:16.558,0:08:18.700
機器人的手背看到的影像

0:08:18.700,0:08:20.500
你就可以看到說

0:08:20.500,0:08:22.400
影像的前半段是

0:08:22.400,0:08:24.980
機械人的手伸向一塊抹布

0:08:24.980,0:08:26.460
然後，影像的後半段

0:08:26.460,0:08:29.300
就是機器人把抹布拿起來

0:08:29.300,0:08:31.120
把抹布拿起來的那一些影像

0:08:31.120,0:08:33.500
是機器自己腦補的結果

0:08:33.500,0:08:35.060
並不存在於現實生活中

0:08:35.060,0:08:38.300
機器自己 predict 接下來會發生什麼事情

0:08:38.300,0:08:41.920
那如果你想要練習

0:08:41.920,0:08:44.640
這個 generation 的話

0:08:44.640,0:08:47.260
一個最簡單的 application，當然是做 MNIST

0:08:47.260,0:08:48.900
不過做 MNIST，我覺得有一點虛弱

0:08:48.900,0:08:51.340
generate digit 有點虛弱，而且那個有點簡單

0:08:51.340,0:08:52.780
所以，我 create 另外一個 task

0:08:52.780,0:08:56.120
如果你想要練習 generative model 的話

0:08:56.120,0:08:57.360
你可以用這個 task

0:08:57.360,0:08:59.560
這一個 task 是 Pokémon Creation

0:08:59.560,0:09:05.480
這邊，我們有 792 張寶可夢的小圖

0:09:05.480,0:09:08.660
我們要讓 machine 看過這些小圖以後

0:09:08.660,0:09:12.560
它自己產生新的寶可夢出來，這一邊的口號就是

0:09:12.560,0:09:16.740
用創造代替捕抓這樣

0:09:17.280,0:09:19.280
過去我們是抓寶可夢

0:09:19.280,0:09:20.620
在野外抓寶可夢

0:09:20.620,0:09:21.720
像我們在實驗室裡面

0:09:21.720,0:09:24.240
是你創造新的寶可夢出來

0:09:24.240,0:09:28.420
image 的 source 是來自於 Pokémon 的 Wiki

0:09:28.420,0:09:29.840
我看了一下它的 copyright

0:09:29.840,0:09:32.140
它的 image 都可以任意使用

0:09:32.140,0:09:34.740
和變造的，所以應該是沒有版權的問題

0:09:34.740,0:09:39.220
原來的 image 是 40*40 的 pixel

0:09:39.220,0:09:42.060
其實，我覺得 40*40 有點稍微太大

0:09:42.060,0:09:43.480
所以，我把它 cut 小一點

0:09:43.480,0:09:46.340
只取了中間的部分

0:09:46.340,0:09:49.140
中心的部分，變成 20*20 的 image

0:09:49.140,0:09:51.360
那看起來大概像是這樣子

0:09:51.360,0:09:53.940
這個是喵喵

0:09:53.940,0:09:55.860
這個是，我也不知道它是什麼

0:09:55.860,0:09:57.420
我只知道它好像跟果然翁在一起

0:09:57.420,0:09:59.200
其實，我沒有把動畫仔細看完

0:09:59.200,0:10:01.420
反正就是這些，你可以

0:10:01.420,0:10:04.180
雖然說，影像的解析度沒有很高

0:10:04.180,0:10:07.440
但是，還是可以很清楚的看到說，它就是寶可夢

0:10:07.440,0:10:09.880
那這邊有一些 tips

0:10:09.880,0:10:11.480
因為，我其實自己實際做了一下

0:10:11.480,0:10:13.220
我覺得有一些 tips

0:10:13.220,0:10:15.420
首先，就是你可能很直覺的覺得說

0:10:15.420,0:10:20.500
一個 image、一個 pixel 應該就是用一個三維的 vector

0:10:20.500,0:10:22.020
用三個數字來描述它

0:10:22.020,0:10:23.820
每一個數字代表了 RGB

0:10:23.820,0:10:25.880
比如說，這樣的 pixel

0:10:25.880,0:10:28.220
你可能就用 3 個 vector

0:10:29.100,0:10:30.860
你可能用三個數值

0:10:30.860,0:10:33.820
50，150 和 100 來描述它

0:10:33.820,0:10:36.060
但是，我覺得實際上這樣做以後呢

0:10:36.060,0:10:39.620
我發現這樣做，結果感覺不是太好

0:10:39.620,0:10:40.880
那我覺得，原因是因為

0:10:40.880,0:10:43.920
你用這樣做，你產生的圖

0:10:43.920,0:10:47.480
都很灰，看起來都灰灰髒髒的

0:10:47.480,0:10:48.940
我覺得一個原因是因為

0:10:48.940,0:10:51.440
如果你要產生非常鮮明的顏色的話

0:10:51.440,0:10:53.660
非常鮮明的顏色往往是

0:10:53.660,0:10:57.320
某一個RGB 裡面的某一個 value 特別高

0:10:57.320,0:10:59.540
其他都接近零

0:10:59.540,0:11:03.320
像灰色，就是三個 RGB 的 value 都差不多

0:11:03.320,0:11:04.120
就是灰色

0:11:04.120,0:11:06.520
所以，如果你要這個

0:11:06.520,0:11:08.480
那它產生非常鮮明的顏色的話

0:11:08.480,0:11:11.360
你這三個值，要差得夠大才行

0:11:11.360,0:11:12.780
但是，你在 learn 的時候

0:11:12.780,0:11:15.120
你往往沒有辦法真的讓，比如說

0:11:15.120,0:11:16.940
G 是 0、B 是 0

0:11:16.940,0:11:19.120
你往往做不到這一件事

0:11:19.120,0:11:20.660
尤其，你今天如果是 output

0:11:20.660,0:11:22.460
你 output 把 0 到 255

0:11:22.460,0:11:24.340
normalize 到 0 到 1 之間的話

0:11:24.340,0:11:26.640
output 你用 sigmoid function 的話

0:11:26.640,0:11:29.340
sigmoid function 的值，通常都落在 0.5 左右

0:11:29.340,0:11:32.880
通常都落在中間，它很難落在這種極端的值

0:11:32.880,0:11:34.580
所以，它產生的值

0:11:34.580,0:11:37.240
都是 RGB 3 個值差不多

0:11:37.240,0:11:39.420
所以，你看起來每一張圖，看起來都是灰色，

0:11:39.420,0:11:41.180
棕色，這感覺不太好看

0:11:41.180,0:11:43.880
所以，我就稍微做了一下前處理

0:11:43.880,0:11:45.280
怎麼做前處理呢？

0:11:45.280,0:11:46.680
我把每一個 pixel

0:11:46.680,0:11:50.900
都用一個 1-of-N encoding 的 vector 來表示

0:11:50.900,0:11:52.280
但是 1-of-N encoding 裡面

0:11:52.280,0:11:53.620
每一個 dimension

0:11:53.620,0:11:54.920
就代表了一個顏色

0:11:54.920,0:11:57.640
也就是說每一個 pixel

0:11:57.640,0:11:59.700
都是用一個 vector來表示

0:11:59.700,0:12:01.640
這個 vector 的每一個 dimension

0:12:01.640,0:12:03.620
比如說，第一個 dimension 就代表黃色

0:12:03.620,0:12:05.240
第二個 dimension 就代表藍色

0:12:05.240,0:12:06.560
第三個 dimension 就代表綠色

0:12:06.560,0:12:07.740
第四個 dimension 就代表黑色，等等

0:12:07.740,0:12:10.100
也就是說，不讓它產生 RGB

0:12:10.100,0:12:11.640
去合成顏色

0:12:11.640,0:12:14.040
而是直接讓它產生一個顏色

0:12:14.040,0:12:15.540
所以，比如說

0:12:15.540,0:12:17.220
這個顏色進來， 這個綠色進來

0:12:17.220,0:12:21.000
那它就是這一維是 1

0:12:21.000,0:12:22.880
然後其他是 0

0:12:22.880,0:12:25.580
所以，一個 pixel，我們用這個方式來描述它

0:12:25.580,0:12:28.320
但是，這邊會有一個問題就是

0:12:28.320,0:12:30.340
你可能的顏色太多了

0:12:30.340,0:12:32.540
RGB 每一個都有 255 種可能

0:12:32.540,0:12:34.140
256種可能

0:12:34.140,0:12:35.280
256 的 3 次方

0:12:35.280,0:12:36.800
有太多可能的顏色

0:12:36.800,0:12:37.940
怎麼辦呢？

0:12:37.940,0:12:40.200
我先做 clustering

0:12:40.200,0:12:43.120
把同樣接近的顏色 cluster 在一起

0:12:43.120,0:12:44.040
也就是說

0:12:44.040,0:12:46.100
這個綠，跟這個綠，跟這個綠

0:12:46.100,0:12:47.380
它們算是同一個顏色

0:12:47.380,0:12:49.620
都用上面這個綠來表示它

0:12:49.620,0:12:52.320
那我就把在 corpus 裡面

0:12:52.320,0:12:55.200
出現次數比較少的這個顏色

0:12:55.200,0:12:56.940
跟出現次數比較多的顏色呢

0:12:56.940,0:12:58.560
把它合併起來

0:12:58.560,0:13:02.180
所以，我們得到了 167 個不同的顏色

0:13:02.180,0:13:05.280
那我 release 了這個 corpus

0:13:05.280,0:13:07.120
大家可以任意使用

0:13:07.120,0:13:08.640
這個 corpus 是這個樣子

0:13:08.640,0:13:12.020
原來 image 在這一邊，然後，我裁過的結果在這邊

0:13:12.020,0:13:13.440
那我這邊就直接存 pixel

0:13:13.440,0:13:16.360
所以你也不用做 preprocessing 了，都幫你做好了

0:13:16.360,0:13:17.700
在這個 data 裡面

0:13:17.700,0:13:21.180
每一個 row，就代表了一張 image

0:13:21.180,0:13:26.880
然後，每一個數字，就代表了一個顏色

0:13:26.880,0:13:28.280
就代表了一個顏色

0:13:28.280,0:13:30.800
那怎麼知道每個數字代表什麼顏色呢？

0:13:30.800,0:13:32.240
它的 mapping 在這一邊

0:13:32.240,0:13:36.080
比如說，0，它的 RGB 就都是 255, 255, 255

0:13:36.080,0:13:37.260
所以，0 代表白色

0:13:37.260,0:13:39.020
然後，比如說，這一邊

0:13:39.020,0:13:44.760
這個 2，2 代表三個都是49, 49, 49

0:13:44.760,0:13:48.100
這個其實是一個灰色，等等 

0:13:48.100,0:13:51.380
那我等一下就做這個 PixelRNN 的實驗

0:13:51.380,0:13:54.940
我發現，其實，你可能會懷疑說只有 700 多張圖

0:13:54.940,0:13:57.340
你 train 得起來嗎？

0:13:57.340,0:13:58.400
我 train 得起來，是 train 得起來

0:13:58.400,0:14:01.620
但問題就是，你可以得出什麼正常的好的結果嗎？

0:14:01.620,0:14:03.360
我發現驚人的就是

0:14:03.360,0:14:04.680
其實是可以的

0:14:04.680,0:14:06.900
然後，我沒有花太多時間調參數

0:14:06.900,0:14:08.960
我就用了一個一層的 LSTM

0:14:08.960,0:14:10.840
還有 512 個 cell

0:14:10.840,0:14:12.580
你不知道 LSTM 是什麼也沒有關係

0:14:12.580,0:14:14.180
反正，就是 learn 一個很簡單的 model

0:14:14.180,0:14:16.680
做出來的結果，就還算尚可

0:14:16.680,0:14:18.900
我相信，你認真調一下參數

0:14:18.900,0:14:21.220
一定可以做得比我好的，好的更多

0:14:21.220,0:14:23.540
這個是實驗的結果

0:14:23.540,0:14:24.880
首先要強調的是

0:14:24.880,0:14:27.540
我特意留了 3 張寶可夢

0:14:27.540,0:14:29.280
是 machine 沒有看過的

0:14:29.280,0:14:30.800
你在 training data 裡面

0:14:30.800,0:14:32.900
是沒有這三張寶可夢

0:14:32.900,0:14:37.600
接下來，我給 machine 看這個寶可夢的前半部

0:14:37.600,0:14:40.340
把剩下的半部，把它蓋起來

0:14:40.340,0:14:42.040
只給 machine 看前半部

0:14:42.040,0:14:45.340
然後，讓它 predict 這個寶可夢應該長什麼樣子

0:14:45.340,0:14:48.500
這個，你覺得它是什麼呢？

0:14:48.500,0:14:49.840
它看起來像是個兔子

0:14:49.840,0:14:50.820
紅色的兔子

0:14:50.820,0:14:53.300
然後，把它的下半身 generate 出來

0:14:53.300,0:14:54.340
它長這樣

0:14:54.340,0:14:56.860
它原來是有穿吊帶褲的兔子

0:14:56.860,0:14:59.980
但它其實是長這樣子

0:15:00.980,0:15:03.460
那你覺得這隻是什麼呢？

0:15:03.460,0:15:04.720
這一隻是甚麼？

0:15:04.720,0:15:07.660
感覺像是鐵甲蛹之類的東西

0:15:07.660,0:15:09.960
那 machine generate 出來結果是這個樣子

0:15:09.960,0:15:12.700
它是一個長的綠毛蟲

0:15:12.700,0:15:13.920
它是一個長的綠毛蟲

0:15:13.920,0:15:15.260
這個還有一個尾巴，這樣

0:15:15.260,0:15:16.640
它是一個綠毛蟲

0:15:16.640,0:15:18.740
但實際上，它是一隻蜥蜴

0:15:18.740,0:15:22.040
然後，這個呢，這個是什麼？

0:15:22.040,0:15:25.880
這個是什麼，這個 machine generate 出來

0:15:25.880,0:15:29.100
它覺得是一個類似狗或是狐狸的東西

0:15:29.100,0:15:30.100
它的臉很長

0:15:30.100,0:15:31.500
然後，這個是它的腳

0:15:31.500,0:15:32.520
這個是它的腳

0:15:32.520,0:15:33.720
machine還是要配色，你看

0:15:33.720,0:15:35.220
你看本來

0:15:35.220,0:15:37.900
本來這一邊它是沒有很多深紫色

0:15:37.900,0:15:39.640
但是到腳這邊，幫它塗一下深紫色這樣

0:15:39.640,0:15:41.240
我覺得還蠻強的，還蠻強的

0:15:41.240,0:15:43.960
但實際上，它其實是長這個樣子

0:15:45.400,0:15:47.480
如果，我們今天給它看

0:15:47.480,0:15:51.360
只有 25% 的圖 ，它會得到什麼

0:15:51.360,0:15:53.160
只給它看一個耳朵

0:15:53.160,0:15:54.580
它會覺得接下來是什麼

0:15:54.580,0:15:57.760
它產生這個臘腸兔這個樣子

0:15:57.760,0:15:59.300
臘腸兔

0:15:59.300,0:16:02.020
而且其實，我覺得 machine 還算蠻強的

0:16:02.020,0:16:03.480
你看它有手

0:16:03.480,0:16:05.320
它有手，它都把手畫出來

0:16:05.320,0:16:08.340
臘腸的兔，嘴巴跟眼睛，這個樣子

0:16:08.340,0:16:09.480
我覺得還蠻強的

0:16:09.480,0:16:13.020
這個給它看一個角

0:16:13.020,0:16:14.755
它會覺得是甚麼呢？

0:16:14.755,0:16:17.140
它覺得是鐵甲蛹這樣

0:16:17.140,0:16:19.320
類似鐵甲蛹，看起來像右邊

0:16:19.320,0:16:21.700
自己產生了一個，看起來很不爽的眼睛

0:16:21.700,0:16:23.380
鼻子，嘴巴這樣

0:16:23.380,0:16:26.880
這個，給它看上面一點點

0:16:26.880,0:16:28.320
也不知道是什麼東西

0:16:28.320,0:16:31.140
然後，它判斷出來，它覺得是這個樣子

0:16:31.140,0:16:32.860
你看它產生一個臉

0:16:32.860,0:16:34.640
它產生一個兔子的臉，這個是它的耳朵

0:16:34.640,0:16:35.860
這個是眼睛

0:16:35.860,0:16:37.420
這個是眼睛，想要翻白眼

0:16:37.420,0:16:38.940
然後，這個是它的鼻子

0:16:38.940,0:16:40.860
它產生一個臉

0:16:40.860,0:16:43.220
所以，我就覺得還蠻強的

0:16:43.220,0:16:45.880
而且，我覺得在做這種 task

0:16:45.880,0:16:49.000
有一個難點就是，你很難 evaluate 這個 task

0:16:49.000,0:16:51.660
因為，所謂創造這件事情

0:16:51.660,0:16:53.420
是無法 evaluate 的

0:16:53.420,0:16:56.600
你不能說，我覺得這個臘腸兔也很合理

0:16:56.600,0:16:58.780
我覺得搞不好還比這個蛞蝓更合理一點

0:16:58.780,0:17:04.760
就是說，它建得出來，並不一定要跟光圈一樣

0:17:04.760,0:17:06.600
它建出來的結果跟光圈不一樣

0:17:06.600,0:17:09.180
並不代表說，它畫的是錯的

0:17:09.180,0:17:11.360
所以，像這種 task

0:17:11.360,0:17:14.040
是很難被，很難被 evaluate 的

0:17:14.040,0:17:15.420
這是現在做這種

0:17:15.420,0:17:19.000
generation 的一個難點

0:17:19.000,0:17:22.140
剛才，是有給 machine 一個開頭

0:17:22.140,0:17:24.660
然後讓它畫下去

0:17:24.660,0:17:29.160
接下來，你就什麼都不給他

0:17:29.160,0:17:32.320
讓它從頭開始畫

0:17:32.320,0:17:35.200
但是，如果你只是什麼都不給它

0:17:35.200,0:17:36.740
讓它從頭開始畫的話

0:17:36.740,0:17:39.120
它可能每一張 image 都是一樣的

0:17:39.120,0:17:42.320
所以你要故意加一些 random

0:17:42.320,0:17:45.280
也就是說，它在 predict 下一個 pixel 的時候

0:17:45.280,0:17:48.940
不見得是選機率最高的，那個 pixel

0:17:48.940,0:17:52.300
它會有一定的機率，選一個

0:17:52.300,0:17:54.740
機率比較低的顏色出來

0:17:54.740,0:17:56.980
畫在圖上面，這樣它每一次畫的圖

0:17:56.980,0:17:58.440
都才會有點不一樣

0:17:58.440,0:18:03.280
那其實蠻多都是不知道是在做什麼的圖

0:18:03.280,0:18:04.880
比如說，像這個我都不知道在做什麼

0:18:04.880,0:18:06.780
這個看起來像是鳥的嘴巴

0:18:06.780,0:18:09.640
那，這個也許，也許是兩個眼睛

0:18:09.640,0:18:11.280
我也不知道它在畫什麼

0:18:11.280,0:18:14.320
這個是，看起來像是個兔子，像是個兔子

0:18:14.320,0:18:15.460
難道這個是它的臉嗎

0:18:15.460,0:18:17.640
難道這個是它戴了一個頭盔

0:18:17.640,0:18:19.460
我也不知道它在畫甚麼

0:18:19.460,0:18:21.180
有一些，我覺得比較清楚

0:18:21.180,0:18:23.560
像這個，我覺得它是一隻飛鳥

0:18:23.560,0:18:24.640
這是它的手

0:18:24.640,0:18:26.300
這個是一個大嘴鳥

0:18:26.300,0:18:27.300
這是它的嘴巴這樣

0:18:27.300,0:18:30.520
這個是一隻比較慘的鴕鳥

0:18:30.520,0:18:31.580
它是一個戴綠帽的駝鳥

0:18:36.200,0:18:39.660
然後，這個是地鼠

0:18:39.660,0:18:41.360
這個畫得還不錯，它還有配色

0:18:41.360,0:18:44.000
淺藍色配白色，這是個地鼠

0:18:44.000,0:18:45.500
它是有眼睛的

0:18:45.500,0:18:50.320
這個也是另外一隻比較大隻的地鼠

0:18:50.320,0:18:51.761
它頭上有一些藍藍紅紅的

0:18:51.761,0:18:52.940
它是比較大隻的地鼠

0:18:52.940,0:18:57.060
然後，這個是，我們胡亂給它取個名字

0:18:57.060,0:18:58.520
叫做岩漿模糊好了

0:18:58.520,0:19:01.000
它下面是岩漿，上面是雲

0:19:01.000,0:19:02.620
叫岩漿雲模糊好了

0:19:02.620,0:19:05.560
它上面，這個是有眼睛

0:19:05.560,0:19:08.620
不要小看它，它是有眼睛的，兩個眼睛都點出來了

0:19:08.620,0:19:11.400
這個是飛行骷髏

0:19:11.400,0:19:13.780
它也是有眼睛的

0:19:13.780,0:19:15.420
我發現這個 model 還蠻強的

0:19:15.420,0:19:16.440
它還蠻喜歡點眼睛出來

0:19:18.240,0:19:20.960
然後，還有其他方法

0:19:20.960,0:19:22.260
細節我們或許下次再講

0:19:22.260,0:19:24.420
我們可以稍微看一下它的結果

0:19:24.420,0:19:28.300
這個東西那叫做 Variational Autoencoder

0:19:28.300,0:19:31.100
那我們之前，已經有講過說

0:19:31.100,0:19:34.020
已經有講過 Auto-encoder

0:19:34.020,0:19:36.300
我們之前講過 Auto-encoder

0:19:36.300,0:19:38.880
那我們之前在講 Auto-encoder 的時候

0:19:38.880,0:19:40.780
我們說，你現在呢

0:19:40.780,0:19:42.520
Auto-encoder 的 training criteria

0:19:42.520,0:19:43.720
就是 input 一張 image

0:19:43.720,0:19:45.340
通過 encoder 就變成一個 code

0:19:45.340,0:19:47.700
再通過 decoder 把 image 解回來

0:19:47.700,0:19:49.060
那你希望 input 跟 output

0:19:49.060,0:19:51.080
越接近越好

0:19:51.080,0:19:52.700
希望 input 跟 output 越接近越好

0:19:52.700,0:19:55.660
那你 learn 完這個 Auto-encoder 以後

0:19:55.660,0:19:58.820
你其實就可以把這 decoder 拿出來

0:19:58.820,0:20:00.700
你就把 decoder 拿出來

0:20:00.700,0:20:03.860
然後，你再給它 input 一個

0:20:03.860,0:20:05.320
random 的東西

0:20:05.320,0:20:06.720
你再給它 input 一個

0:20:06.720,0:20:07.960
你 generate 一個 random 的 vector

0:20:07.960,0:20:10.220
把這個 random vector 當作是 一個 code

0:20:10.220,0:20:11.180
你這個 code 10 維

0:20:11.180,0:20:13.180
你就 generate 一個 10 維的 vector

0:20:13.180,0:20:15.300
然後，希望丟到這個 decoder 裡面

0:20:15.300,0:20:19.000
它 output ，就可以是一張完整的 image

0:20:19.000,0:20:21.700
但，實際上這麼做呢

0:20:21.700,0:20:24.760
你得到的 performance 通常不一定很好

0:20:24.760,0:20:26.040
你要用一個方法叫做

0:20:26.040,0:20:28.500
Variation Autoencoder ，VAE

0:20:28.500,0:20:30.900
你得到的結果會比較好

0:20:30.900,0:20:32.280
這個 VAE 怎麼做呢？

0:20:32.280,0:20:34.780
它的結構跟 Auto-encoder 非常像

0:20:34.780,0:20:39.020
它只是在中間加了一些神妙的小 trick

0:20:39.020,0:20:40.820
為什麼要加神妙的小 trick

0:20:40.820,0:20:42.160
或許我們下一次再講

0:20:42.160,0:20:43.920
這個神妙的小 trick 是什麼

0:20:43.920,0:20:47.640
它說，input一個 encoder

0:20:48.140,0:20:52.600
然後，這 encoder 跟 decoder 的部分維持原狀

0:20:52.600,0:20:53.800
維持原狀不動

0:20:53.800,0:20:56.860
但是，現在在 encoder 的地方

0:20:56.860,0:20:58.580
我們不是直接 output code

0:20:58.580,0:21:01.080
我們先 output 兩個 vector

0:21:01.080,0:21:02.280
我們先 output 兩個 vector

0:21:02.280,0:21:03.460
假設你的 code

0:21:03.460,0:21:05.320
你打算要做的 code 是三維的話

0:21:05.320,0:21:06.860
那你 output 的這兩個 vector 呢

0:21:06.860,0:21:08.720
也都是 3 維

0:21:08.720,0:21:10.260
這個 vector 是 m1, m2, m3

0:21:10.260,0:21:13.080
這個 vector 是 σ1, σ2, σ3

0:21:13.080,0:21:16.500
接下來，你用 normal distribution

0:21:16.500,0:21:19.280
去 generate 另外一個也是 3 維的 vector

0:21:19.280,0:21:21.600
它的 3 維分別是 e1, e2, e3

0:21:21.600,0:21:27.740
接下來，你把 σ1, σ2, σ3 取 exponential

0:21:27.740,0:21:29.940
跟 e1, e2, e3 相乘

0:21:29.940,0:21:31.840
跟 e1, e2, e3 相乘

0:21:31.840,0:21:35.680
然後，把它跟 m1, m2, m3 加起來

0:21:35.680,0:21:38.960
你得到這個 c1, c2, c3

0:21:38.960,0:21:41.700
這個東西呢，才是你的 code

0:21:41.700,0:21:43.700
這邊每一個 c 呢

0:21:43.700,0:21:50.660
這個 ci = exp(σi) * ei + mi

0:21:50.660,0:21:52.180
然後，丟到 decoder 裡面

0:21:52.180,0:21:58.540
希望說 decode 能夠 minimize reconstruction error

0:21:58.540,0:22:00.800
你希望你的 decoder 可以 minimize

0:22:00.800,0:22:02.560
reconstruction error

0:22:02.560,0:22:04.420
但是，光只有這麼做是不夠的

0:22:04.420,0:22:06.560
它還有第二項

0:22:06.560,0:22:07.960
這一項是說

0:22:07.960,0:22:10.440
這一項非常的神妙

0:22:10.440,0:22:11.960
我們之後再解釋

0:22:11.960,0:22:13.120
這一項是怎麼樣啊

0:22:13.120,0:22:14.400
你看，覺得很怪

0:22:14.400,0:22:18.340
這一項是，我們把它的三個 dimension 加起來

0:22:18.620,0:22:25.740
然後我們要去 minimize：1 + σi - (mi)^2 - exp(σi)

0:22:25.740,0:22:28.740
有這麼一項

0:22:28.740,0:22:30.300
minimize reconstruction error

0:22:30.300,0:22:32.540
同時 minimize 這一項

0:22:32.540,0:22:37.040
那你用 VAE 做出來結果怎麼樣呢？

0:22:37.040,0:22:41.660
這個是 OpenAI 做的結果

0:22:41.660,0:22:44.060
他們是做在 Cifar-10 上面

0:22:44.060,0:22:48.300
那你會發現說，其實用 VAE 得到的圖呢

0:22:48.300,0:22:50.220
它是不太清楚的

0:22:50.220,0:22:51.320
它是不太清楚的

0:22:51.320,0:22:53.040
這些圖你都

0:22:53.040,0:22:54.860
你看得出來，好像想要畫點什麼

0:22:54.860,0:22:56.720
但是你又搞不清楚，它到底在畫什麼

0:22:56.720,0:23:02.000
但是用 VAE 跟剛才的 PixelRNN 有什麼不一樣的地方呢

0:23:02.000,0:23:04.020
用 VAE 的話

0:23:04.020,0:23:05.560
你可以做以下的事情

0:23:05.560,0:23:09.120
你可以 control 你要 generate 的 image，理論上

0:23:09.120,0:23:11.240
你可以 control 你要 generate 的 image

0:23:11.240,0:23:12.740
什麼意思呢？

0:23:12.740,0:23:17.700
假設，我們現在把 VAE 用在 Pokémon creation 上面

0:23:17.700,0:23:19.540
那我們 training 的時候

0:23:19.540,0:23:21.220
就是 input 一個 Pokémon

0:23:21.220,0:23:23.880
然後 reconstruct 一樣的 Pokémon

0:23:23.880,0:23:25.980
然後 learn 出來這個 code

0:23:25.980,0:23:27.740
然後 learn 出來這個 code

0:23:27.740,0:23:29.320
我們就設 10 維

0:23:29.320,0:23:33.240
learn 好 這一個 Pokémon 的 VAE 以後

0:23:33.240,0:23:36.680
我們就把 decoder 的部分拿出來

0:23:36.680,0:23:39.460
因為，現在我們有一個 decoder

0:23:39.460,0:23:40.680
你可以 input 一個 vector

0:23:40.680,0:23:42.500
所以，你在 input 的 時候，你可以這樣做

0:23:42.500,0:23:45.200
你可以說，我現在有 10 維的 vector

0:23:45.280,0:23:46.980
我固定其中 8 維

0:23:46.980,0:23:48.820
只選其中的 2 維出來

0:23:48.820,0:23:53.280
然後，在這兩維的 dimension 上面

0:23:53.280,0:23:55.200
我灑不同的點

0:23:55.200,0:23:56.400
我灑不同的點

0:23:56.400,0:23:59.760
然後，我們把每一點都丟到 decoder 裡面

0:23:59.760,0:24:03.760
看它合出來的 image 長什麼樣子

0:24:03.760,0:24:07.020
那如果我們做這一件事情的話

0:24:07.020,0:24:09.000
如果我們灑不同的點的話

0:24:09.000,0:24:09.980
你就可以看到說

0:24:09.980,0:24:12.000
這個 code 的每一個 dimension

0:24:12.000,0:24:13.240
分別代表什麼意思

0:24:13.240,0:24:14.960
如果，我們可以解讀說

0:24:14.960,0:24:16.760
code 的每一個 dimension 代表什麼意思

0:24:16.760,0:24:18.460
以後我們就可以把那個 code

0:24:18.460,0:24:20.120
當作像是一個拉桿一樣

0:24:20.400,0:24:21.924
每一個 dimension 當作一個拉桿一樣

0:24:21.924,0:24:22.960
你可以調整它

0:24:22.960,0:24:25.080
你就可以產生不同的寶可夢

0:24:25.080,0:24:26.380
理想上是這樣子

0:24:26.380,0:24:31.480
那我們用 VAE 產生出來的結果是這個樣子

0:24:31.480,0:24:34.360
你可能覺得沒有很好

0:24:34.360,0:24:38.000
首先，你都看不出來每一隻是什麼

0:24:38.000,0:24:39.760
沒錯， 用 VAE 做出來就是這個樣子

0:24:39.760,0:24:43.000
那這兩個 dimension

0:24:43.000,0:24:45.420
分別是移動了

0:24:45.420,0:24:49.080
變化了兩個這個 code 的 兩個 dimension 以後的結果

0:24:49.080,0:24:51.860
但是，你從這個

0:24:51.860,0:24:54.120
你從這個變化，你可以看得出來說

0:24:54.120,0:24:57.280
每一個 dimension 其實或許它真的是有些含意的

0:24:57.280,0:25:00.940
比如說，如果我們看這一個變化

0:25:00.940,0:25:02.740
這個變化

0:25:02.740,0:25:06.820
它本來是看起來像是一個站著的東西

0:25:07.620,0:25:11.120
然後，它後來就逐漸倒下來，逐漸倒下來

0:25:11.120,0:25:14.200
演化，變成類似魚的東西

0:25:14.200,0:25:16.420
然後，後來就塌下來

0:25:16.420,0:25:18.420
塌下來，變成一個趴在地上的東西

0:25:18.420,0:25:21.660
如果你從左邊到右邊

0:25:21.660,0:25:23.940
你就會發它站的越來越直

0:25:23.940,0:25:27.860
它本來是，感覺是有點前傾的

0:25:27.860,0:25:31.320
越往右它就站得越來越直，它頭上會出現一個帽子

0:25:31.340,0:25:32.840
站得越來越直

0:25:32.840,0:25:36.480
所以，你可以從這樣的 dimension 變化發現說

0:25:36.480,0:25:38.460
它確實是有學到一些東西

0:25:38.460,0:25:40.640
如果我們可以讓圖產生更清楚的話

0:25:40.640,0:25:42.820
我們就可以控制這兩個 dimension

0:25:42.820,0:25:44.860
就可以產生不同的寶可夢

0:25:44.860,0:25:47.400
這邊是某兩個 dimension

0:25:47.400,0:25:49.780
這邊是另外兩個 dimension 的結果

0:25:49.780,0:25:52.280
這邊，這個的例子可能又更清楚一點

0:25:52.280,0:25:56.860
從右邊到左邊，本來是一個類倉鼠的樣子

0:25:56.860,0:26:00.040
後來就慢慢倒下來，倒下、倒下，然後變成一團布這樣

0:26:00.040,0:26:02.380
如果你看直的話

0:26:02.380,0:26:04.760
看直的話，它本來是一個倉鼠的樣子

0:26:04.760,0:26:07.420
倉鼠的樣子，從上面往下

0:26:07.420,0:26:10.600
你就會發現說，首先它的腳，越來越長

0:26:10.600,0:26:12.400
你就看到寶可夢的演化

0:26:12.400,0:26:15.800
它本來腳很短，後來越來越長、越來越長

0:26:15.800,0:26:20.120
後來變成有一隻很長的腳，看起來就變成像是鳥

0:26:20.120,0:26:22.080
後來就變成有兩隻很長的腳

0:26:22.080,0:26:25.300
後來又變成說，其實它是有四隻腳

0:26:25.300,0:26:27.160
看起來像似哺乳類的動物

0:26:27.160,0:26:28.380
這是它的演化

0:26:28.380,0:26:29.920
如果你看它的尾巴的話

0:26:29.920,0:26:30.980
本來尾巴很短

0:26:30.980,0:26:33.660
後來尾巴也越來越長

0:26:33.660,0:26:34.820
尾巴越來越長

0:26:34.820,0:26:36.800
如果你看它的頭的話

0:26:36.800,0:26:38.560
本來耳朵很短

0:26:38.560,0:26:41.060
後來耳朵越來越長

0:26:41.060,0:26:43.520
看起來就像是，長出了角一樣

0:26:43.520,0:26:46.460
就可以看到說，隨著 input 的 code 的不同

0:26:46.460,0:26:48.360
你就可以產生不同的寶可夢

0:26:48.360,0:26:50.440
但是，在這麼多圖裡面

0:26:50.440,0:26:53.700
你會發現都沒有清楚的，都沒看起來像樣的

0:26:53.700,0:26:54.860
那我先找到一個像樣的

0:26:54.860,0:26:56.120
就是在這一邊，這樣

0:26:56.120,0:26:58.540
我找到一個，這一邊這一隻

0:26:58.540,0:27:00.460
我想原來的寶可夢裡面應該是沒有這一隻

0:27:00.460,0:27:02.620
我看了，我翻了一下圖鑑

0:27:02.620,0:27:05.080
但是沒有很仔細翻，我覺得應該是沒有這一隻

0:27:05.080,0:27:06.380
它產生出來是這樣

0:27:06.380,0:27:09.820
看起來，它的頭像是一個海馬

0:27:09.820,0:27:12.480
然後它的尾巴，就叫做鱷魚

0:27:12.480,0:27:14.300
我們就胡亂叫它鱷魚海馬

0:27:18.780,0:27:22.440
然後，有人說可以用 VAE  來寫詩

0:27:22.440,0:27:24.320
怎麼用 VAE 來寫詩呢？

0:27:24.320,0:27:27.060
這個做法是這樣子的

0:27:27.320,0:27:31.260
本來這個 VAE 的 Auto-encoder

0:27:31.260,0:27:35.760
input 是一個 image，output 也是一個 image

0:27:35.760,0:27:37.940
現在只是把 input 跟 output 改掉

0:27:37.940,0:27:39.580
改成 input 一個 sentence

0:27:39.580,0:27:40.840
output 也是一個 sentence

0:27:40.840,0:27:43.900
不過，如果你要 input 處理 sentence 的 input

0:27:43.900,0:27:45.800
產生 sentence 的 output

0:27:45.800,0:27:49.140
這邊你需要用 RNN 才能夠做到

0:27:49.140,0:27:51.960
不過，這個我們之後再講

0:27:51.960,0:27:55.680
那怎麼讓 machine 寫詩呢？

0:27:55.680,0:27:57.360
這一邊的作法是這樣

0:27:57.360,0:28:00.500
你先胡亂選兩個句子

0:28:00.500,0:28:01.680
先胡亂選兩個句子

0:28:01.680,0:28:05.480
一個句子是 I went to  the store to  buy some groceries.

0:28:05.480,0:28:07.940
第二個句子是 "don't worry about it," she said.

0:28:07.940,0:28:10.520
接下來，你通過這個 encoder

0:28:10.520,0:28:14.120
這兩個句子，都找出它的 code

0:28:14.120,0:28:15.080
都找出它的 code

0:28:15.080,0:28:18.460
所以，這兩個句子就變成

0:28:18.460,0:28:20.540
在 code space 上面的兩個點

0:28:20.540,0:28:23.160
接下來呢，你把這兩個點相連

0:28:23.160,0:28:26.840
然後，中間等間隔的取一些點

0:28:26.840,0:28:29.220
再把中間等間隔取的點呢

0:28:29.220,0:28:34.580
你就把這個 code 丟到 decode 裡面，再還原出去

0:28:34.580,0:28:37.720
所以，把這一個點稍微偏一點以後

0:28:37.720,0:28:40.120
把 I went to  the store to buy some groceries.

0:28:40.120,0:28:41.180
稍微偏一點以後

0:28:41.180,0:28:42.520
你得到的句子就是

0:28:42.520,0:28:44.940
I store to buy some groceries.

0:28:44.940,0:28:46.000
再偏一點以後

0:28:46.000,0:28:49.680
你就得到 I were to  buy any groceries.

0:28:49.680,0:28:51.480
就這樣一直下來，一直下來

0:28:51.480,0:28:52.860
到這一邊呢

0:28:52.860,0:28:56.080
變成 "come with me," she said

0:28:56.080,0:28:57.560
然後 "talk to  me," she said.

0:28:57.560,0:28:58.900
然後變成 "don't worry about it," she said.

0:28:58.900,0:29:02.280
你可能會說，這個算是寫詩嗎？

0:29:02.280,0:29:04.340
這個是這樣

0:29:04.340,0:29:05.820
如果你仔細看他的 paper 的話

0:29:05.820,0:29:07.840
他的 paper 裡面沒有提到寫詩這一件事情

0:29:07.840,0:29:09.820
在這個 blog 裡面說是

0:29:09.820,0:29:11.460
說是這樣子是在寫詩就是了'

0:29:11.460,0:29:13.260
我不知道這個 blog 是誰寫的

0:29:13.260,0:29:16.200
大概就是這個樣子

0:29:16.880,0:29:18.380
那 GAN 的部分

0:29:18.380,0:29:21.640
我們就下一次再講

0:29:21.640,0:29:25.640
我們先就休息10 分鐘，等一下來講一下 final

0:29:28.840,0:29:34.000
臺灣大學人工智慧中心
科技部人工智慧技術暨全幅健康照護聯合研究中心
http://aintu.tw
