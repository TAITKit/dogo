<head><meta http-equiv='Content-Type' content='text/html; charset=utf-8'></head>
﻿0:00:00.000,0:00:02.720<br>
臺灣大學人工智慧中心<br>
科技部人工智慧技術暨全幅健康照護聯合研究中心<br>
http://aintu.tw<br>
<br>
0:00:02.720,0:00:09.100<br>
去找最小的、最好的 function，<br>
再來我們要問的問題是，我們上一次有看到說<br>
<br>
0:00:09.760,0:00:13.080<br>
如果你選擇不同的 function set<br>
<br>
0:00:13.080,0:00:15.020<br>
你就是選擇不同的 model<br>
<br>
0:00:15.020,0:00:17.340<br>
你在 testing data 上也會得到不同的error<br>
<br>
0:00:17.340,0:00:19.340<br>
你在 testing data 上也會得到不同的error<br>
<br>
0:00:19.600,0:00:26.080<br>
而且越複雜的 model 不見得會給你越低的 error<br>
<br>
0:00:26.980,0:00:28.960<br>
你會發現說<br>
<br>
0:00:28.980,0:00:32.600<br>
1 到 5 分別代表說我們今天<br>
<br>
0:00:33.100,0:00:34.640<br>
做 linear regression 的時候<br>
<br>
0:00:35.080,0:00:40.200<br>
我們考慮的 input 是 1 次、1 次 2 次、<br>
1 次 2 次 3 次一直到 1 次到 5 次<br>
<br>
0:00:40.600,0:00:43.340<br>
那你發現，最複雜的model，<br>
其實它的 performance 是最差的<br>
<br>
0:00:43.340,0:00:45.340<br>
今天我們要討論的問題就是<br>
<br>
0:00:45.340,0:00:50.700<br>
這個 error 來自什麼地方。<br>
<br>
0:00:53.340,0:00:55.340<br>
其實 error 有兩個來源<br>
<br>
0:00:55.340,0:00:57.340<br>
一個是來自於 bias<br>
<br>
0:00:57.340,0:00:59.340<br>
一個是來自於 variance。<br>
<br>
0:00:59.900,0:01:02.540<br>
了解這個 error 的來源其實是重要的<br>
<br>
0:01:02.540,0:01:06.580<br>
因為你常常做一下 machine learning<br>
<br>
0:01:06.580,0:01:09.340<br>
然後做完就發現說，得到一個 error rate<br>
<br>
0:01:09.340,0:01:11.340<br>
比如說 60% 的 error rate<br>
<br>
0:01:11.340,0:01:13.340<br>
接下來你要怎麼 improve 你的 model 呢？<br>
<br>
0:01:13.340,0:01:15.340<br>
如果你沒有什麼方向的話<br>
<br>
0:01:15.340,0:01:17.340<br>
毫無頭緒的亂做，你就沒有效率<br>
<br>
0:01:17.340,0:01:21.280<br>
如果你今天可以診斷你的 error 的來源<br>
<br>
0:01:21.340,0:01:26.000<br>
比如說 error 可以分成兩種，<br>
一種是來自 bias，一種是來自 variance<br>
<br>
0:01:26.000,0:01:27.340<br>
如果你可以診斷你的 error 的來源<br>
<br>
0:01:27.340,0:01:31.460<br>
你就可以挑選適當的方法來 improve 你的 model<br>
<br>
0:01:34.940,0:01:39.340<br>
我們在上週的時候<br>
<br>
0:01:39.340,0:01:41.280<br>
我們舉的例子是這樣<br>
<br>
0:01:41.340,0:01:45.700<br>
我們要做寶可夢進化後的 CP值的估測<br>
<br>
0:01:45.700,0:01:48.200<br>
也就是說我們要找一個 function<br>
<br>
0:01:48.300,0:01:50.740<br>
這個 function input 一隻寶可夢<br>
<br>
0:01:50.740,0:01:53.000<br>
output 就是他進化以後的 CP 值<br>
<br>
0:01:53.000,0:01:54.420<br>
那這個 function<br>
<br>
0:01:54.420,0:01:55.740<br>
理論上<br>
<br>
0:01:56.280,0:01:58.900<br>
有一個最佳的 function<br>
<br>
0:01:58.900,0:02:01.340<br>
這個理論上最佳的 function<br>
<br>
0:02:01.340,0:02:02.760<br>
我們寫成 f̂<br>
<br>
0:02:02.980,0:02:05.340<br>
那這個理論上最佳的 function 我們是不知道的<br>
<br>
0:02:05.340,0:02:06.940<br>
只有 Niantic 知道<br>
<br>
0:02:06.940,0:02:09.340<br>
Niantic 大家知道是甚麼嗎？就是做寶可夢的那個公司<br>
<br>
0:02:10.480,0:02:12.880<br>
因為他一定是用那個程式寫出來的<br>
<br>
0:02:12.880,0:02:15.040<br>
所以如果你知道那個程式的話<br>
<br>
0:02:15.040,0:02:17.340<br>
你就可以知道 input 一個寶可夢<br>
<br>
0:02:17.340,0:02:21.180<br>
照理說， output 他的進化後的 CP 值應該是甚麼<br>
<br>
0:02:21.340,0:02:23.340<br>
但是問題就是這個function，<br>
<br>
0:02:23.340,0:02:26.240<br>
f̂  是你不知道的<br>
<br>
0:02:26.540,0:02:28.320<br>
那你能夠做的事情是<br>
<br>
0:02:28.320,0:02:30.160<br>
你有一些 training data<br>
<br>
0:02:30.160,0:02:31.980<br>
你實際去抓一些寶可夢<br>
<br>
0:02:32.220,0:02:34.300<br>
然後去找一個<br>
<br>
0:02:34.420,0:02:38.260<br>
根據你的 training data 所學出來、所找到的<br>
<br>
0:02:38.260,0:02:40.780<br>
最好的function f*<br>
<br>
0:02:40.820,0:02:44.880<br>
那這個 f* 並不會真的等於 f̂<br>
<br>
0:02:45.180,0:02:47.340<br>
因為根本不知道真的 f̂ 是什麼樣子。<br>
<br>
0:02:47.340,0:02:49.420<br>
那個 f* 可能不等於 f̂<br>
<br>
0:02:49.520,0:02:53.040<br>
這個 f* 呢，它就好像是一個 f̂ 的估測值一樣<br>
<br>
0:02:53.340,0:02:55.340<br>
它的 estimator 一樣<br>
<br>
0:02:55.720,0:02:58.180<br>
所以就想成說現在是在打靶<br>
<br>
0:02:58.500,0:03:00.800<br>
f̂ 是靶的中心點<br>
<br>
0:03:01.340,0:03:03.340<br>
你今天收集到一些 data 做 training 以後<br>
<br>
0:03:03.540,0:03:06.360<br>
你找到一個你覺得最好的 function f*<br>
<br>
0:03:06.840,0:03:08.540<br>
這個 f* 它不等於 f̂<br>
<br>
0:03:08.820,0:03:11.160<br>
它是在把紙上的另外一個位置<br>
<br>
0:03:11.160,0:03:13.340<br>
這個 f* 跟這個 f̂<br>
<br>
0:03:13.340,0:03:15.340<br>
它們中間有一段距離<br>
<br>
0:03:16.280,0:03:18.880<br>
這個距離來自於兩件事<br>
<br>
0:03:19.060,0:03:21.340<br>
它可能來自於 bias<br>
<br>
0:03:22.160,0:03:24.160<br>
也有可能來自於 variance<br>
<br>
0:03:24.940,0:03:28.680<br>
那一個 estimator 的 bias 和 variance 指的是甚麼呢？<br>
<br>
0:03:29.020,0:03:32.140<br>
我們先舉一個你在機率裡面看過的例子<br>
<br>
0:03:32.560,0:03:33.960<br>
這個地方在機率<br>
<br>
0:03:34.180,0:03:36.320<br>
我想應該是機率與統計，你應該是學過的<br>
<br>
0:03:36.740,0:03:38.140<br>
所以你可以很快地看過去<br>
<br>
0:03:38.380,0:03:41.260<br>
假設我們現在有一個 variable x<br>
<br>
0:03:41.340,0:03:43.340<br>
我想要估測它的 mean<br>
<br>
0:03:43.340,0:03:44.840<br>
怎麼做呢？<br>
<br>
0:03:44.840,0:03:47.340<br>
假設這個 variable x 它的 mean 是 μ<br>
<br>
0:03:47.340,0:03:49.800<br>
它的 variance 是 σ²<br>
<br>
0:03:50.600,0:03:52.740<br>
那我要估測 mean 的話<br>
<br>
0:03:53.040,0:03:54.400<br>
我怎麼做呢？<br>
<br>
0:03:54.740,0:03:56.380<br>
我就先 sample N 個點<br>
<br>
0:03:56.380,0:03:58.660<br>
我就對這個 variable sample N 個點<br>
<br>
0:03:58.660,0:04:00.680<br>
x^1, x^2....到 x^N<br>
<br>
0:04:00.920,0:04:06.400<br>
我們再把這 N 個點算平均值得到 m<br>
<br>
0:04:07.220,0:04:10.840<br>
這個N個點算出來的平均值會跟μ一樣嗎？<br>
<br>
0:04:11.340,0:04:12.980<br>
其實不會，對不對？<br>
<br>
0:04:12.980,0:04:14.500<br>
除非你 sample 無窮多個點<br>
<br>
0:04:14.500,0:04:18.460<br>
不然如果你只 sample 比如說 5 個點、10 個點，<br>
n = 5 跟 10<br>
<br>
0:04:18.660,0:04:21.340<br>
這個 μ 跟 m 它們不見得是一樣的<br>
<br>
0:04:22.120,0:04:22.980<br>
所以<br>
<br>
0:04:23.060,0:04:25.340<br>
假設這個是 μ 的 value<br>
<br>
0:04:26.220,0:04:28.600<br>
現在你做一次sample<br>
<br>
0:04:29.340,0:04:33.120<br>
你 sample n 個點算出來的 m 可能不會跟 μ 一樣。<br>
<br>
0:04:33.340,0:04:36.720<br>
做第一次實驗做出 m1，有可能跟 μ 不一樣<br>
<br>
0:04:36.960,0:04:38.960<br>
再做一次實驗 m2，也跟 μ 不一樣<br>
<br>
0:04:39.020,0:04:40.980<br>
m3 也跟 μ 不一樣，m4 也跟 μ 不一樣<br>
<br>
0:04:40.980,0:04:42.660<br>
m5 不一樣，m6 也不一樣，等等<br>
<br>
0:04:42.660,0:04:45.200<br>
你沒有辦法找到一個 m 正好 exactly 等於 μ<br>
<br>
0:04:45.340,0:04:50.700<br>
但是如果你今天把你的 m 的期望值算出來的話，<br>
<br>
0:04:51.000,0:04:53.000<br>
假如你算 E[m]<br>
<br>
0:04:53.340,0:04:55.340<br>
m 就是這個式子，把它代進來<br>
<br>
0:04:55.420,0:04:58.020<br>
然後用國小數學把 1 放進去<br>
<br>
0:04:58.800,0:05:03.140<br>
然後你就得到 x^n 的期望值 summation over n，取 1/N<br>
<br>
0:05:03.800,0:05:06.700<br>
反正得到的值，就是 μ 這樣。<br>
<br>
0:05:07.120,0:05:12.580<br>
所以今天每一個 m 雖然都不一定跟 μ exactly 一樣<br>
<br>
0:05:13.000,0:05:15.000<br>
但是如果你找很多 m<br>
<br>
0:05:15.340,0:05:19.160<br>
它們的期望值會正好等於 μ<br>
<br>
0:05:19.980,0:05:21.980<br>
所以用 m 來 estimate μ<br>
<br>
0:05:22.280,0:05:24.280<br>
m 這個 estimator<br>
<br>
0:05:24.560,0:05:25.960<br>
它是 unbiased<br>
<br>
0:05:26.480,0:05:29.740<br>
因為他的期望值會正好等於μ<br>
<br>
0:05:29.740,0:05:30.860<br>
就好像是說<br>
<br>
0:05:31.080,0:05:33.080<br>
如果你在打靶的時候<br>
<br>
0:05:33.340,0:05:35.340<br>
他的準心是瞄準 μ 的<br>
<br>
0:05:35.340,0:05:38.240<br>
但是因為種種比如說機械故障<br>
<br>
0:05:38.480,0:05:41.280<br>
或者受到其他各種風速的干擾等等<br>
<br>
0:05:42.080,0:05:45.580<br>
你會散落在你本來瞄準的位置的周圍<br>
<br>
0:05:48.960,0:05:52.380<br>
那這個散佈在周圍，會散的多開呢？<br>
<br>
0:05:52.600,0:05:53.240<br>
取決於<br>
<br>
0:05:53.340,0:05:55.340<br>
m 的 variance<br>
<br>
0:05:56.280,0:05:59.440<br>
那這個 Var[m] 就是 σ²/N<br>
<br>
0:05:59.500,0:06:01.400<br>
所以你就不要問怎麼來的<br>
<br>
0:06:01.560,0:06:03.260<br>
這個機率課本都有寫<br>
<br>
0:06:03.320,0:06:05.320<br>
那這個 variance 的值呢<br>
<br>
0:06:05.340,0:06:06.940<br>
它 depend on<br>
<br>
0:06:06.980,0:06:09.340<br>
你今天取了多少的 sample<br>
<br>
0:06:10.380,0:06:12.460<br>
如果你今天的 N 呢<br>
<br>
0:06:13.340,0:06:15.720<br>
嗯我發現一個錯耶，你有發現嗎？<br>
<br>
0:06:16.120,0:06:18.900<br>
我今天把 larger 和 smaller 放反了<br>
<br>
0:06:19.340,0:06:20.560<br>
不好意思<br>
<br>
0:06:20.720,0:06:24.840<br>
這個 larger 和 smaller 它們應該是反過來的<br>
<br>
0:06:25.340,0:06:27.320<br>
如果你有比較多的 N 的話<br>
<br>
0:06:27.580,0:06:31.340<br>
它的散佈就會比較集中<br>
<br>
0:06:31.720,0:06:33.960<br>
如果你只取比較少的 N 的話<br>
<br>
0:06:34.300,0:06:37.380<br>
你那個 m 就會分散的比較開<br>
<br>
0:06:38.420,0:06:42.360<br>
如果你要估測 variance 怎麼辦呢？<br>
<br>
0:06:42.820,0:06:44.820<br>
你就先用剛才的辦法估測 m<br>
<br>
0:06:45.060,0:06:46.620<br>
估測 m 以後<br>
<br>
0:06:47.040,0:06:49.020<br>
你再計算 (x^n-m)²<br>
<br>
0:06:49.020,0:06:51.020<br>
再取它們的平均值<br>
<br>
0:06:51.040,0:06:53.040<br>
你得到另外的值是 s²<br>
<br>
0:06:53.200,0:06:55.340<br>
這個 s² 可以拿來估測 σ²<br>
<br>
0:06:57.040,0:07:00.340<br>
這個 s² 它估測的怎麼樣呢?<br>
<br>
0:07:01.460,0:07:04.640<br>
當然每一次你算一個 s 出來<br>
<br>
0:07:04.760,0:07:06.660<br>
它們跟 σ<br>
<br>
0:07:06.660,0:07:10.000<br>
這邊我應該要把它取平方才對<br>
<br>
0:07:10.340,0:07:12.920<br>
因為 s² 才是 σ² 的估測值<br>
<br>
0:07:13.080,0:07:15.160<br>
假設我這邊有取平方好了<br>
<br>
0:07:15.400,0:07:18.340<br>
我們每一次取出來的 s<br>
<br>
0:07:18.780,0:07:20.780<br>
它會散佈在，它不會跟 σ 正好一樣<br>
<br>
0:07:21.340,0:07:23.600<br>
它散佈在 σ 的周圍<br>
<br>
0:07:23.600,0:07:26.360<br>
但是這個 estimator 它是 biased<br>
<br>
0:07:26.520,0:07:32.140<br>
也就是說如果你取 s² 的期望值的話<br>
<br>
0:07:32.520,0:07:35.240<br>
它算出來並不是正好等於 σ²<br>
<br>
0:07:35.340,0:07:38.100<br>
它是 N-1/N<br>
<br>
0:07:38.900,0:07:42.440<br>
所以你會發現普遍而言<br>
<br>
0:07:42.800,0:07:46.800<br>
s² 是比 σ² 還要小的<br>
<br>
0:07:47.040,0:07:48.900<br>
就是小的次數比較多<br>
<br>
0:07:48.900,0:07:50.920<br>
但因為有 variance 所以也有可能比較大<br>
<br>
0:07:50.920,0:07:53.340<br>
但是平均而言小的次數是比較多的<br>
<br>
0:07:54.380,0:07:56.380<br>
如果你 increase N 的話<br>
<br>
0:07:56.580,0:07:58.560<br>
如果 N 比較大的話<br>
<br>
0:07:58.560,0:08:06.920<br>
那 σ² 跟 s² 估測之間的差距就會變小<br>
<br>
0:08:09.340,0:08:11.640<br>
好，那說了這些<br>
<br>
0:08:12.320,0:08:14.860<br>
我們回到 regression 這個問題來<br>
<br>
0:08:15.100,0:08:17.500<br>
比如說我們現在要估測的是<br>
<br>
0:08:17.820,0:08:19.340<br>
靶的中心<br>
<br>
0:08:19.340,0:08:21.340<br>
也就是 f̂<br>
<br>
0:08:21.340,0:08:23.340<br>
這個是我們的目標<br>
<br>
0:08:23.940,0:08:26.640<br>
那你 collect 一些 data<br>
<br>
0:08:26.860,0:08:28.460<br>
做一次實驗<br>
<br>
0:08:28.740,0:08:33.240<br>
你找出來的 f* 可能是在這個位置<br>
<br>
0:08:33.980,0:08:36.860<br>
這個位置跟這個紅心之間<br>
<br>
0:08:37.340,0:08:40.940<br>
它們其實有發生了兩件事<br>
<br>
0:08:41.340,0:08:43.400<br>
它們這個 error 取決於兩件事<br>
<br>
0:08:44.280,0:08:48.260<br>
第一件事情是你瞄準的位置在哪裡<br>
<br>
0:08:48.860,0:08:51.760<br>
就是你這個 estimator 是不是 bias<br>
<br>
0:08:51.940,0:08:54.300<br>
怎麼知道 estimator 是不是 bias 呢？<br>
<br>
0:08:54.620,0:08:57.220<br>
你把這個estimator f*<br>
<br>
0:08:57.500,0:09:01.340<br>
假設你可以做很多次實驗<br>
<br>
0:09:01.900,0:09:05.440<br>
那你把這個 f* 的期望值算出來<br>
<br>
0:09:05.760,0:09:07.760<br>
我們這邊寫成 f\bar<br>
<br>
0:09:08.360,0:09:09.720<br>
bar 就是平均的意思<br>
<br>
0:09:10.020,0:09:13.020<br>
f* 的期望值算出來就是 f\bar<br>
<br>
0:09:13.960,0:09:18.120<br>
那你會發現說，假設我們用右下角這個例子來看<br>
<br>
0:09:18.360,0:09:20.940<br>
你做了很多次實驗，找了很多不同的 f\bar<br>
<br>
0:09:22.080,0:09:24.600<br>
你會發現它們的散佈是這些藍色的點<br>
<br>
0:09:25.020,0:09:28.060<br>
這個時候你的 f* 呢，可能是在這個地方<br>
<br>
0:09:28.520,0:09:32.180<br>
那也就是說你的這個 estimator<br>
<br>
0:09:32.620,0:09:36.200<br>
跟你的靶心中間是有一個 bias 的<br>
<br>
0:09:36.820,0:09:39.660<br>
也就是說你瞄的時候就沒有瞄準<br>
<br>
0:09:39.860,0:09:42.660<br>
你以為正中心在這邊，你瞄這個點<br>
<br>
0:09:42.660,0:09:44.960<br>
那實際上呢，靶心是在這個地方<br>
<br>
0:09:45.260,0:09:47.820<br>
你瞄的時候就沒有瞄準<br>
<br>
0:09:48.060,0:09:49.680<br>
但這還有另外一個 error<br>
<br>
0:09:49.680,0:09:54.600<br>
這個 error 來自於你瞄準的這個位置<br>
<br>
0:09:55.060,0:09:57.720<br>
但是你把子彈射出去以後呢<br>
<br>
0:09:57.840,0:09:59.040<br>
還是會有偏移的<br>
<br>
0:09:59.180,0:10:01.480<br>
你瞄準這個位置，但是射出去還是會有偏移的<br>
<br>
0:10:01.680,0:10:03.680<br>
所以你每次找出來的 f* 是不一樣的<br>
<br>
0:10:03.940,0:10:07.120<br>
而這個 f* 跟你瞄準的位置<br>
<br>
0:10:07.760,0:10:10.800<br>
也就是 f* 期望值 f\bar 中間的距離呢<br>
<br>
0:10:11.060,0:10:12.120<br>
就是 variance<br>
<br>
0:10:12.380,0:10:13.900<br>
所以你的錯誤來自於兩件事<br>
<br>
0:10:14.080,0:10:15.460<br>
一件事情是<br>
<br>
0:10:16.200,0:10:17.960<br>
你的 bias 有多大<br>
<br>
0:10:18.300,0:10:21.200<br>
另外一件事情呢，是你的 variance 有多大<br>
<br>
0:10:21.320,0:10:23.000<br>
所以最理想的狀況是<br>
<br>
0:10:23.280,0:10:25.200<br>
我們期待的是<br>
<br>
0:10:25.200,0:10:28.260<br>
你同時沒有 bias，variance 又小<br>
<br>
0:10:28.420,0:10:32.220<br>
這樣你每次做實驗，你找出來的每個 f* 都是好的<br>
<br>
0:10:33.160,0:10:36.040<br>
那如果說今天<br>
<br>
0:10:36.220,0:10:38.620<br>
你有可能遇到一個狀況是<br>
<br>
0:10:38.960,0:10:41.860<br>
你的 bias 很大，但 variance 很小<br>
<br>
0:10:42.080,0:10:47.260<br>
那你每一次找的 f* 都很像，但是都集中在這個錯的位置<br>
<br>
0:10:47.260,0:10:48.380<br>
那你總是有錯<br>
<br>
0:10:48.540,0:10:50.260<br>
那也有可能是<br>
<br>
0:10:50.280,0:10:55.400<br>
你今天找出來的 f\bar 呢，是沒有 bias 的<br>
<br>
0:10:55.480,0:10:58.080<br>
你瞄的位置是對的，但是你那個槍性能很差<br>
<br>
0:10:58.080,0:11:00.060<br>
所以它每次射出去以後呢，是散佈在<br>
<br>
0:11:00.080,0:11:01.820<br>
這個靶心的周圍的<br>
<br>
0:11:02.080,0:11:04.860<br>
那你也會得到一些 error，所以<br>
<br>
0:11:05.000,0:11:09.000<br>
error 來自於兩個地方，一個是你瞄準的位置在哪裡<br>
<br>
0:11:09.000,0:11:12.620<br>
另外一個是你今天的這個 variance 有多大<br>
<br>
0:11:12.820,0:11:14.620<br>
可是有的人會問一個問題<br>
<br>
0:11:14.920,0:11:17.620<br>
你不就只能做一次實驗嗎？<br>
<br>
0:11:18.180,0:11:20.340<br>
如果你上周有來的話<br>
<br>
0:11:20.380,0:11:25.040<br>
你不就 collect 了十筆 data，然後就找一個 f*，然後就結束了嗎？<br>
<br>
0:11:25.300,0:11:28.880<br>
你怎麼找很多個 f* 呢？<br>
<br>
0:11:29.180,0:11:32.540<br>
你怎麼知道它的 variance 跟 bias 有多大呢？<br>
<br>
0:11:32.680,0:11:34.300<br>
你怎麼找很多個 f* 呢？<br>
<br>
0:11:34.520,0:11:36.000<br>
所以，這個怎麼想<br>
<br>
0:11:36.180,0:11:39.520<br>
你就假設說這個世界上是有很多的平行的 宇宙的<br>
<br>
0:11:39.660,0:11:41.920<br>
我們知道有很多的平行的宇宙<br>
<br>
0:11:41.920,0:11:44.180<br>
在很多個平行宇宙，在每一個宇宙都不一樣<br>
<br>
0:11:44.320,0:11:46.320<br>
但是我們都在抓寶可夢這樣子<br>
<br>
0:11:46.520,0:11:48.520<br>
在每一個平行宇宙裡面<br>
<br>
0:11:48.600,0:11:52.560<br>
我們都想 estimate 進化後的 CP 值<br>
<br>
0:11:52.980,0:11:54.740<br>
所以在每個平行宇宙裡面呢<br>
<br>
0:11:54.820,0:11:58.260<br>
我都去抓了 10 個寶可夢然後來算 f*<br>
<br>
0:11:58.420,0:12:02.920<br>
我們抓到的寶可夢呢，是不一樣的<br>
<br>
0:12:03.060,0:12:06.000<br>
在不同宇宙裡面，抓到的 10 之寶可夢是不一樣的<br>
<br>
0:12:06.080,0:12:08.220<br>
這個是第一個宇宙中的我這樣子<br>
<br>
0:12:08.220,0:12:10.220<br>
然後抓到的是這 10 隻<br>
<br>
0:12:10.220,0:12:12.960<br>
這個是第二個宇宙中的我，<br>
其實只是衣服換一個顏色而已<br>
<br>
0:12:12.960,0:12:14.620<br>
你抓到的是這 10 隻<br>
<br>
0:12:14.620,0:12:18.540<br>
這個是第三個宇宙中的我，這時候性別也換了<br>
然後抓到的是這 10 隻<br>
<br>
0:12:18.800,0:12:21.040<br>
好那因為抓到的寶可夢是不一樣的<br>
<br>
0:12:21.340,0:12:27.840<br>
如果你拿不同的寶可夢來找你的最好的 function<br>
<br>
0:12:28.080,0:12:30.500<br>
就算你用同一個 model<br>
<br>
0:12:30.560,0:12:36.540<br>
假設我們現在都用 y = b + w * x_cp，這個 model<br>
<br>
0:12:36.860,0:12:40.160<br>
我們用同樣的 model，但你給它的 data 不一樣<br>
<br>
0:12:40.280,0:12:43.060<br>
那你找出來的最好的 function f* 就是不一樣的<br>
<br>
0:12:43.060,0:12:45.220<br>
所以在宇宙編號 123 號<br>
<br>
0:12:45.220,0:12:48.160<br>
我們抓到的這 10 隻寶可夢<br>
<br>
0:12:48.160,0:12:51.040<br>
用這個 model，我們找出來的 f* 是這樣<br>
<br>
0:12:52.020,0:12:55.080<br>
在宇宙編號 345 號裡面<br>
<br>
0:12:55.180,0:12:57.180<br>
我們找到另外 10 隻寶可夢<br>
<br>
0:12:57.260,0:12:59.420<br>
我們找到的 model 是這個樣子<br>
<br>
0:12:59.540,0:13:04.760<br>
這兩個 model 是不一樣的，在不同宇宙裡面<br>
我們找到的 f* 是不一樣的<br>
<br>
0:13:05.220,0:13:06.740<br>
好現在我們的問題就是<br>
<br>
0:13:06.740,0:13:10.800<br>
每一個宇宙找出來的 f* 就像對著把只開一槍一樣<br>
<br>
0:13:10.800,0:13:12.420<br>
那我們現在就是要知道說<br>
<br>
0:13:12.420,0:13:15.380<br>
它的散佈是甚麼樣子的<br>
<br>
0:13:15.380,0:13:20.980<br>
好，所以我們就把 100 個不同宇宙裡面的 f* 都找出來<br>
<br>
0:13:20.980,0:13:23.060<br>
當然世界上並沒有真的平行宇宙<br>
<br>
0:13:23.060,0:13:25.200<br>
所以做這件事情其實就是<br>
<br>
0:13:25.460,0:13:30.260<br>
你就做 100 次實驗，然後<br>
每次都抓 10 隻不同的寶可夢就是了<br>
<br>
0:13:30.900,0:13:32.680<br>
你了解我的意思<br>
<br>
0:13:32.760,0:13:35.540<br>
在 100 個平行宇宙裡面<br>
<br>
0:13:35.580,0:13:38.100<br>
我們都抓了 10 隻不同的寶可夢<br>
<br>
0:13:38.100,0:13:41.200<br>
然後，都去找一個 f*<br>
<br>
0:13:41.300,0:13:46.680<br>
那今天如果我的 model 是 y = b + w * x_cp<br>
<br>
0:13:47.380,0:13:50.560<br>
那這 100 個 f* 它們的分佈長甚麼樣子呢？<br>
<br>
0:13:50.560,0:13:52.560<br>
如果我們把這 100 個 f*<br>
<br>
0:13:52.560,0:13:56.880<br>
這 100 個 y = b + w * x_cp 畫出來，會長這樣<br>
<br>
0:13:57.260,0:14:00.880<br>
所以有 100 個不同的 w，100 個不同的 b<br>
<br>
0:14:00.880,0:14:02.900<br>
你把這 100 條直線都畫出來<br>
<br>
0:14:02.960,0:14:04.960<br>
它會長成這個樣子<br>
<br>
0:14:05.040,0:14:07.040<br>
這邊有 100 條直線<br>
<br>
0:14:07.080,0:14:09.120<br>
那如果我今天換另外一個 model<br>
<br>
0:14:09.120,0:14:10.640<br>
你換一個 model<br>
<br>
0:14:10.640,0:14:15.220<br>
這個 model 是考慮了  x_cp,  (x_cp)^2,  (x_cp)^3<br>
<br>
0:14:15.440,0:14:21.360<br>
你做 100 次實驗，在 100 個宇宙裡面找<br>
出了不同的 b, w1, w2, w3<br>
<br>
0:14:21.420,0:14:25.380<br>
那你的這 100 條線長這個樣子<br>
<br>
0:14:25.500,0:14:29.300<br>
那你就會發現說有點像是散開了，像花一樣地散開了<br>
<br>
0:14:29.720,0:14:31.720<br>
好，那如果今天是<br>
<br>
0:14:31.920,0:14:33.920<br>
換一個最複雜的 model<br>
<br>
0:14:34.020,0:14:36.440<br>
例如：5 次的 model，那你就會發現說<br>
<br>
0:14:36.440,0:14:42.240<br>
做 100 次實驗以後，你把那 100 條虛線都畫出來<br>
<br>
0:14:42.240,0:14:45.560<br>
你就會發現是這樣子的，崩潰的<br>
<br>
0:14:45.560,0:14:49.740<br>
在 100 個宇宙裡面，每一件事情都是有可能會發生的<br>
<br>
0:14:50.600,0:14:55.420<br>
所以呢，如果我們看這個 model 之間的 variance 的話<br>
<br>
0:14:55.620,0:14:59.340<br>
如果你看你做 100 次的射擊以後<br>
<br>
0:14:59.340,0:15:01.340<br>
你的結果的散佈的話<br>
<br>
0:15:01.340,0:15:02.820<br>
你會發現說<br>
<br>
0:15:02.820,0:15:06.200<br>
簡單的 model，就是只有考慮一次的 model<br>
<br>
0:15:06.200,0:15:08.200<br>
它是比較集中的<br>
<br>
0:15:08.740,0:15:10.740<br>
如果你考慮 5 次的話<br>
<br>
0:15:11.080,0:15:15.540<br>
它散佈就非常的廣<br>
<br>
0:15:16.240,0:15:19.180<br>
所以如果你用一個比較簡單的 model 的時候<br>
<br>
0:15:19.680,0:15:22.100<br>
它的 variance 是比較小的<br>
<br>
0:15:22.380,0:15:26.280<br>
就好像說，你在射擊的時候<br>
每次射擊的位置是差不多的<br>
<br>
0:15:26.340,0:15:29.100<br>
你每次找出來的直線呢<br>
<br>
0:15:29.320,0:15:31.600<br>
你每次找出來的最好的 function f* 呢<br>
<br>
0:15:31.780,0:15:33.060<br>
都是差不多的<br>
<br>
0:15:33.620,0:15:37.060<br>
但是如果你今天換一個比較複雜的 model<br>
<br>
0:15:37.240,0:15:40.180<br>
它的散佈就很開，就像這邊藍色的點一樣<br>
<br>
0:15:40.400,0:15:43.200<br>
它的 variance 很大，散佈就很開<br>
<br>
0:15:43.420,0:15:46.020<br>
這邊的每一條直線呢，都長得很不像<br>
<br>
0:15:46.300,0:15:51.780<br>
各種怪怪的線，都長得不一樣，<br>
它的散佈呢，就非常的開<br>
<br>
0:15:52.020,0:15:57.200<br>
今天你可能會問一個問題，<br>
為甚麼比較複雜的 model，它的散佈就比較開呢？<br>
<br>
0:15:57.820,0:16:02.380<br>
為甚麼比較簡單的 model，它就散佈的比較緊呢？<br>
<br>
0:16:02.460,0:16:03.680<br>
因為，你可以這樣想<br>
<br>
0:16:03.680,0:16:08.080<br>
簡單的 model 它比較不會受你的 data 的影響<br>
<br>
0:16:08.100,0:16:10.180<br>
在每個宇宙裡面，我們 sample 出來的<br>
<br>
0:16:10.300,0:16:13.300<br>
我們抓到的寶可夢都不一樣，<br>
所以找出來的 model 都不一樣<br>
<br>
0:16:13.560,0:16:15.060<br>
那比較簡單的 model<br>
<br>
0:16:15.060,0:16:18.780<br>
它受到不同 data 的影響是比較小的<br>
<br>
0:16:19.120,0:16:21.760<br>
舉例來說，我們舉一個極端的例子<br>
<br>
0:16:22.200,0:16:23.580<br>
這個極端的例子是<br>
<br>
0:16:23.620,0:16:27.180<br>
我們的整個 model set 裡面呢<br>
<br>
0:16:27.200,0:16:29.200<br>
就我們整個 function set 裡面呢<br>
<br>
0:16:29.200,0:16:32.620<br>
那我們整個 function set 這個 model 裡面，<br>
就一個 function f(x)，<br>
<br>
0:16:32.880,0:16:35.700<br>
output 就是 c，你不管抓怎麼樣的 training data<br>
<br>
0:16:35.700,0:16:37.660<br>
這個 function output 就是給你 c 這樣<br>
<br>
0:16:37.700,0:16:39.380<br>
給你一個 constant<br>
<br>
0:16:39.380,0:16:42.240<br>
這時候你就會發現說，你在不同的宇宙裡面<br>
<br>
0:16:42.300,0:16:45.380<br>
你找出來的 model 都是一模一樣的，因為你根本就沒找<br>
<br>
0:16:45.560,0:16:48.840<br>
你的不同宇宙裡面，找出來的 model 通通是一模一樣的<br>
<br>
0:16:48.880,0:16:50.720<br>
它的 variance 呢，是 0<br>
<br>
0:16:51.020,0:16:54.100<br>
所以如果給你一個最簡單的 model，它的 variance 是 0<br>
<br>
0:16:54.340,0:16:56.860<br>
當你給的這個 model 它的複雜度越來越高的時候呢<br>
<br>
0:16:57.160,0:17:00.260<br>
它的 variance 呢，就會越來越大<br>
<br>
0:17:00.840,0:17:04.400<br>
好，接下來呢，我們來看 bias<br>
<br>
0:17:05.000,0:17:07.000<br>
好，那 bias 是甚麼呢？<br>
<br>
0:17:07.280,0:17:11.000<br>
bias 的意思是說，我們有很多很多的 f*<br>
<br>
0:17:11.260,0:17:15.360<br>
假設我們把所有的 f* 平均起來，找它的期望值<br>
<br>
0:17:15.520,0:17:17.520<br>
也就是 f\bar 的話<br>
<br>
0:17:17.740,0:17:23.620<br>
這個 f\bar 跟我們的靶心 f̂ 它有多接近呢？<br>
<br>
0:17:24.160,0:17:26.460<br>
如果是一個大的 bias 的話<br>
<br>
0:17:26.500,0:17:30.660<br>
意思是說，你今天把所有的 f* 平均起來<br>
<br>
0:17:30.880,0:17:34.600<br>
你得到的 f\bar，它跟靶心是有一段距離的<br>
<br>
0:17:36.000,0:17:37.840<br>
如果是小的 bias 的話<br>
<br>
0:17:38.000,0:17:42.280<br>
意思是說你的 f* 可能分散得很開<br>
<br>
0:17:42.380,0:17:46.600<br>
它分散得多開我們不管，你要找它的平均值<br>
<br>
0:17:46.640,0:17:49.360<br>
它的平均值呢，跟靶心是接近的<br>
<br>
0:17:49.360,0:17:52.100<br>
不管它散的多開，它的平均值跟靶心是接近的<br>
<br>
0:17:52.100,0:17:53.600<br>
這樣叫 small bias<br>
<br>
0:17:54.020,0:17:56.700<br>
說到這邊的時候，我就卡住啦<br>
<br>
0:17:56.820,0:17:58.060<br>
我為甚麼卡住了呢？<br>
<br>
0:17:58.060,0:18:03.720<br>
因為我想要量：不同 function 間的 bias 有多大<br>
<br>
0:18:03.720,0:18:05.720<br>
那仔細想想根本沒有辦法量這件事情<br>
<br>
0:18:05.720,0:18:07.780<br>
因為我根本不知道那個 f̂ 長甚麼樣子阿<br>
<br>
0:18:07.780,0:18:09.780<br>
所以我就卡住了這樣子，所以我只好<br>
<br>
0:18:09.780,0:18:12.480<br>
胡亂自己假設一個 f̂<br>
<br>
0:18:12.480,0:18:16.420<br>
假設說 f̂ 就是長這條直線這樣子<br>
<br>
0:18:18.080,0:18:21.700<br>
好，那我們就假設說 f̂ 就是長這條直線<br>
<br>
0:18:21.920,0:18:24.500<br>
所以我們的寶可夢 data 呢<br>
<br>
0:18:24.500,0:18:29.480<br>
寶可夢呢，就是從這條虛線 sample 出來的<br>
<br>
0:18:29.480,0:18:32.080<br>
那每次我們就 sample 10 個點出來<br>
<br>
0:18:32.080,0:18:34.580<br>
那你就可以找一個 f*<br>
<br>
0:18:35.300,0:18:38.640<br>
好那這個呢，是實驗的結果<br>
<br>
0:18:39.300,0:18:43.640<br>
黑色的線代表的是我們剛才在前一頁投影片看到的<br>
<br>
0:18:43.640,0:18:48.620<br>
真正的 f̂，就是你的靶心的位置是這條黑色的直線<br>
<br>
0:18:49.480,0:18:53.400<br>
紅色的呢，代表了我們做 5000 次實驗<br>
<br>
0:18:53.400,0:18:57.480<br>
5000 次實驗每一次找出來的 f* 都是不一樣的<br>
<br>
0:18:57.560,0:18:59.560<br>
所以假設是一次的 model<br>
<br>
0:18:59.620,0:19:01.620<br>
最簡單的 model ，它長得<br>
<br>
0:19:01.620,0:19:03.620<br>
有很多，有 5000 條直線在這邊<br>
<br>
0:19:03.620,0:19:06.040<br>
你這邊畫出來就是紅紅的一大塊<br>
<br>
0:19:06.840,0:19:08.840<br>
好，如果是藍色的呢<br>
<br>
0:19:09.120,0:19:12.120<br>
藍色代表說我們這個是 f\bar<br>
<br>
0:19:12.120,0:19:17.580<br>
就是我們把 5000 個 f* 平均起來變成 f\bar，<br>
就是藍色的這條線<br>
<br>
0:19:18.860,0:19:20.860<br>
好，果我們只考慮一次的話<br>
<br>
0:19:20.860,0:19:25.300<br>
你會發現說那 5000 條直線都差不多，<br>
都差不多在這個地方<br>
<br>
0:19:25.680,0:19:29.380<br>
那他們的平均就是這條藍色的線<br>
<br>
0:19:29.380,0:19:31.380<br>
那它跟黑色這個  f̂<br>
<br>
0:19:31.380,0:19:34.020<br>
跟靶心是有一段差距的<br>
<br>
0:19:34.820,0:19:36.820<br>
如果你用 3 次式<br>
<br>
0:19:36.820,0:19:41.500<br>
3 次式的話，你會發現說你 5000 條直線畫出來會是這樣子<br>
<br>
0:19:41.500,0:19:43.960<br>
它的頭跟尾是很散的<br>
<br>
0:19:44.860,0:19:46.860<br>
所以它的頭跟尾都很散<br>
<br>
0:19:46.860,0:19:48.860<br>
但是如果你說平均找 f\bar<br>
<br>
0:19:49.180,0:19:51.180<br>
也就是說藍色這條線的話<br>
<br>
0:19:51.420,0:19:56.000<br>
你會發現說，你算每一次的 f* 都差很多<br>
<br>
0:19:56.600,0:19:58.600<br>
那平均起來這個藍色的線<br>
<br>
0:19:58.840,0:20:00.520<br>
跟黑色這個 f̂<br>
<br>
0:20:00.760,0:20:02.560<br>
其實相對於這邊<br>
<br>
0:20:02.740,0:20:04.740<br>
它是比較接近的<br>
<br>
0:20:05.380,0:20:09.220<br>
如果我們找 5000 條，如果我們用 5 次式<br>
<br>
0:20:09.420,0:20:13.500<br>
那你就發現說 5000 條線畫出來是這樣，<br>
你要不要乾脆把整個圖都塗紅色這樣<br>
<br>
0:20:14.980,0:20:17.280<br>
你會發現說這時候一切都有可能<br>
<br>
0:20:17.400,0:20:19.940<br>
那雖然這個地方你完全看不出來說，哇<br>
<br>
0:20:20.060,0:20:23.120<br>
到底有甚麼直線，通通塗成紅色的<br>
<br>
0:20:23.500,0:20:25.500<br>
但是如果你把它平均起來<br>
<br>
0:20:25.700,0:20:29.720<br>
你把這 5000 條、5 次式的曲線平均起來，<br>
你會發現說<br>
<br>
0:20:30.160,0:20:33.000<br>
它得到的是這條藍色的 f\bar<br>
<br>
0:20:33.080,0:20:35.460<br>
它的 f\bar 是這條藍色的<br>
<br>
0:20:35.580,0:20:42.660<br>
它跟我們真正的 f̂，它跟真正的 f̂ 是接近的<br>
<br>
0:20:43.620,0:20:47.580<br>
雖然她每次都差很多，但平均起來以後，是接近的<br>
<br>
0:20:48.280,0:20:50.340<br>
所以呢，我們看到說<br>
<br>
0:20:50.340,0:20:52.380<br>
如果是一個比較簡單的 model<br>
<br>
0:20:52.620,0:20:56.060<br>
它有比較大的 bias<br>
<br>
0:20:56.060,0:20:58.440<br>
如果是一個比較複雜的 model<br>
<br>
0:20:58.440,0:21:00.620<br>
每一次找出來的 f* 都不一樣<br>
<br>
0:21:00.620,0:21:03.380<br>
但它有比較小的 bias<br>
<br>
0:21:03.700,0:21:07.340<br>
所以今天左邊這個簡單的 model 它的 case<br>
<br>
0:21:07.460,0:21:09.240<br>
就像是這個樣子<br>
<br>
0:21:09.240,0:21:12.120<br>
每一次 f* 都差不多<br>
<br>
0:21:12.120,0:21:16.340<br>
它的分布比較小，但是它跟靶心是有差距的<br>
<br>
0:21:17.000,0:21:18.600<br>
那這個 case<br>
<br>
0:21:18.820,0:21:20.820<br>
就像是這邊這樣子<br>
<br>
0:21:20.860,0:21:25.660<br>
每一次找出來的 f* 都不太一樣，但平均而言，是在靶心附近<br>
<br>
0:21:25.960,0:21:27.960<br>
為甚麼會這樣子<br>
<br>
0:21:27.960,0:21:29.980<br>
我試著直觀的解釋給大家聽<br>
<br>
0:21:30.200,0:21:35.380<br>
我們說，我們的 model 就是一個 function set 對不對<br>
<br>
0:21:35.580,0:21:39.580<br>
那我們就用一個範圍呢，來表示這個 function set<br>
<br>
0:21:40.000,0:21:43.220<br>
當你定一個 model 的時候，你就已經設定好說<br>
<br>
0:21:43.220,0:21:47.460<br>
你最好的 function 就只能從那個 function set 裡面挑出來<br>
<br>
0:21:47.980,0:21:49.980<br>
如果是一個簡單的 model<br>
<br>
0:21:50.280,0:21:53.380<br>
它的 space 是比較小<br>
<br>
0:21:53.620,0:21:57.400<br>
所以這個比較小的 space，<br>
它可能根本就沒有包含你的 target<br>
<br>
0:21:57.640,0:21:59.800<br>
如果再沒有包含 target 的情況下<br>
<br>
0:21:59.900,0:22:02.220<br>
你從這裡面，不管怎麼 sample<br>
<br>
0:22:02.280,0:22:05.080<br>
你平均起來都不會是這個 target 阿<br>
<br>
0:22:05.240,0:22:08.320<br>
因為你的這個 function set 裡面<br>
根本就沒有包含那個 target 阿<br>
<br>
0:22:09.180,0:22:11.540<br>
但是如果今天你的 model 呢<br>
<br>
0:22:11.640,0:22:14.280<br>
是比較複雜的<br>
<br>
0:22:14.340,0:22:16.980<br>
你的 model 所代表的這個 function space<br>
<br>
0:22:17.100,0:22:20.860<br>
我們上次有講過說你從 1 次、2 次、3 次一直到 5 次<br>
<br>
0:22:20.940,0:22:22.940<br>
你的 function 是越來越複雜的<br>
<br>
0:22:22.940,0:22:25.760<br>
那簡單的 function 是包含在複雜的 function 裡面<br>
<br>
0:22:26.100,0:22:28.780<br>
所以如果你用 5 次的時候，這個時候呢<br>
<br>
0:22:28.780,0:22:31.600<br>
你的 function 的 space 是比較大<br>
<br>
0:22:31.840,0:22:33.840<br>
那它可能有包含這個 target<br>
<br>
0:22:33.840,0:22:38.940<br>
它可能有包含這個 target，只是它沒有辦法<br>
找出這個 target 在哪裡<br>
<br>
0:22:38.940,0:22:40.940<br>
因為你給的 training data 不夠<br>
<br>
0:22:40.940,0:22:43.100<br>
你給的 training data 每一次都不一樣<br>
<br>
0:22:43.100,0:22:45.100<br>
所以它每次找出來的 f* 都不一樣<br>
<br>
0:22:45.100,0:22:47.900<br>
但如果它們是散佈在這個 target 附近的<br>
<br>
0:22:47.900,0:22:51.100<br>
那平均起來呢，你就可以得到 f\bar<br>
<br>
0:22:52.220,0:22:56.260<br>
好，所以我們回到我們上次看的那個 model<br>
<br>
0:22:56.260,0:23:00.340<br>
對這個 testing data, error 所畫出來的線<br>
<br>
0:23:01.340,0:23:03.340<br>
那比較簡單的 model<br>
<br>
0:23:03.340,0:23:05.180<br>
我們剛才有講說比較簡單的 model<br>
<br>
0:23:05.180,0:23:09.960<br>
它就是 bias 比較大，但是 variance 比較小<br>
<br>
0:23:09.960,0:23:11.960<br>
比較複雜的 model<br>
<br>
0:23:11.960,0:23:16.120<br>
就是 bias 比較小，但 variance 比較大<br>
<br>
0:23:16.120,0:23:18.920<br>
所以今天這個圖，由左到右<br>
<br>
0:23:18.920,0:23:24.600<br>
一方面呢，model 的 bias 是逐漸地下降<br>
<br>
0:23:24.600,0:23:29.140<br>
這是 bias 所造成的 error 是逐漸下降<br>
<br>
0:23:29.140,0:23:32.960<br>
也就是你瞄的越來越準、你瞄的越來越準<br>
<br>
0:23:33.500,0:23:39.460<br>
但是同時呢，同時呢，這個 variance 是越來越大的<br>
<br>
0:23:39.760,0:23:41.840<br>
現在，雖然你每次瞄的越來越準<br>
<br>
0:23:41.840,0:23:46.380<br>
但是你每次射出去以後，你的誤差呢，是越來越大<br>
<br>
0:23:46.760,0:23:50.300<br>
所以當這兩項同時被考慮的時候<br>
<br>
0:23:50.300,0:23:52.780<br>
你得到的就是藍色這條線<br>
<br>
0:23:52.780,0:23:55.420<br>
藍色這條線，也就是說<br>
<br>
0:23:55.420,0:23:58.600<br>
在某個地方，你可以找到一個平衡的點<br>
<br>
0:23:58.660,0:24:01.620<br>
讓你同時考慮 bias 和 variance 的時候<br>
<br>
0:24:01.620,0:24:03.620<br>
你得到的 error 是越小<br>
<br>
0:24:03.780,0:24:05.780<br>
但是當你的 model 越來越複雜的時候<br>
<br>
0:24:05.780,0:24:07.780<br>
你的 variance 增長的比較快<br>
<br>
0:24:07.800,0:24:11.540<br>
所以你的 model 的 error 就變得很大<br>
<br>
0:24:12.140,0:24:16.700<br>
所以今天如果是一個 variance 大的情形<br>
<br>
0:24:16.880,0:24:19.740<br>
如果你的 error 來自於 variance 很大<br>
<br>
0:24:19.780,0:24:22.460<br>
這個狀況呢，就是 Overfittng<br>
<br>
0:24:23.080,0:24:27.400<br>
如果今天你的 error 來自於 bias 很大<br>
<br>
0:24:27.460,0:24:30.680<br>
這個狀況呢，叫做 Underfitting<br>
<br>
0:24:31.340,0:24:34.700<br>
所以今天假設你遇到一個 error 的時候<br>
<br>
0:24:34.700,0:24:37.180<br>
你自己做一些 implement<br>
<br>
0:24:37.180,0:24:39.860<br>
比如說你碩士論文用到 machine learning 的技術<br>
<br>
0:24:39.860,0:24:43.320<br>
你做完得到一個結果，然後你後面寫了一些 future work<br>
<br>
0:24:43.320,0:24:45.520<br>
然後我都會問一個問題<br>
<br>
0:24:46.560,0:24:49.980<br>
如果你找我去考碩士、博士的話，<br>
我都問這個問題<br>
<br>
0:24:49.980,0:24:57.240<br>
就是說，你覺得你現在的問題是<br>
bias 大、還是 variance 大<br>
<br>
0:24:57.240,0:25:00.520<br>
你應該先知道這件事情，你才知道你的 future work<br>
<br>
0:25:00.580,0:25:04.600<br>
你要 improve 你的 model 的時候，<br>
你應該要走哪一個方向<br>
<br>
0:25:05.220,0:25:09.640<br>
那怎麼知道現在是 bias 大還是 variance 大呢？<br>
<br>
0:25:09.640,0:25:12.840<br>
好，甚麼時候 bias 大？<br>
<br>
0:25:12.840,0:25:18.440<br>
如果今天你的 model 沒有辦法 fit <br>
你的 training 的 examples<br>
<br>
0:25:18.440,0:25:21.800<br>
那代表說呢，你的 bias 是大的<br>
<br>
0:25:21.800,0:25:25.180<br>
就是如果我們只 sample 這幾個藍色的點<br>
<br>
0:25:25.520,0:25:31.220<br>
而你的 model even 沒有 fit 這少數幾個藍色的點<br>
<br>
0:25:31.220,0:25:38.360<br>
代表說你的 model 跟正確的 model 是有一段差距的<br>
<br>
0:25:39.000,0:25:41.900<br>
所以這個時候是 Underfitting<br>
<br>
0:25:41.900,0:25:43.900<br>
這個時候是 bias 大的狀況<br>
<br>
0:25:44.400,0:25:47.820<br>
如果今天是你在 training data 上<br>
<br>
0:25:48.020,0:25:49.460<br>
你可以 fit 你的 training data<br>
<br>
0:25:49.500,0:25:51.600<br>
你在 training data 上得到小的 error<br>
<br>
0:25:51.600,0:25:56.280<br>
但是在 testing data 上，你卻得到一個大的 error<br>
<br>
0:25:56.280,0:26:00.000<br>
這意味著你的 model 可能是 variance 比較大<br>
<br>
0:26:00.520,0:26:03.160<br>
這個時候呢，代表的是 Overfitting<br>
<br>
0:26:03.160,0:26:06.380<br>
那遇到 bias 大跟 variance 大的時候<br>
<br>
0:26:06.380,0:26:09.840<br>
你其實是要用不同的方式來處理它們<br>
<br>
0:26:10.220,0:26:13.920<br>
比如說，如果今天是 bias 大<br>
<br>
0:26:13.920,0:26:15.920<br>
那你要做的事情是甚麼呢？<br>
<br>
0:26:15.920,0:26:18.500<br>
你應該去 redesign 你的 model<br>
<br>
0:26:18.500,0:26:24.300<br>
bias 大代表說，你現在這個 model 裡面可能根本沒有包含你的 target<br>
<br>
0:26:24.300,0:26:27.420<br>
你的 f̂，它根本就不再你的 model set 裡面<br>
<br>
0:26:27.420,0:26:29.180<br>
那你要怎麼辦呢？<br>
<br>
0:26:29.180,0:26:32.300<br>
你要做的事情是：redesign 你的 model<br>
<br>
0:26:32.300,0:26:34.960<br>
比如說，你可能重寫你 model 的式子<br>
<br>
0:26:34.960,0:26:36.900<br>
把更多的 feature 加進去<br>
<br>
0:26:36.900,0:26:43.020<br>
比如說只考慮 CP 值可能不夠，你可能還要考慮 <br>
hp 值阿，或其他甚麼東西<br>
<br>
0:26:43.260,0:26:45.180<br>
或者是，你讓你的 model 更複雜<br>
<br>
0:26:45.240,0:26:48.140<br>
本來只考慮 1 次不夠，你可能要考慮 2 次、3 次等等<br>
<br>
0:26:48.360,0:26:53.060<br>
在這個狀況下，因為是你的 model 不好，沒有包含 f̂<br>
<br>
0:26:53.320,0:26:56.680<br>
所以如果你今天你 error 差是來自 bias<br>
<br>
0:26:56.840,0:27:00.400<br>
那你不要說我去 collect 更多 data，<br>
collect 更多 data 是沒有用的<br>
<br>
0:27:00.400,0:27:03.880<br>
今天這個狀況下，collect 更多 data，你也不會有幫助<br>
<br>
0:27:03.880,0:27:08.200<br>
因為你的 model、你的 function set 本來就不好<br>
<br>
0:27:08.200,0:27:10.460<br>
再找更多的 data 下來，也不會有幫助<br>
<br>
0:27:11.060,0:27:12.820<br>
好今天如果是另外一個 case<br>
<br>
0:27:13.020,0:27:15.160<br>
如果是 variance 大的話<br>
<br>
0:27:15.220,0:27:17.040<br>
那你應該怎麼辦呢？<br>
<br>
0:27:17.100,0:27:20.400<br>
一個方法就是增加你的 data<br>
<br>
0:27:20.680,0:27:25.120<br>
那我們看剛才的例子，如果是 5 次式，找 100 個  f̂<br>
<br>
0:27:25.120,0:27:30.080<br>
每次如果們只抓 10 隻寶可夢的話，那我們找出來的式子<br>
<br>
0:27:30.080,0:27:31.380<br>
是這個樣子的<br>
<br>
0:27:32.940,0:27:36.180<br>
找出來的 100 個 f* 的散佈是這個樣子<br>
<br>
0:27:36.740,0:27:39.280<br>
但如果每次抓 100 隻寶可夢的話<br>
<br>
0:27:39.280,0:27:41.840<br>
那 100 個 f*，你會發現說他們非常的集中<br>
<br>
0:27:41.840,0:27:46.840<br>
他們幾乎都集中在這個地方<br>
<br>
0:27:46.840,0:27:52.380<br>
所以增加 data 是一個很有效控制 variance 的方法<br>
<br>
0:27:52.400,0:27:55.340<br>
假如你 variance 太大的話，這個時候你要做的事情<br>
<br>
0:27:55.460,0:28:00.760<br>
collect data 幾乎是一個，像是萬能丹一樣的東西<br>
<br>
0:28:00.760,0:28:06.600<br>
它不會傷害你的 bias<br>
<br>
0:28:06.600,0:28:08.380<br>
但是它有可造成你的問題就是<br>
<br>
0:28:08.380,0:28:10.680<br>
你在實際上你沒有辦法 collect 更多 data<br>
<br>
0:28:10.680,0:28:15.720<br>
對不對，在 practical，collect data 很麻煩阿，<br>
你不見得能 collect 更多 data<br>
<br>
0:28:15.900,0:28:17.280<br>
不只在學校實驗室沒有辦法<br>
<br>
0:28:17.280,0:28:21.340<br>
你可能以為在業界就可以說你要 collect 多少 data，其實你也不見得可以<br>
<br>
0:28:21.340,0:28:25.580<br>
比如說，有些人在業界想要做一些 AI 的東西<br>
<br>
0:28:25.580,0:28:29.000<br>
然後他就跟老闆說，我要 collect 一萬筆 labeled data<br>
<br>
0:28:29.000,0:28:32.140<br>
然後就被 reject，因為老闆說這個，機器會自己學習<br>
<br>
0:28:32.140,0:28:35.160<br>
所以你不需要 labeled data，不是機器會自己學習嗎？<br>
<br>
0:28:35.160,0:28:36.140<br>
為甚麼要 labeled data<br>
<br>
0:28:36.260,0:28:37.560<br>
就把他否決了這樣子<br>
<br>
0:28:38.800,0:28:42.000<br>
所以在業界，不是你想要 collect data 就可以的<br>
<br>
0:28:42.000,0:28:45.180<br>
會有各種 review，尤其是你的高層又不知道 machine learning 是什麼的時候<br>
<br>
0:28:45.180,0:28:48.740<br>
你就會很卡，所以有時候你根本就沒有辦法 collect data<br>
<br>
0:28:48.740,0:28:50.460<br>
所以你不見得能夠這麼做<br>
<br>
0:28:50.460,0:28:52.860<br>
那如果你不能這麼做，其實有一招<br>
<br>
0:28:52.860,0:28:57.440<br>
這招就是 generate 假的 training data<br>
<br>
0:28:57.440,0:29:01.580<br>
根據你對這個問題的理解，自己去製造更多 data<br>
<br>
0:29:01.580,0:29:06.060<br>
還是有這招，比如說，在做手寫數字辨識的時候<br>
<br>
0:29:06.060,0:29:08.720<br>
手寫辨識的時候，有人會說<br>
<br>
0:29:08.720,0:29:11.380<br>
因為每個人手寫的這個角度不一樣<br>
<br>
0:29:11.380,0:29:18.100<br>
所以我把所有 training data 裡面的數字<br>
都左轉 15 度、右轉 15度<br>
<br>
0:29:18.100,0:29:19.500<br>
這樣是可以<br>
<br>
0:29:19.620,0:29:23.720<br>
或者是做影像辨識，你只有一個從左邊開過來的火車<br>
<br>
0:29:23.720,0:29:25.920<br>
沒有從右邊開過來的火車，怎麼辦？<br>
<br>
0:29:25.920,0:29:28.320<br>
把整個圖片翻轉你就有從有右邊開過來的火車啦<br>
<br>
0:29:28.320,0:29:32.560<br>
對不對，你可以把你的每張圖片都左右顛倒<br>
<br>
0:29:32.560,0:29:34.360<br>
這樣你就多一倍的 data 出來<br>
<br>
0:29:34.920,0:29:37.200<br>
或者是在語音辨識的時候<br>
<br>
0:29:37.560,0:29:44.040<br>
你說，你只有男生說你好，沒有女生說大家好<br>
<br>
0:29:44.260,0:29:47.380<br>
那你就把那個男生的聲音<br>
<br>
0:29:47.380,0:29:50.240<br>
用一個變聲器把它轉一下這樣<br>
<br>
0:29:50.240,0:29:52.940<br>
就變女生的聲音，女生的聲音用變聲器轉，<br>
就變男生的聲音<br>
<br>
0:29:52.940,0:29:55.760<br>
你這 data 就多出來，而且是真的有人這麼做的<br>
<br>
0:29:55.760,0:29:58.980<br>
或者是說，你說我只有這個 clean speech<br>
<br>
0:29:58.980,0:30:00.500<br>
你在錄音室錄的聲音<br>
<br>
0:30:00.620,0:30:02.780<br>
可是我是要做真正的 detection<br>
<br>
0:30:02.780,0:30:05.980<br>
那是要讓你在公車上用的<br>
<br>
0:30:05.980,0:30:06.920<br>
那怎麼辦？<br>
<br>
0:30:06.920,0:30:08.980<br>
你就去公車上面，錄一些雜訊<br>
<br>
0:30:08.980,0:30:12.000<br>
然後呢，加到你在錄音室錄的聲音裡面<br>
<br>
0:30:12.000,0:30:14.280<br>
你馬上就有公車上面的雜訊了<br>
<br>
0:30:14.280,0:30:17.420<br>
所以你有各種方法可以用啦<br>
<br>
0:30:17.560,0:30:22.080<br>
比如說，還有人說，我今天要做 <br>
language understanding 的 task<br>
<br>
0:30:22.080,0:30:27.880<br>
那我今天要做 support 各種不同國家的 language understanding 的 task 的時候<br>
<br>
0:30:27.980,0:30:30.000<br>
我要做 10 種國家、我 10 種語言都要<br>
<br>
0:30:30.000,0:30:32.520<br>
那老闆只給你英文的 data<br>
<br>
0:30:32.520,0:30:34.140<br>
它自己會學這樣子<br>
<br>
0:30:34.200,0:30:36.580<br>
只給你英文的 data，它中文自己學就會學的會<br>
<br>
0:30:36.580,0:30:39.060<br>
那怎麼辦呢？你就可以做 translation<br>
<br>
0:30:39.060,0:30:43.040<br>
把英文通通硬翻成中文，結果還是跟你 trained 一樣<br>
<br>
0:30:43.040,0:30:44.560<br>
所以有各種不同的做法<br>
<br>
0:30:45.280,0:30:49.800<br>
好，那如果你沒有辦法 collect 更多data 的話<br>
<br>
0:30:49.800,0:30:53.800<br>
你還有這另外一招，叫 Regularization<br>
<br>
0:30:53.800,0:30:55.740<br>
這我們上次也有看到<br>
<br>
0:30:55.740,0:30:59.480<br>
就是我們在一個 loss function 裡面，後面呢，再加一個 term<br>
<br>
0:30:59.480,0:31:02.800<br>
這個 term 會希望你的參數，越少越好<br>
<br>
0:31:03.100,0:31:06.760<br>
也就是說希望你今天找出來的曲線呢，越平滑越好<br>
<br>
0:31:07.220,0:31:11.100<br>
然後那個新加的 term 前面可以有一個 weight<br>
<br>
0:31:11.100,0:31:14.600<br>
代表你希望你的曲線有多平滑<br>
<br>
0:31:14.600,0:31:19.880<br>
左邊這個圖是，沒有加 Regularization 的 test<br>
<br>
0:31:19.880,0:31:21.540<br>
這個圖跟這個圖是一樣的<br>
<br>
0:31:21.540,0:31:27.400<br>
如果你今天加了 Regularization 以後<br>
<br>
0:31:27.400,0:31:30.500<br>
因為你的所有曲線都會變平滑<br>
<br>
0:31:30.500,0:31:34.300<br>
本來這種怪怪的、很不平滑的曲線就不會再出現了<br>
<br>
0:31:34.300,0:31:38.300<br>
所有曲線呢，都集中在比較平滑的區域<br>
<br>
0:31:38.360,0:31:40.160<br>
都變成比較平滑的曲線<br>
<br>
0:31:40.440,0:31:44.340<br>
如果你再更增加它的 weight 的話<br>
<br>
0:31:44.340,0:31:46.920<br>
再考慮要讓你的曲線更平滑的話<br>
<br>
0:31:47.000,0:31:48.280<br>
那你得到的結果就是這樣<br>
<br>
0:31:48.280,0:31:50.400<br>
所以如果你加了 Regularization 以後<br>
<br>
0:31:50.400,0:31:53.140<br>
你強迫所有的曲線都要比較平滑<br>
<br>
0:31:53.140,0:31:57.640<br>
所以這個時候呢，也會讓你的 variance 變小<br>
<br>
0:31:57.640,0:32:01.680<br>
那這個時候，你會得到的一個可能的傷害就是<br>
<br>
0:32:01.680,0:32:03.840<br>
你有可能會傷害你的 bias<br>
<br>
0:32:03.840,0:32:06.500<br>
對不對，你調整了你的 function space<br>
<br>
0:32:06.500,0:32:11.040<br>
變成它只包含那些比較平滑的曲線<br>
<br>
0:32:11.040,0:32:14.700<br>
那你可能就沒有辦法包含你的 f̂<br>
<br>
0:32:14.700,0:32:17.940<br>
那你可能就沒有辦法包含你的那個目標的 function<br>
<br>
0:32:17.940,0:32:20.020<br>
你就可能傷害了你的 bias<br>
<br>
0:32:20.020,0:32:24.180<br>
所以當你做 Regularization 的時候，<br>
你要調整一下 Regularization 的 weight<br>
<br>
0:32:24.180,0:32:27.680<br>
在 variance 和 bias 之間呢，取得平衡<br>
<br>
0:32:28.840,0:32:31.880<br>
好，所以我們現在會遇到的問題往往是這樣<br>
<br>
0:32:31.880,0:32:34.500<br>
我們有很多個 model 可以選擇<br>
<br>
0:32:34.720,0:32:38.840<br>
那在這還有很多的參數可以調，<br>
比如說，Regularization 的 weight<br>
<br>
0:32:38.920,0:32:44.340<br>
那通常我們是在 bias 跟 variance 之間呢，<br>
做一些 trade-off<br>
<br>
0:32:44.340,0:32:48.480<br>
做一些平衡，我們希望找一個 model<br>
<br>
0:32:49.600,0:32:52.860<br>
variance 夠小、bias 也夠小<br>
<br>
0:32:52.860,0:32:57.320<br>
這兩個合起來，給我們最小的 testing data 的 error<br>
<br>
0:32:57.320,0:33:00.620<br>
我們通常需要選擇一個最好的 model<br>
<br>
0:33:01.080,0:33:05.220<br>
但是以下這件事情，是你不該做的<br>
<br>
0:33:05.220,0:33:09.600<br>
或是你最好、就是你不要這麼做，這個事情是怎樣呢？<br>
<br>
0:33:09.600,0:33:14.480<br>
就是你手上有 training set 、有 testing set<br>
<br>
0:33:15.000,0:33:18.300<br>
然後接下來你想要知道說：model 1、2、3 裡面<br>
<br>
0:33:18.300,0:33:21.080<br>
你應該選哪一個 model？<br>
<br>
0:33:21.080,0:33:27.460<br>
你就分別用 model 1、2、3 呢，分別去找一個 best function<br>
<br>
0:33:27.460,0:33:30.040<br>
我們 train 出一個 model，train 出一個 function<br>
<br>
0:33:30.040,0:33:33.460<br>
好接下來你把它 apply  到 testing set 上面<br>
<br>
0:33:33.460,0:33:38.340<br>
model 1給你 error 0.9、model 2給你 error 0.7<br>
model 3給你 error 0.5<br>
<br>
0:33:38.340,0:33:42.660<br>
那很直覺的就是 model 3 最好這樣子<br>
<br>
0:33:42.660,0:33:45.300<br>
但是，你現在可能的問題是<br>
<br>
0:33:45.300,0:33:49.100<br>
這 testing set 是你自己手上的 testing set<br>
<br>
0:33:49.100,0:33:51.600<br>
是你自己拿來衡量 model 好壞的 testing set<br>
<br>
0:33:52.080,0:33:55.060<br>
真正的 testing set 是你沒有的<br>
<br>
0:33:55.060,0:33:57.040<br>
真正的 testing set 的時候呢，假設我們<br>
<br>
0:33:57.040,0:34:01.520<br>
今天把我做的寶可夢的預測，放到網路上這樣<br>
<br>
0:34:01.520,0:34:03.160<br>
然後看看有沒有人要用<br>
<br>
0:34:03.160,0:34:07.220<br>
那新進來的 data 我是從來沒有看過的<br>
<br>
0:34:07.220,0:34:09.100<br>
那因為你在挑 model的時候<br>
<br>
0:34:09.100,0:34:13.060<br>
你考慮了你自己手上的這一筆 testing set<br>
<br>
0:34:13.060,0:34:17.720<br>
而你自己手上的這筆 testing set，它有一筆 bias<br>
<br>
0:34:18.020,0:34:22.020<br>
就是你手上這筆 testing set，它有自己的一個 bias<br>
<br>
0:34:22.020,0:34:28.680<br>
那現在講的這個 bias 跟之前講的 bias 是有一點難解釋，是有關係，但意思略有不同<br>
<br>
0:34:28.680,0:34:31.540<br>
這個 testing set 有自己的 bias<br>
<br>
0:34:31.540,0:34:36.340<br>
所以你今天拿這個 testing set 來選這最好的 model 的時候<br>
<br>
0:34:36.340,0:34:40.240<br>
它在真正的 testing set 上，不見得是最好的 model<br>
<br>
0:34:40.240,0:34:47.800<br>
通常都是比較差的，所以你可能會得到的 error 是大於你在自己的 testing set 估測的 0.5<br>
<br>
0:34:47.980,0:34:51.880<br>
好這樣講甚麼自己的 testing set，你可能有一點困惑<br>
<br>
0:34:51.880,0:34:55.280<br>
那我們就直接拿我們的作業來舉例<br>
<br>
0:34:55.280,0:34:59.860<br>
你可能已經做了作業，那我們就是希望大家<br>
做了作業以後，再來講這個東西<br>
<br>
0:35:00.340,0:35:01.500<br>
這個是這樣<br>
<br>
0:35:01.500,0:35:03.560<br>
你手上有 training set<br>
<br>
0:35:03.940,0:35:05.800<br>
那你有 testing set<br>
<br>
0:35:05.800,0:35:08.280<br>
那 testing set 其實有兩組<br>
<br>
0:35:08.280,0:35:13.280<br>
一組是 public set，一組是 private set<br>
<br>
0:35:14.140,0:35:17.980<br>
你今天上傳你的結果到<br>
<br>
0:35:18.140,0:35:20.140<br>
Kaggle 的 leaderboard 的時候<br>
<br>
0:35:20.140,0:35:24.880<br>
你只能看到 public set 的分數，<br>
你沒有辦法看到 private set 的分數<br>
<br>
0:35:24.880,0:35:28.900<br>
private 的分數要等到作業 deadline，<br>
你沒有辦法在上傳以後<br>
<br>
0:35:28.900,0:35:31.800<br>
你才會在一瞬間看到你 private set 的分數<br>
<br>
0:35:31.800,0:35:35.400<br>
你那個本來 ranking 上面秀的是 public 的分數<br>
<br>
0:35:35.400,0:35:38.240<br>
它一瞬間翻過來變成那個 private 的分數<br>
<br>
0:35:39.080,0:35:43.580<br>
然後，如果你今天做的是下面這個狀況<br>
<br>
0:35:43.580,0:35:47.180<br>
我用我的 training data，train 了這三個 model<br>
<br>
0:35:47.700,0:35:53.820<br>
我想知道哪一個結果是最好的，<br>
所以我把 3 個 model 的結果通通傳到 Kaggle 上面<br>
<br>
0:35:53.820,0:35:58.400<br>
在 Leaderboard 上，它告訴我說， model 3 給我的 error 是最好的<br>
<br>
0:35:58.400,0:36:01.780<br>
你可能就覺得說，我做完了，我 beat the baseline !<br>
<br>
0:36:01.860,0:36:04.280<br>
但是，private set 你是看不到的阿<br>
<br>
0:36:04.280,0:36:08.400<br>
而 private set 的 error 通常是大於 public set 的 error 阿<br>
<br>
0:36:08.680,0:36:11.000<br>
所以你可能並沒有 beat baseline<br>
<br>
0:36:11.720,0:36:14.100<br>
所以這是有可能發生的<br>
<br>
0:36:14.200,0:36:19.180<br>
在下周五，那個作業 deadline 的時候，你可能就這樣<br>
<br>
0:36:21.160,0:36:27.320<br>
這個是有可能發生的，先跟大家講一下，<br>
你不要太沮喪這樣子<br>
<br>
0:36:27.480,0:36:32.620<br>
比如說，第 3 名的搞不好現在排第 100<br>
<br>
0:36:32.620,0:36:35.140<br>
因為你知道，我是看得到 private set 的啦<br>
<br>
0:36:35.140,0:36:39.940<br>
我舉個例子，搞不好前 5 名的可能是在 100 名也說不定<br>
<br>
0:36:39.940,0:36:45.060<br>
然後也有比較勵志的故事，比如說現在第一名的，<br>
他其實可在 40 幾名這樣<br>
<br>
0:36:45.060,0:36:47.060<br>
這個是真正的 example<br>
<br>
0:36:47.820,0:36:52.080<br>
這樣你 40 幾名的，你是不是就高興了呢這樣子<br>
<br>
0:36:53.820,0:37:00.520<br>
所以這個 public set 的結果，是不可靠的<br>
<br>
0:37:00.520,0:37:04.560<br>
所以，怎麼做才是比較可靠的呢？<br>
<br>
0:37:04.560,0:37:12.180<br>
你要做的事，你要這樣做就是<br>
你要把你的 training set 分成兩組<br>
<br>
0:37:12.180,0:37:16.400<br>
其實大家也不用太在意那個排名，<br>
那個占分也才一點點對不對<br>
<br>
0:37:16.740,0:37:20.680<br>
排名太差也不用太難過這樣子<br>
<br>
0:37:20.680,0:37:27.500<br>
好，那 training set 呢，你要把它分成兩組<br>
<br>
0:37:27.700,0:37:30.060<br>
這兩組呢，一組是真正拿來 train model<br>
<br>
0:37:30.060,0:37:33.400<br>
我們把它叫做 training set<br>
<br>
0:37:33.400,0:37:35.740<br>
另外一組，你不拿它來 train model<br>
<br>
0:37:35.740,0:37:38.160<br>
你拿它來選 model<br>
<br>
0:37:38.160,0:37:41.980<br>
你在這個 training set 上找出最好的 function f*<br>
<br>
0:37:41.980,0:37:46.480<br>
然後才用 validation set 來選擇你的 model<br>
<br>
0:37:46.480,0:37:47.900<br>
也就是你的做法應該是這樣子<br>
<br>
0:37:47.900,0:37:54.140<br>
你決定說，我到底應該用<br>
model 1, model 2, 還是 model 3<br>
<br>
0:37:54.240,0:37:58.460<br>
然後你把這 3 個 model，<br>
用你的 training set 去 train 好以後<br>
<br>
0:37:58.460,0:38:02.700<br>
接著看一下，它們在 validation set 上的 performance<br>
<br>
0:38:02.700,0:38:07.340<br>
假設現在 model 3 的 performance 是最好的<br>
<br>
0:38:07.340,0:38:11.540<br>
那你可以直接把這個 model 3 的結果拿來 apply在 testing data 上<br>
<br>
0:38:11.640,0:38:13.060<br>
那如果你擔心說<br>
<br>
0:38:13.060,0:38:16.660<br>
現在我把 training set 分成 training 跟 validation<br>
<br>
0:38:17.400,0:38:19.940<br>
感覺 training data 變少的話，那你可以這麼做<br>
<br>
0:38:19.940,0:38:23.460<br>
已經決定 model 3 是最好的 model<br>
<br>
0:38:23.460,0:38:25.340<br>
你就定住用 model 3<br>
<br>
0:38:25.340,0:38:30.000<br>
但是用全部的 data 在 model 3 上面再 train 一次<br>
<br>
0:38:30.000,0:38:33.600<br>
這樣你就可以使用全部的 training data<br>
<br>
0:38:34.460,0:38:37.700<br>
這個時候，如果你把這個 model<br>
<br>
0:38:37.700,0:38:41.800<br>
apply 到 public set 上面<br>
<br>
0:38:41.800,0:38:45.720<br>
你可能會得到一個大於 0.5 的 error<br>
<br>
0:38:45.720,0:38:50.220<br>
雖然這麼做，你得到的 error 表面上看起來是比較大的<br>
<br>
0:38:50.220,0:38:53.260<br>
但是這個時候，你在 public set 上面的 error<br>
<br>
0:38:53.260,0:38:58.640<br>
才能夠真正反映你在 private set 上的 error<br>
<br>
0:38:58.640,0:39:00.640<br>
這樣大家了解我的意思嗎？<br>
<br>
0:39:00.640,0:39:02.900<br>
當然我可以了解有一種狀況是<br>
<br>
0:39:04.080,0:39:07.320<br>
幾乎沒有辦法，就是在你的心情上<br>
<br>
0:39:07.320,0:39:10.020<br>
基本上沒有辦法避免這麼做就是<br>
<br>
0:39:10.020,0:39:14.220<br>
不建議你這麼做就是，因為通常你看到你的<br>
<br>
0:39:14.220,0:39:18.200<br>
public set 上的結果太差，<br>
你就會想說回頭再去找些甚麼東西<br>
<br>
0:39:18.960,0:39:21.200<br>
那基本上是不建議你這麼做<br>
<br>
0:39:21.200,0:39:24.200<br>
因為如果你回頭再去搞點甚麼東西的話<br>
<br>
0:39:24.200,0:39:30.060<br>
你就變成又把這個 public testing set 的 bias<br>
<br>
0:39:30.060,0:39:31.620<br>
考慮進去了<br>
<br>
0:39:31.620,0:39:34.160<br>
你又把這個 bias 考慮進去<br>
<br>
0:39:34.160,0:39:37.760<br>
這樣會變成說，你在這個 public testing set 上<br>
<br>
0:39:37.760,0:39:41.500<br>
所看到的 performance 沒有辦法反映<br>
<br>
0:39:41.500,0:39:44.520<br>
你在 private set 上看到的 performance<br>
<br>
0:39:44.520,0:39:47.400<br>
但我知道說在心情上<br>
<br>
0:39:47.400,0:39:50.460<br>
你幾乎沒有辦法把持得住不這麼做<br>
<br>
0:39:50.540,0:39:52.800<br>
你可能看到說小毛 ranking 在前面<br>
<br>
0:39:52.800,0:39:55.620<br>
所以你就會想到說我再弄一個結果，擺在它前面這樣子<br>
<br>
0:39:55.620,0:39:58.340<br>
那其實你可以等到，等 private set 真正出來的時候<br>
<br>
0:39:58.340,0:39:59.920<br>
你搞不好就 rank 它前面這樣子<br>
<br>
0:39:59.920,0:40:03.620<br>
所以 public set 並不是最終的結果<br>
<br>
0:40:03.980,0:40:07.200<br>
那比如說，你看你在發 paper 的時候<br>
<br>
0:40:07.200,0:40:09.000<br>
有時候你會 propose 一個方法<br>
<br>
0:40:09.000,0:40:10.920<br>
那你要 attach 在 benchmark 的 corpus<br>
<br>
0:40:12.080,0:40:14.200<br>
當你要 attach 在 benchmark 的 corpus 上面的時候<br>
<br>
0:40:14.200,0:40:15.880<br>
如果你在 testing set 得到一個差的結果<br>
<br>
0:40:15.880,0:40:17.640<br>
你也幾乎沒有辦法把持自己<br>
<br>
0:40:17.640,0:40:19.940<br>
不回頭去調整一下你的 model 這樣子<br>
<br>
0:40:19.940,0:40:22.120<br>
你不會說，我在 testing set 上得到一個差的結果<br>
<br>
0:40:22.120,0:40:24.480<br>
只是寫一個 paper 告訴他說這個方法不 work 這樣子<br>
<br>
0:40:25.820,0:40:28.580<br>
你就會回頭去，因為搞點東、搞點西<br>
<br>
0:40:28.580,0:40:32.260<br>
然後硬是在 testing set 上把結果做起來<br>
<br>
0:40:32.260,0:40:35.600<br>
你幾乎沒有辦法避免做這件事情啦<br>
<br>
0:40:35.600,0:40:38.120<br>
那所以我想你能夠做的事情就是<br>
<br>
0:40:38.120,0:40:41.000<br>
你要 keep in mind，如果在那個 benchmark corpus 上面<br>
<br>
0:40:41.000,0:40:43.620<br>
所看到的 testing 的 performance<br>
<br>
0:40:43.620,0:40:45.760<br>
它的 error，你可以說是假的<br>
<br>
0:40:45.760,0:40:50.240<br>
或者是它大於在 real 的 application 上應該有的值<br>
<br>
0:40:50.340,0:40:51.900<br>
比如說你現在常常聽到說<br>
<br>
0:40:51.900,0:40:54.260<br>
在 image lab 的那個 corpus 上面<br>
<br>
0:40:54.760,0:40:57.220<br>
error rate 都降到 3%，那個是超越人類<br>
<br>
0:40:57.420,0:40:59.640<br>
但是，真的是這樣子嗎？<br>
<br>
0:40:59.640,0:41:01.540<br>
已經有這麼多人玩過這個 corpus<br>
<br>
0:41:01.540,0:41:03.480<br>
它已經有這麼多人試過告訴你說<br>
<br>
0:41:03.480,0:41:05.300<br>
前面那些方法都不 work<br>
<br>
0:41:05.300,0:41:09.160<br>
他們都幫你挑過 model 了，你已經用 testing set 調過參數了<br>
<br>
0:41:09.160,0:41:13.040<br>
所以，如果你把那些 model 真的 apply 到現實生活中<br>
<br>
0:41:13.040,0:41:15.360<br>
它的 error rate 應該會是大於 3%<br>
<br>
0:41:18.240,0:41:19.880<br>
好，那有人會擔心說<br>
<br>
0:41:19.880,0:41:23.620<br>
我這個分，如果分壞了怎麼辦？<br>
<br>
0:41:23.620,0:41:29.120<br>
分壞了，就是說如果這個 validation set 其實也有怪怪的 bias<br>
<br>
0:41:29.120,0:41:32.280<br>
怎麼辦呢？那你可以做下面這件事啦<br>
<br>
0:41:32.280,0:41:35.040<br>
這件事情是：N-fold Cross Validation<br>
<br>
0:41:35.260,0:41:38.420<br>
也就是說，如果你不相信某一次分<br>
<br>
0:41:38.560,0:41:40.400<br>
train 跟 test 的結果的話<br>
<br>
0:41:40.400,0:41:42.920<br>
那你就分很多種不同的樣子<br>
<br>
0:41:42.920,0:41:46.120<br>
比如說，如果你做 3-fold 的  validation<br>
<br>
0:41:46.140,0:41:50.320<br>
意思就是，你把你的 training set 分成 3 份<br>
<br>
0:41:50.320,0:41:53.760<br>
你每一次拿其中一份當做 validation set<br>
<br>
0:41:53.760,0:41:55.760<br>
另外兩份做 training<br>
<br>
0:41:55.760,0:42:01.640<br>
你拿某一份當 validation set，另外兩份當 training<br>
<br>
0:42:02.000,0:42:05.300<br>
接下來呢，如果你要知道 model 1, 2, 3 哪一份比較好的話<br>
<br>
0:42:05.300,0:42:09.920<br>
你就把這 3 個 model 通通在這一個情境下<br>
<br>
0:42:09.980,0:42:13.300<br>
由這兩個 set 做 training ，這個做 validation 的情境下<br>
<br>
0:42:13.300,0:42:14.880<br>
算一下它的 error<br>
<br>
0:42:14.880,0:42:19.700<br>
你在這個情境下，算一下它的 error<br>
<br>
0:42:19.700,0:42:25.040<br>
然後你算一下它的 average error<br>
<br>
0:42:25.040,0:42:27.720<br>
然後你會發現說，在這 3 個情況下的 average<br>
<br>
0:42:27.720,0:42:32.060<br>
是 model 1 最好<br>
<br>
0:42:32.060,0:42:38.100<br>
然後接下來呢，<br>
你就把 model 1再 train 在你完整的 training set 上面<br>
<br>
0:42:38.100,0:42:42.440<br>
然後，再去 test 在你的 testing set 上面<br>
<br>
0:42:43.100,0:42:49.660<br>
那原則上就是，如果你少去太在意你在 public set<br>
<br>
0:42:49.660,0:42:53.600<br>
上面的分數，就是少去根據它調整<br>
<br>
0:42:53.600,0:42:57.360<br>
你的 model 的話，你往往會在 private set上面<br>
<br>
0:42:57.360,0:43:00.820<br>
得到的差距和 testing set 是比較小的<br>
<br>
0:43:01.640,0:43:07.900<br>
好那講到這邊呢，我們就先下課休息 5 分鐘，<br>
然後我們就趕快回來這樣子<br>
<br>
0:43:07.900,0:43:13.180<br>
臺灣大學人工智慧中心<br>
科技部人工智慧技術暨全幅健康照護聯合研究中心<br>
http://aintu.tw<br>
