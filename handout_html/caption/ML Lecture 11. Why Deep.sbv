0:00:00.000,0:00:01.400
臺灣大學人工智慧中心
科技部人工智慧技術暨全幅健康照護聯合研究中心
http://aintu.tw

0:00:01.460,0:00:02.800
告訴我們說，network 越 deep

0:00:02.800,0:00:06.040
從 1 層到 7 層，我的 error rate 不斷地下降

0:00:06.040,0:00:06.662
那問題是

0:00:06.662,0:00:08.840
如果你仔細地思考一下這個問題

0:00:08.840,0:00:10.840
你的 network 越深

0:00:10.840,0:00:13.220
如果你 imply 的是你的參數越多的話

0:00:13.220,0:00:16.020
那這個有甚麼好說的

0:00:16.020,0:00:18.580
你的 model 比較複雜

0:00:18.580,0:00:20.680
你的 data 如果比較多的話

0:00:20.685,0:00:22.480
本來你的 performance 就會比較好

0:00:22.500,0:00:25.320
所以你真正要比較一個

0:00:25.320,0:00:28.900
你真正要比較 Deep 和 Shallow 的 model 的時候

0:00:28.900,0:00:32.600
你應該做的事情是，你要調整 Deep 和 Shallow 的 model

0:00:32.620,0:00:35.720
讓他們的參數是一樣多的

0:00:35.740,0:00:37.360
那很多人在比較 Deep 和 Shallow 的 model 的時候

0:00:37.360,0:00:38.760
是沒有注意到這一件事情的

0:00:38.760,0:00:40.720
所以那一個評比是不公平的

0:00:40.720,0:00:42.760
如果你要給 Deep 和 Shallow 的 model 公平的評比

0:00:42.760,0:00:44.800
你要故意調整他的參數

0:00:44.800,0:00:47.840
讓他們的參數是一樣多的，在這個情況下

0:00:47.840,0:00:50.280
Shallow 的 model 就會是一個

0:00:50.280,0:00:55.060
矮胖的 model，Deep 的 model就會是一個瘦高的 model

0:00:55.060,0:00:56.960
接下的問題就是

0:00:56.960,0:00:58.580
在這個公平的評比之下

0:00:58.580,0:01:01.020
是 Shallow 比較強還是 Deep 比較強 ?

0:01:01.020,0:01:03.700
所以剛才那一個實驗結果裡面呢

0:01:03.700,0:01:05.260
是有後半段

0:01:05.260,0:01:07.120
後半段的實驗結果是這樣說的

0:01:07.120,0:01:10.180
它說我們用 5 層

0:01:10.180,0:01:15.120
每層兩千個 neuron， 得到 error rate 是17.2

0:01:15.120,0:01:18.440
error rate 是越小越好 ，那這一邊用一層

0:01:18.440,0:01:21.980
3772 的 neuron，得到 error rate 是 22.5

0:01:21.980,0:01:23.660
為什麼是 37722 個 neuron 呢？

0:01:23.660,0:01:25.500
這並不是什麼 lucky number

0:01:25.500,0:01:28.300
這是為了讓一個 hidden layer 的 network 跟

0:01:28.300,0:01:34.280
有 5 層的 hidden layer 的 network，它們的參數是接近的

0:01:34.280,0:01:37.300
那如果我們只有一層的 network

0:01:37.300,0:01:40.740
這個時候它的 error rate 是 22.5

0:01:42.520,0:01:44.440
這個 error rate 遠比它大

0:01:44.440,0:01:46.340
如果我們看另外一個 case，7 層

0:01:46.340,0:01:50.040
每層 2000 個 neuron 跟一層 4634 個 neuron

0:01:50.040,0:01:51.980
它們的參數數目是接近的

0:01:51.980,0:01:52.980
這個時候你會發現說

0:01:52.980,0:01:56.700
只有一層它的 performance 是比較差的

0:01:56.700,0:02:02.880
甚至如果你今天再增加 network 的參數變成一層

0:02:02.880,0:02:08.000
但是有 16k 個 neuron，有好多好多的 neuron

0:02:08.000,0:02:10.560
有原來這個 case 的4倍

0:02:10.560,0:02:16.020
那你的 error rate 也只有從 22.6 降到 22.1 而已

0:02:16.020,0:02:21.980
當你用一個只有一層，但非常非常寬的  network

0:02:21.980,0:02:25.060
跟也是只有一層，但是沒有那麼寬的 network 來比

0:02:25.060,0:02:26.040
因為他的參數比較多

0:02:26.040,0:02:28.080
所以它的 performance 還比它強

0:02:28.080,0:02:29.840
它的 performance 還是比它強

0:02:29.840,0:02:31.000
但如果你比較

0:02:31.000,0:02:33.640
這個有兩層的 network 跟這個只有一層的 network

0:02:33.640,0:02:35.300
這個有兩層的 network 的參數遠比它少

0:02:35.300,0:02:37.360
這個參數是少的

0:02:37.360,0:02:38.420
這個參數是多的

0:02:38.420,0:02:41.720
但是結果，這個 case 只有兩層

0:02:41.720,0:02:43.320
它的 performance 還是比

0:02:43.320,0:02:47.480
只有一層的 network 的 performance 還要好

0:02:47.480,0:02:49.360
現在，接下來的問題就是

0:02:50.860,0:02:52.960
為什麼會這樣

0:02:52.960,0:02:55.460
因為在很多人的的想像裡面

0:02:55.460,0:02:57.260
deep learning 會 work 就是因為

0:02:57.260,0:03:01.420
這是一個，有人覺得說 deep learning 就是一個暴力輾壓的方法

0:03:01.420,0:03:03.340
我弄一個大很大的 model

0:03:03.340,0:03:05.240
然後我 collect 一大堆的 data

0:03:05.240,0:03:08.080
所以就得到比較好的 performance

0:03:08.080,0:03:09.540
它就是一個暴力的方法

0:03:09.540,0:03:11.540
你有沒有發現實際不是這個樣子

0:03:11.540,0:03:14.060
如果你今天只是單純的增加 parameter

0:03:14.060,0:03:16.120
但是你是讓 network 長寬

0:03:16.120,0:03:18.420
而不是長高的話

0:03:18.420,0:03:21.460
其實你對 performance 的幫助，是比較小的

0:03:21.460,0:03:25.040
把 network 長高，對 performance 的影響很有幫助

0:03:25.040,0:03:27.420
把 network 長寬 ，幫助沒有那麼好

0:03:27.420,0:03:29.300
為什麼會這樣呢？

0:03:29.300,0:03:33.200
我們可以想像說，當我們在做 deep learning 的時後

0:03:33.200,0:03:38.120
其實我們就是在做這個模組化的這件事情

0:03:38.120,0:03:39.400
甚麼意思呢 ?

0:03:39.400,0:03:41.020
大家都應該會寫程式

0:03:41.020,0:03:43.640
所以你就知道說，當你在寫程式的時候

0:03:43.640,0:03:47.160
你不能把所有的程式都寫在 main function  裡面

0:03:47.160,0:03:50.520
你不能把 5000 行的程式都寫在 main function 裡面

0:03:50.520,0:03:53.740
你會寫一些 subfunction

0:03:53.740,0:03:56.300
對不對，你會在你的 main function 裡面

0:03:56.300,0:03:59.660
去 call subfunction 1、function 2 和 function 3

0:03:59.660,0:04:02.340
然後 function 2 裡面可能還會去 call

0:04:02.340,0:04:04.320
subsub 1、subsub 2 和 subsub 3

0:04:04.320,0:04:08.020
然後 subsub 2 還會再 call  subsubsub2 這個樣子

0:04:08.020,0:04:09.940
它是一層一層

0:04:09.940,0:04:12.980
它是有這個結構化的結構

0:04:12.980,0:04:16.440
但是這個層次，你要有結構化的架構

0:04:16.440,0:04:18.040
這樣做的好處是

0:04:18.040,0:04:21.440
有一些 function 是可以共用的

0:04:21.500,0:04:25.100
比如說，搞不好這個  function 是  sorting

0:04:25.100,0:04:27.300
然後，你只要在其他的

0:04:27.300,0:04:29.600
更 high level 的 function 裡面 call sorting

0:04:29.600,0:04:31.000
就會 call 到這個 function

0:04:31.000,0:04:35.360
你就不用每一次在每一個 subfunction 裡面

0:04:35.360,0:04:36.700
需要做 sorting 的時候

0:04:36.700,0:04:38.460
都 implement 一個完整的 sorting function

0:04:38.460,0:04:39.980
你可以把它變成模組

0:04:39.980,0:04:41.260
需要的時候再去 call 它

0:04:41.260,0:04:44.660
這樣你就可以減少你程式的複雜度

0:04:44.660,0:04:46.200
可以讓你的程式比較簡潔

0:04:47.300,0:04:49.640
那如果用在 machine learning 上面呢

0:04:49.640,0:04:51.740
你可以想像我們現在有架一個 task

0:04:51.740,0:04:53.880
假設我們要做影像分類

0:04:53.880,0:04:57.220
那我們要把 image 分成，比如說 4 類

0:04:57.220,0:04:59.900
比如說，長頭髮女生、長頭髮男生

0:04:59.900,0:05:01.980
和短頭髮女生、短頭髮男生

0:05:01.980,0:05:05.000
那你可能說，我們對這四類我們要分類的影像

0:05:05.000,0:05:06.560
通通去 collect data

0:05:06.560,0:05:09.640
比如說，長頭髮女生可以 collect 到一堆 data

0:05:09.640,0:05:11.500
長頭髮男生也有一些 data

0:05:11.500,0:05:13.460
短頭髮女生，短頭髮男生都有一些 data

0:05:13.460,0:05:15.400
你就去 train 4 個 classifier

0:05:15.400,0:05:17.220
你就可以 solve 這個 problem

0:05:17.340,0:05:19.620
但是問題就是，長頭髮的男生

0:05:19.620,0:05:21.160
你的 data 可能是比較少的

0:05:21.160,0:05:22.360
比如說，在立法院裡面

0:05:22.360,0:05:23.600
只有林昶佐是長頭髮

0:05:23.600,0:05:26.440
那他現在也不是長頭髮，所以這個 data 是比較少的

0:05:26.440,0:05:28.740
就是你沒有太多的 training data

0:05:28.740,0:05:30.340
所以，你 train 出來的

0:05:30.340,0:05:32.440
detect 長頭髮男生的 classifier

0:05:32.440,0:05:33.880
就比較 weak

0:05:33.880,0:05:36.980
所以，你 detect 長頭髮男生的 performance 就比較差

0:05:37.120,0:05:38.340
那怎麼辦呢？

0:05:38.340,0:05:41.320
你可以用模組化的概念

0:05:41.340,0:05:45.020
假設我們現在不是先直接去解那一個問題

0:05:45.020,0:05:49.080
而是把原來的問題切成比較小的問題

0:05:49.080,0:05:51.520
比如說，我們 learn 一些 classifier

0:05:51.520,0:05:53.300
這一些 classifier 它的工作

0:05:53.300,0:05:57.360
是去 detect 有沒有某一種 attribute 出現

0:05:57.360,0:06:00.520
比如說，它不是直接去 detect 說

0:06:00.520,0:06:02.840
是長頭髮男生，還是長頭髮女生

0:06:02.840,0:06:05.520
它是把這個問題切成比較小的問題

0:06:05.520,0:06:07.020
它把這個問題切成

0:06:07.020,0:06:10.600
我們先決定說，input 一張 image，它是男生還是女生

0:06:10.600,0:06:13.580
input 一張 image，它是長頭髮還是短頭髮

0:06:13.580,0:06:16.580
雖然說，長頭髮的男生 data 很少

0:06:16.580,0:06:20.040
雖然說，長頭髮的男生 data 很少

0:06:20.040,0:06:22.140
但女生的 data 和男生的 data 都可以

0:06:22.140,0:06:24.180
分別 collect 到足夠的 data

0:06:24.200,0:06:26.320
雖然，長頭髮男生的 data 很少

0:06:26.320,0:06:29.180
但是長髮的人跟短髮的人的 data

0:06:29.180,0:06:31.060
你都可以 collect 到夠多

0:06:31.060,0:06:34.580
所以你 train 這些 basic 的 classifier 的時候

0:06:34.580,0:06:36.640
你就不會 train 的太差

0:06:36.640,0:06:39.420
你這些 basic 的 classifier 都是有足夠 data

0:06:39.420,0:06:41.500
把它 train 好

0:06:42.180,0:06:45.160
所以，接下來

0:06:45.160,0:06:49.460
如果你要解，最後我們要真正處理的問題的時候

0:06:49.460,0:06:52.900
你的每一個 classifier 就去參考這一些

0:06:52.900,0:06:54.940
basic 的 attribute 的 output

0:06:54.940,0:06:57.520
你就最後要下決定的那一個 classifier

0:06:57.520,0:07:01.100
它是把前面的 basic 的 classifier 當中的 module

0:07:01.100,0:07:03.340
去 call 它的 output

0:07:03.340,0:07:06.300
而每一個 classifier 都共用同樣的 module

0:07:06.300,0:07:07.920
都共用同樣的 module

0:07:07.920,0:07:10.000
只是可能用不同的方式來使用它而已

0:07:10.000,0:07:11.340
對 classifier 來說

0:07:11.340,0:07:14.220
它看到前面的 basic 的 classifier 告訴它說

0:07:14.220,0:07:16.060
是女生、是長頭髮

0:07:16.060,0:07:19.320
那這個 classifier output 就是 yes，反之就是 no

0:07:19.320,0:07:22.440
所以，對後面這些 classifier 來說

0:07:22.440,0:07:24.300
它可以利用前面這些 classifier

0:07:24.300,0:07:28.060
所以它只要用比較少的 training data

0:07:28.060,0:07:31.940
就可以把結果 train 好

0:07:31.940,0:07:34.980
雖然說 classifier 2 的 data 很少

0:07:34.980,0:07:37.460
但是，現在要做的事情是比較簡單的

0:07:37.460,0:07:40.460
真正複雜的事都被 basic classifier 做掉了

0:07:40.460,0:07:42.600
所以，classifier 需要做的事情比較簡單

0:07:42.600,0:07:45.000
所以，比較少的 data，就可以把它 train 好

0:07:45.000,0:07:49.860
那 deep learning 怎麼跟模組化的概念，扯上關係呢？

0:07:49.860,0:07:51.080
你想想看

0:07:51.080,0:07:54.940
每一個 neuron 其實就是一個 basic 的 classifier

0:07:54.940,0:07:58.320
第一層 neuron，它是一個最 basic 的 classifier

0:07:58.320,0:08:01.640
第二層 neuron 是比較複雜的 classifier

0:08:01.640,0:08:03.720
它用第一層 basic 的 classifier 的 output

0:08:03.720,0:08:05.720
當作它的 input

0:08:05.720,0:08:08.660
它把第一層的 classifier 當作 module

0:08:08.660,0:08:11.420
而第三層的 neuron 又把第二層的 neuron

0:08:11.420,0:08:15.880
當作它  module，以此類推

0:08:15.880,0:08:18.280
當然這邊要強調的是說

0:08:18.280,0:08:19.560
在做 deep learning 的時候

0:08:19.560,0:08:22.300
怎麼做模組化這件事情是 machine

0:08:22.300,0:08:24.120
自動學到的

0:08:24.120,0:08:26.000
那我覺得呢，這件事情還頗神奇

0:08:26.000,0:08:27.460
那 machine 就自動學到說

0:08:27.460,0:08:29.380
比如說，在 image 裡面

0:08:29.380,0:08:33.080
第一層 classifier 就是 detect 最單純的 attribute 等等

0:08:33.080,0:08:34.740
那我們剛才說

0:08:34.740,0:08:36.560
做 modularization 的好處是甚麼

0:08:36.560,0:08:38.280
做 modularization 的好處是

0:08:39.000,0:08:42.720
讓我們的模型變簡單了，對不對

0:08:42.720,0:08:45.680
我們是把本來的比較複雜的問題，變得比較簡單

0:08:45.680,0:08:48.920
所以，當我們把問題變簡單的時候

0:08:48.920,0:08:50.740
就算 training data 沒有那麼多

0:08:50.740,0:08:54.020
我們也可以把這個 task 做好

0:08:54.020,0:08:56.980
這個是 modularization、這是模組化的精神

0:08:56.980,0:08:59.240
如果 deep learning 做得是做模組化的話

0:08:59.240,0:09:02.220
其實，神奇的事就是

0:09:02.220,0:09:05.300
deep learning 需要的 training data 是比較少的

0:09:05.980,0:09:08.780
這個，有沒有跟你的認知是相反的呢

0:09:08.780,0:09:11.900
我知道現在因為 deep learning 很紅

0:09:11.900,0:09:14.880
新聞上都有各種各式樣的說法

0:09:14.880,0:09:16.080
常常聽有人說

0:09:16.080,0:09:21.760
AI 就等於 big data 加 deep learning

0:09:21.760,0:09:23.220
那很多人就會覺得說

0:09:23.220,0:09:25.300
所以，這個 deep learning 會 work

0:09:25.300,0:09:28.300
是因為 big data 的關係

0:09:28.300,0:09:31.420
沒有 big data，deep learning 就不會 work

0:09:31.420,0:09:35.720
其實，我認為並不是這個樣子

0:09:35.720,0:09:39.100
你知道嗎 ， 如果你仔細想想看

0:09:39.100,0:09:42.960
假設我有真正很大的 big data

0:09:42.960,0:09:45.700
假設我們今天要做 image 的 classification

0:09:45.700,0:09:49.020
然後，我們的 data base 實在是太大了

0:09:49.020,0:09:52.320
大到我可以把全世界的 image 通通收集進來

0:09:52.320,0:09:54.100
testing 的每一張 image

0:09:54.100,0:09:55.420
都在我的 data base 裡面有一張

0:09:55.420,0:09:57.020
那我何必做 machine learning

0:09:57.020,0:09:58.740
我直接 table lookup 就好了

0:09:58.740,0:10:01.860
所以其實 machine learning 跟 big data

0:10:01.860,0:10:03.640
在某種程度上它們其實是相反的

0:10:03.640,0:10:05.000
你有真正的 big data 的時候

0:10:05.000,0:10:05.940
你就不用 learn 它，你就 table lookup

0:10:05.940,0:10:08.220
我們之所以不能 table lookup

0:10:08.220,0:10:09.540
就是因為沒有足夠 data

0:10:09.540,0:10:13.160
所以，我們才需要 machine 去做舉一反三這件事情

0:10:13.160,0:10:16.620
我們才需要  machine 去做學習這一件事情

0:10:16.620,0:10:21.540
所以這一邊有沒有跟你的認知是不太一樣的呢

0:10:21.540,0:10:25.000
其實當我們做 deep learning 的時候

0:10:25.000,0:10:27.340
就是因為我們沒有足夠的 training data

0:10:27.340,0:10:29.960
所以，我們需要 deep learning

0:10:29.960,0:10:33.620
那剩下的我們就留待下一次再說，謝謝

0:10:46.180,0:10:48.600
好，各位同學大家好

0:10:48.600,0:10:50.120
我們開始上課吧

0:10:50.120,0:10:52.600
上周我我們講到說

0:10:52.600,0:10:55.860
為什麼我們需要用到 deep learning

0:10:55.860,0:10:59.900
然後 ，這是我們已經講過的

0:10:59.900,0:11:02.460
如果你們在用 deep learning 的話

0:11:02.460,0:11:06.560
其實你們是在做模組化這一件事情

0:11:06.560,0:11:10.420
所以，如果從模組化的觀點來看的話

0:11:10.420,0:11:14.360
deep learning 所給我們帶來的優勢並不是

0:11:14.360,0:11:18.220
就像有人說的，我就用一個比較大的 model

0:11:18.220,0:11:22.600
然後有比較多的參數，collect 比較多的 training data

0:11:22.600,0:11:23.920
然後，硬 train 下去，所以

0:11:23.920,0:11:25.860
performance 比 Shallow 的 model 好

0:11:25.860,0:11:27.220
可能不是這樣

0:11:27.220,0:11:31.280
因為我們說 deep learning 的好處是來自於模組化

0:11:31.280,0:11:34.620
那模組化的好處是，我現在是用

0:11:34.620,0:11:38.840
比較 efficient 的方式來使用我的參數

0:11:39.660,0:11:44.180
在影像上面

0:11:44.180,0:11:47.140
你可以觀察到類似模組化的現象

0:11:47.140,0:11:50.200
我今天要講的是，接下來我要講的是

0:11:50.200,0:11:51.720
語音的部分

0:11:51.720,0:11:57.340
那我們知道 deep learning 在影像和語音上表現的特別好

0:11:57.340,0:12:00.920
我們在來一下在語音上

0:12:00.920,0:12:04.120
為什麼我們會需要用到模組化的概念

0:12:04.120,0:12:08.000
那我們先非常非常簡短的介紹一下

0:12:08.000,0:12:12.340
語音的、人類語言的架構

0:12:12.340,0:12:14.420
當你說一句話的時候

0:12:14.420,0:12:17.420
比如說 ，你說 what do you think

0:12:17.420,0:12:21.440
那這句話其實是由一串 phoneme 所組成的

0:12:21.440,0:12:25.140
所謂的 phoneme，它的中文翻成音素

0:12:25.140,0:12:31.820
它是語言學家訂出來的，人類發音的基本單位

0:12:31.820,0:12:33.460
如果你不知道 phoneme 是甚麼的話

0:12:33.460,0:12:36.080
就把它想成是音標

0:12:36.080,0:12:38.460
所以，what 由 4 個 phoneme 組成

0:12:38.460,0:12:41.340
do 由兩個 phoneme 組成，you 由兩個 phoneme 組成

0:12:41.340,0:12:46.540
等等，然後接下來，同樣的 phoneme

0:12:46.540,0:12:49.860
它可能會有不太一樣的發音

0:12:49.860,0:12:53.180
為甚麼呢？當你發 d uw 的時候

0:12:53.180,0:12:55.080
和你發 y uw 的時候

0:12:55.080,0:12:57.860
你心裡想的是同一個 phoneme

0:12:57.860,0:13:00.760
你心裡想要發的都是 uw

0:13:00.760,0:13:04.260
但是，因為人類口腔器官的限制

0:13:04.260,0:13:08.920
所以，你沒辦法每一次發的 uw 都是一樣的

0:13:08.920,0:13:12.900
為甚麼呢？因為這個 uw 前面跟後面

0:13:12.900,0:13:15.000
有接了其他的 phoneme

0:13:15.000,0:13:18.120
因為人類發音器官的限制

0:13:18.120,0:13:22.400
所以，你的 phoneme 的發音會受到前後的 phone 所影響

0:13:22.400,0:13:24.820
所以，為了表達這一件事情

0:13:24.820,0:13:27.880
我們會給同樣的 phoneme

0:13:27.880,0:13:29.720
不同的 model

0:13:29.720,0:13:32.280
這個東西叫做 tri-phone

0:13:32.280,0:13:34.440
那 tri-phone 表達的方式是這樣

0:13:34.440,0:13:37.540
你把這個 uw

0:13:37.540,0:13:40.460
加上前面的 phoneme d 跟後面的 phoneme y

0:13:40.460,0:13:44.620
跟這個 uw 加上前面的 phoneme y 跟後面的 phoneme th

0:13:44.620,0:13:45.940
就是 tri-phone

0:13:45.940,0:13:48.160
那有人看到這種表示方式就覺得說

0:13:48.160,0:13:50.220
tri-phone 就是 3 個 phone

0:13:50.220,0:13:51.680
看起來像是

0:13:51.680,0:13:54.940
本來只考慮一個 phone，現在考慮 3 個

0:13:54.940,0:13:57.460
不是這個意思，不是考慮 3 個 phone 的意思

0:13:57.460,0:13:59.680
這個意思是說，現在一個 phone

0:13:59.680,0:14:02.580
我們用不同的 model 來表示它

0:14:02.580,0:14:05.680
如果一個 phoneme ，它的 contest 不一樣

0:14:05.680,0:14:07.620
這兩個 uw 的 contest 不一樣

0:14:07.620,0:14:09.380
我們就用不同的 model

0:14:09.380,0:14:12.320
來模擬、來描述這樣子的 phoneme

0:14:12.320,0:14:15.580
那一個 phoneme，它可以拆成幾個 state

0:14:15.580,0:14:19.780
state 有幾個，其實是你要自己訂的

0:14:19.780,0:14:22.340
是 engineer 自己訂的，比如說，我們通常就訂成

0:14:22.340,0:14:24.840
3 個 state

0:14:24.840,0:14:30.140
那這個是人類語言的基本架構

0:14:30.140,0:14:32.880
怎麼做語音辨識呢？

0:14:32.880,0:14:34.300
怎麼做語音辨識呢？

0:14:34.300,0:14:37.500
語音辨識其實非常的複雜

0:14:37.500,0:14:40.480
我們現在只是講語音辨識的第一步

0:14:40.480,0:14:42.520
第一步這是你要做的事情是把

0:14:42.520,0:14:46.400
acoustic feature 轉成 state

0:14:46.400,0:14:49.200
這是一個單純的 classification 的 problem

0:14:49.200,0:14:51.360
這個 classification 的 problem 就跟

0:14:51.360,0:14:53.060
比如說，你在作業三

0:14:53.060,0:14:55.760
把 input 一張 image 分成 10 類是一樣的

0:14:55.760,0:14:57.900
現在只是要 input 一個 acoustic feature

0:14:57.900,0:15:00.520
然後，把它分說它是哪一個 state

0:15:00.520,0:15:02.900
所以，acoustic feature 是甚麼呢？

0:15:02.900,0:15:05.460
這邊我們不會細談，所謂的 acoustic feature

0:15:05.460,0:15:07.180
簡單講起來就是

0:15:07.180,0:15:11.120
input 聲音訊號，它是一串 wave form

0:15:11.120,0:15:16.220
那你把這個，在這個 weight phone 上面取一個 window

0:15:16.220,0:15:18.940
這個通常不會取太大

0:15:18.940,0:15:20.500
比如說，250 個 mini second

0:15:20.500,0:15:24.680
你把一個 window 當作

0:15:24.680,0:15:25.940
你把一個 window

0:15:25.940,0:15:27.620
裡面就把它用一個 feature

0:15:27.620,0:15:30.820
來描述這個 window 裡面的特性

0:15:30.820,0:15:33.540
那這個東西，就是一個 acoustic feature

0:15:33.540,0:15:38.220
那你在這個聲音訊號上面呢

0:15:38.220,0:15:41.040
你會每隔一個時間點，每隔一小段

0:15:41.040,0:15:44.020
時間，就取一個 window

0:15:44.020,0:15:47.460
所以，一段聲音訊號就會變成一串

0:15:47.460,0:15:51.120
vector sequence，這個叫做 acoustic feature sequence

0:15:51.120,0:15:53.980
那在做語音辨識的第一階段

0:15:53.980,0:15:55.440
你需要做的事情就是

0:15:55.440,0:15:58.240
決定每一個 acoustic feature

0:15:58.240,0:16:00.900
它屬於哪一個 state

0:16:00.900,0:16:03.840
你要建一個 classifier，這個 classifier 告訴我們說

0:16:03.840,0:16:07.600
第一個 acoustic feature 它屬於 state a, state a

0:16:07.600,0:16:09.280
第三個也屬於 state a

0:16:09.280,0:16:12.000
接下來屬於 state b，接下來屬於 state c 等等

0:16:12.000,0:16:16.640
光只有做這樣子，是沒有辦法做一個語音辨識系統的

0:16:16.640,0:16:18.820
這個東西只是 state 而已

0:16:18.820,0:16:22.220
你要把 state 轉成 phoneme

0:16:22.220,0:16:24.980
然後再把 phoneme 轉成文字

0:16:24.980,0:16:28.760
接下來，你還要考慮同音異字的問題

0:16:28.760,0:16:31.120
用 language model 考慮同音異字的問題，等等

0:16:31.120,0:16:33.300
這個就不是我們今天所要講的

0:16:33.300,0:16:36.660
我想要比較一下

0:16:36.660,0:16:39.800
過去在用 deep learning 之前

0:16:39.800,0:16:42.540
和用 deep learning 之後，在語音辨識上的模型

0:16:42.540,0:16:43.480
有什麼不同

0:16:43.480,0:16:46.180
這個時候，你就更能夠體會說為甚麼 deep learning

0:16:46.180,0:16:51.160
在語音上，會有非常顯著的成果

0:16:51.160,0:16:54.180
那我們說

0:16:54.180,0:16:57.020
我們要繼續做的事情

0:16:57.060,0:16:59.800
在語音辨識的第一個階段，就是要做分類這個問題

0:16:59.800,0:17:01.940
也就是決定一個 acoustic feature

0:17:01.940,0:17:05.160
它屬於哪一個 state

0:17:05.160,0:17:06.440
那傳統的方法呢

0:17:06.440,0:17:09.200
叫做這個 HMM-GMM

0:17:09.200,0:17:11.780
這個 GMM 的方法是怎麼做的呢

0:17:11.780,0:17:12.900
這個方法是說

0:17:12.900,0:17:14.600
我們假設每一個 state

0:17:14.600,0:17:16.920
它就是一個 stationary 的

0:17:16.920,0:17:21.840
它裡面訊號的分佈

0:17:21.840,0:17:25.020
每一個屬於某一個 state 的 acoustic feature 的分佈呢

0:17:25.020,0:17:28.320
是 stationary 的，所以你可以用一個model 來描述他

0:17:28.320,0:17:30.500
比如說，這一個 state

0:17:30.500,0:17:34.780
這個第一當作中心的這個 tri-phone 的第一個 state

0:17:34.780,0:17:39.440
它可以用一個 GMM 來描述它

0:17:39.440,0:17:41.380
那另外一個 state

0:17:41.380,0:17:44.500
可以用另外一個 GMM 來描述它

0:17:44.500,0:17:46.160
這時候給你一個 feature

0:17:46.160,0:17:48.500
你就可以算說，這一個 acoustic feature

0:17:48.500,0:17:51.440
從每一個 state 產生出來的機率

0:17:51.440,0:17:54.680
這個東西叫做 Gaussian Mixture Model，叫做 GMM

0:17:54.680,0:17:57.880
但是如果說你仔細想一想，發現這一招其實

0:17:57.880,0:18:00.240
根本不太 work，為甚麼呢？

0:18:00.240,0:18:03.720
因為 tri-phone 的數目太多了

0:18:03.720,0:18:06.260
一般語言，中文英文

0:18:06.260,0:18:10.160
都有 30 幾、將近 40 個 phoneme

0:18:10.160,0:18:11.680
我們就算 30 個好了

0:18:11.680,0:18:13.420
那在 tri-phone 裡面

0:18:13.420,0:18:16.120
每一個 phoneme，隨著它 contest 的不同

0:18:16.120,0:18:17.660
也要用不同的 model

0:18:17.660,0:18:19.560
所以，到底有多少個 tri-phone

0:18:19.560,0:18:23.660
你有 30 的 3 次方個 tri-phone

0:18:23.660,0:18:28.320
你有 9000 個，不是 9000，是

0:18:28.320,0:18:31.760
是 27000 個 tri-phone

0:18:31.760,0:18:33.160
每一個 tri-phone 又有三個 state

0:18:33.160,0:18:35.760
所以，你有數萬個 state

0:18:35.760,0:18:39.040
你每一個 state 都要很用一個 GMM 來描述

0:18:39.040,0:18:40.520
那參數太多了

0:18:40.520,0:18:41.980
你的 training data 根本不夠

0:18:41.980,0:18:46.180
所以傳統上，在有 deep learning 之前怎麼處理這件事呢

0:18:46.180,0:18:48.960
我們說有一些 state

0:18:48.960,0:18:52.760
其實它們會共用同樣的 model distribution

0:18:52.760,0:18:56.080
這件事情叫做 Tied-state

0:18:56.080,0:18:58.180
這件事情叫做 Tied-state

0:18:58.180,0:19:00.120
那你可能會覺得有點抽象

0:19:00.120,0:19:04.880
甚麼叫做不同的 state 共用同樣的 distribution 呢

0:19:04.880,0:19:05.940
意思就是說

0:19:05.940,0:19:08.900
假如你在寫程式的時候

0:19:08.900,0:19:13.520
不同的 state 的名稱，就好像是 pointer 一樣

0:19:13.520,0:19:16.200
所以，實際上你真的在寫程式的時候，你就這麼寫

0:19:16.200,0:19:18.700
state 的名稱是 pointer

0:19:18.700,0:19:20.640
那不同的 pointer

0:19:20.640,0:19:23.880
它們可能會指向同樣的

0:19:26.440,0:19:30.200
它們可能會指向同樣的 distribution

0:19:30.200,0:19:31.420
所以，有一些 state

0:19:31.420,0:19:33.380
它的 distribution 是共用的

0:19:33.380,0:19:34.660
有一些沒有共用

0:19:34.660,0:19:36.520
到底哪一些要共有，哪一些不要共用

0:19:36.520,0:19:39.220
就變成說，你要憑著經驗

0:19:39.220,0:19:42.300
還有一些語言學的知識阿

0:19:42.300,0:19:45.660
來決定說哪些 state 它們的聲音是需要共用的

0:19:45.660,0:19:47.420
可是，這樣是不夠的

0:19:47.420,0:19:51.040
如果只分 state 的 distribution

0:19:51.040,0:19:53.360
要共用或不共用，這樣太粗了

0:19:53.360,0:19:55.740
所以，有的人就會開始提出一些想法說

0:19:55.740,0:19:59.060
如何讓它部分共用，等等

0:19:59.060,0:20:01.320
那在 deep learning 火紅之前

0:20:01.320,0:20:05.660
再前一個提出來比較有創新的方法，叫做 subspace GMM

0:20:05.660,0:20:10.200
那其實它裡面有這個 modularization、有模組化的影子

0:20:10.200,0:20:12.380
在這個 subspace GMM 裡面呢

0:20:12.380,0:20:15.580
這個方法是說，我們原來是每一個

0:20:15.580,0:20:17.680
state 它就有一個 distribution

0:20:17.680,0:20:19.860
在 subspace GMM 裡面，它說

0:20:19.860,0:20:23.320
我們先把很多很多的 Gaussian

0:20:23.320,0:20:26.700
先找出來，我們先找一個 Gaussian pool

0:20:26.700,0:20:30.240
那每一個 state，它的 information 就是一個 key

0:20:30.240,0:20:33.220
那一個  key 告訴我們說，這個 state

0:20:33.220,0:20:36.420
要從這個 Gaussian 的 pool 裡面

0:20:36.420,0:20:40.920
挑那些 Gaussian 出來，比如說

0:20:40.920,0:20:42.540
可能有某一個 state 1

0:20:42.540,0:20:45.240
它挑第一、第三、第五個 Gaussian

0:20:45.240,0:20:48.400
某一個 state 2，它挑第一、第四、第六個 Gaussian

0:20:48.400,0:20:50.260
如果你這樣做的話

0:20:50.260,0:20:53.620
這些 state 有些時候就可以 share 部分的 Gaussian

0:20:53.620,0:20:56.020
那有些時候就可以完全不 share Gaussian

0:20:56.020,0:20:57.780
那至於要 share 多少的 Gaussian

0:20:57.780,0:21:02.120
這個東西，是可以從 training data 去把它學出來的

0:21:02.120,0:21:06.320
這個是在 DNN 火紅之前的做法

0:21:06.320,0:21:09.580
但是，如果你仔細想想

0:21:09.580,0:21:12.340
剛才講的這個，HMM-GMM 的方式

0:21:12.340,0:21:15.020
所有的 phone 或者是 state

0:21:15.020,0:21:16.960
是 independent model 的

0:21:16.960,0:21:20.180
這件事情是不 efficient 的

0:21:20.180,0:21:22.260
對 model 人類的聲音來說

0:21:22.260,0:21:24.900
那如果你想想看人類的聲音

0:21:24.900,0:21:27.700
不同的 phoneme

0:21:27.700,0:21:32.080
雖然說我們把它歸類為不同的音素

0:21:32.080,0:21:35.220
我們在分類的時候把他歸類為不同的 class

0:21:35.220,0:21:37.240
但這些 phoneme 之間並不是

0:21:37.240,0:21:38.800
完全無關的

0:21:38.800,0:21:44.040
它們都是由人類的發音器官所 generate 出來的

0:21:44.040,0:21:48.140
它們中間是有根據人類發音器官發音的方式

0:21:48.140,0:21:50.120
它們是有某些關係的

0:21:50.120,0:21:52.640
舉例來說，在這個圖上

0:21:52.640,0:21:55.480
這個圖呢，在這個圖上呢

0:21:55.480,0:22:01.000
人類語言裡面所有的母音

0:22:01.000,0:22:03.680
這個母音的發音呢

0:22:03.680,0:22:06.940
其實，就只受到三件事情的影響而已

0:22:06.940,0:22:10.560
一個是你舌頭的前後的位置

0:22:10.560,0:22:13.340
一個是你舌頭上下的位置

0:22:13.340,0:22:16.700
還有一個，就是你的嘴型

0:22:16.700,0:22:18.240
所以，一個母音的發音

0:22:18.240,0:22:20.480
其實就只受到這三件事的影響而已

0:22:20.480,0:22:22.100
比如說，在這個圖上呢

0:22:22.100,0:22:25.580
你可以找到英文的五個

0:22:25.580,0:22:30.840
常見的、英文的 5 個母音 a, e, i, o, u

0:22:30.840,0:22:33.400
這個  a, e, i, o, u 啊

0:22:33.400,0:22:35.380
它們之間的差別就是

0:22:35.380,0:22:39.840
當你發 a 到 e 到 i 的時候

0:22:39.840,0:22:42.280
你的舌頭是由下往上

0:22:42.280,0:22:45.000
那個 i 跟 o 的差別呢

0:22:45.000,0:22:48.380
是你的舌頭放在前面或放在後面的差別

0:22:48.380,0:22:53.740
所以，如果你發 a, e, i, o, u 的話

0:22:53.740,0:22:55.540
你的舌頭變化方式呢

0:22:55.540,0:22:57.100
就會這張圖一樣

0:22:57.100,0:22:59.560
相信這個時候，你心理一定是在想

0:22:59.560,0:23:01.920
一定是在默念 a, e, i, o, u 這樣

0:23:01.920,0:23:04.500
然後，你會想說

0:23:04.500,0:23:06.240
怎麼感覺不太出來

0:23:06.240,0:23:11.260
我發現你自己唸，不太會感覺你的舌頭位置在哪裡

0:23:11.260,0:23:15.220
你要知道說，你的舌頭位置是不是真的跟這個圖上一樣

0:23:15.220,0:23:19.540
你就回去張大嘴巴，對著鏡子唸 a, e, i, o, u

0:23:19.540,0:23:21.780
你會發現說，你舌頭的位置呢

0:23:21.780,0:23:23.820
就跟這個圖上是一模一樣的

0:23:24.320,0:23:27.640
在這個圖上，同一個位置

0:23:27.640,0:23:29.680
的母音呢

0:23:29.680,0:23:33.040
代表說，舌頭的位置是一樣的，但是

0:23:33.040,0:23:34.840
嘴型是不一樣的

0:23:34.840,0:23:36.780
比如說，我們看左上角

0:23:36.780,0:23:40.320
在最左上角的位置有兩個母音

0:23:40.320,0:23:45.320
一個是 i，一個是 u 這樣

0:23:45.320,0:23:47.520
那 i 跟 u 的差別

0:23:47.520,0:23:51.120
它們舌頭位置是一樣的，只是嘴型是不一樣的

0:23:51.120,0:23:54.420
如果是 i 的話，嘴是比較扁的

0:23:54.420,0:23:57.520
u 的話，嘴是比較圓的

0:23:57.520,0:24:00.520
所以，你只要改變嘴型的位置，就可以從 i 變成 u

0:24:00.520,0:24:03.860
你本來發 i~~~u~~~ 這樣子

0:24:03.860,0:24:06.380
你改變一下嘴型，它的發音就不一樣

0:24:10.760,0:24:15.620
所以說，因為不同的 phoneme 之間是有關係的

0:24:15.620,0:24:19.180
所以，你說每一個 phoneme 都搞一個自己的 model

0:24:19.180,0:24:22.420
這件事情其實是沒有效率的

0:24:22.420,0:24:24.820
那如果今天是用

0:24:24.820,0:24:26.740
deep learning 是怎麼做的呢

0:24:26.740,0:24:28.880
如果是 deep learning 的話

0:24:28.880,0:24:33.160
你就是去 learn 一個 deep neural network

0:24:33.160,0:24:35.100
這個 deep neural network 的 input 呢

0:24:35.100,0:24:38.000
就是一個 acoustic feature

0:24:38.000,0:24:43.080
它的 output 就是每一個 feature 屬於哪一個 state 的機率

0:24:43.080,0:24:45.420
這是一個很單純的 classification 的 problem

0:24:45.420,0:24:48.200
跟你作業三做在影像上是沒有甚麼差別的

0:24:48.200,0:24:51.760
learn 一個 DNN，input 是一個 acoustic feature

0:24:51.760,0:24:55.100
output 就是告訴你說，這個 acoustic feature

0:24:55.100,0:24:56.240
屬於每一個 state

0:24:56.240,0:24:59.980
它屬於 state a, state b, state c 的機率

0:24:59.980,0:25:02.800
那這邊最關鍵的一點是

0:25:02.800,0:25:04.720
所有的 state

0:25:04.720,0:25:07.500
都共用同一個 DNN

0:25:07.500,0:25:10.260
在整個辨識裡面，你就只有一個 DNN 而已

0:25:10.260,0:25:14.840
你沒有每一個 state 都有一個 DNN

0:25:14.840,0:25:16.240
所以，有人覺得說

0:25:16.240,0:25:18.700
所以，有些人他沒有想清楚

0:25:18.700,0:25:21.480
這個 deep learning 到底 powerful 在哪裡，他會說

0:25:21.480,0:25:24.160
從 GMM 變到 deep learning 厲害的地方就是

0:25:24.160,0:25:30.780
本來 GMM 通常你最多也就做 64 個 Gaussian mixture 而已

0:25:30.780,0:25:35.880
那 DNN 有 10 層，每層 1000 個 neuron

0:25:35.880,0:25:38.780
果然參數很多，參數變多了，所以 performance 變好了

0:25:38.780,0:25:41.400
這是一個暴力輾壓的方法，其實也沒什麼

0:25:41.400,0:25:43.580
其實 DNN 不是一個暴力輾壓的方法

0:25:43.580,0:25:48.100
你仔細想想看，在做 HMM-GMM 的時候

0:25:48.100,0:25:49.860
你說 GMM 只有 64 個 mixture

0:25:49.860,0:25:52.460
好像覺得很簡單，但是其實你是

0:25:52.460,0:25:55.040
每一個 state 都有一個 Gaussian mixture

0:25:55.040,0:25:57.640
所以真正合起來，它的參數是多得不得了的

0:25:57.640,0:25:59.920
如果你仔細去算一下

0:25:59.920,0:26:02.800
GMM 用的參數跟 DNN 用的參數

0:26:02.800,0:26:05.420
我曾經在不同的 task 上估測過這一件事情

0:26:05.420,0:26:08.280
它們用的參數，你會發現其實是差不多多的

0:26:08.280,0:26:10.780
所以，DNN 它只是用一個很大的 model

0:26:10.780,0:26:13.280
GMM 是用很多很小的 model

0:26:13.280,0:26:15.700
但是，當我們把這兩個東西拿來比較的時候

0:26:15.700,0:26:18.280
其實它們用的參數量，是差不多多的

0:26:18.280,0:26:21.320
但是，DNN 把所有的

0:26:21.320,0:26:25.580
它把所有的 state

0:26:25.580,0:26:29.640
通通用同一個 model 來做分類

0:26:29.640,0:26:32.060
會是比較有效率的做法

0:26:32.060,0:26:35.400
為甚麼這樣是比較有效率的做法呢

0:26:35.400,0:26:39.160
舉例來說，如果你今天把

0:26:39.160,0:26:40.700
一個 DNN

0:26:40.700,0:26:44.140
它的某一個 hidden layer 拿出來

0:26:44.140,0:26:47.480
然後，因為一個 hidden layer

0:26:47.480,0:26:49.560
比如說，它其實有 1000 個 neuron

0:26:49.560,0:26:51.280
你沒有辦法分析它

0:26:51.280,0:26:54.060
但是，你可以把那 1000 個 layer 的 output 降維

0:26:54.060,0:26:56.060
降到 2 維

0:26:56.060,0:26:58.080
所以，在這個圖上

0:26:58.080,0:27:03.480
每一個點代表了一個 acoustic feature

0:27:03.480,0:27:06.320
它通過 DNN 以後

0:27:06.320,0:27:09.960
它通過 DNN 以後

0:27:09.960,0:27:12.860
它把它這個 output layer 的 output 降到二維

0:27:12.860,0:27:15.280
可以發現說它的分布是長這個樣子的

0:27:15.280,0:27:18.460
在這個圖上的顏色代表甚麼意思呢

0:27:18.460,0:27:21.340
這邊的顏色，其實就是

0:27:21.340,0:27:23.340
a, e, i

0:27:23.340,0:27:31.100
a, e, i, o, u 這樣，特別把這 5 個母音

0:27:31.100,0:27:34.680
用跟這邊圖的顏色一樣的框框

0:27:34.680,0:27:36.020
把它框起來

0:27:36.020,0:27:38.800
那你會發現神奇的事就是

0:27:38.800,0:27:41.820
這邊，這 5 個母音的分布

0:27:41.820,0:27:46.380
跟這一個圖的分布，其實幾乎是一樣的

0:27:46.380,0:27:49.840
這邊是 a, e, i, o, u

0:27:49.840,0:27:51.920
這邊是 a, e, i, o, u

0:27:51.920,0:27:54.420
所以，你可以發現說

0:27:54.420,0:27:56.180
DNN 在做的事情

0:27:56.180,0:27:58.820
它的比較 lower 的 layer 做的事情

0:27:58.820,0:27:59.720
它其實是在

0:27:59.720,0:28:02.420
它並不是真的要要馬上去偵測說

0:28:02.420,0:28:04.560
現在 input 這個發音，它是屬於

0:28:04.560,0:28:07.400
哪一個 phone 或哪一個 state，它做的事情是

0:28:07.400,0:28:10.480
它先觀察說，當你聽到這個發音的時候

0:28:10.480,0:28:12.520
人是用甚麼樣的方式

0:28:12.520,0:28:13.880
在發這個聲音的

0:28:13.880,0:28:15.860
它的舌頭的位置在哪裡

0:28:15.860,0:28:18.500
它的舌頭位置是高還是低呢

0:28:18.500,0:28:21.900
它的舌頭位置是在前還是後呢，等等

0:28:21.900,0:28:25.860
然後，lower 的 layer，比較靠近 input 的 layer

0:28:25.860,0:28:28.180
我們今天知道了發音的方式以後

0:28:28.180,0:28:31.060
接下來的 layer，再根據

0:28:31.060,0:28:33.680
這個結果，去決定說

0:28:33.680,0:28:37.400
現在的發音是屬於哪一個 state 或哪一個 phone

0:28:37.400,0:28:39.420
所以，所有的 phone 呢

0:28:39.420,0:28:42.380
會用同一組 detector

0:28:42.380,0:28:44.100
也就是這些 lower 的 layer

0:28:44.100,0:28:46.140
是一個人類發音方式的 detector

0:28:46.140,0:28:48.600
而所有的 phone 的偵測都是用

0:28:48.600,0:28:50.580
同一組 detector 完成的

0:28:50.580,0:28:54.220
所有 phone 的偵測，都 share 同一組的參數

0:28:54.220,0:28:58.460
所以，它這邊就有做到模組化這件事情

0:28:58.460,0:29:00.320
當你做模組化的時候

0:29:00.320,0:29:02.960
你是用比較少的參數

0:29:02.960,0:29:05.880
你是用比較有效率的方式

0:29:05.880,0:29:07.720
來使用你的參數

0:29:07.720,0:29:10.120
所以，我們回到

0:29:10.120,0:29:11.980
我們很久以前就提過的

0:29:11.980,0:29:14.400
Universality 的 Theorem

0:29:14.400,0:29:18.160
過去有一個理論告訴我們說

0:29:18.160,0:29:20.660
任何的 continuous 的 function

0:29:20.660,0:29:24.860
它都可以用一層 neural network 來完成

0:29:24.860,0:29:27.840
只要那層 neural network 夠寬的話

0:29:27.840,0:29:30.160
在 90 年代

0:29:30.160,0:29:33.740
這是很多人放棄做 deep learning 的一個原因

0:29:33.740,0:29:35.800
你想想看，只要一層 hidden layer

0:29:35.800,0:29:39.120
就可以完成所有的 function

0:29:39.120,0:29:41.380
一層 hidden layer 就可以表示所有的 function

0:29:41.380,0:29:44.160
那做 deep learning 的意義何在呢

0:29:44.160,0:29:47.620
所以很多人覺得說，deep 是沒有必要的

0:29:47.620,0:29:50.400
我們就只要一個 hidden layer 就好

0:29:51.380,0:29:55.540
但是，這個理論有一件事情沒有告訴我們的是

0:29:55.540,0:29:58.560
它只告訴我們可能性

0:29:58.560,0:30:02.380
但是它沒有告訴我們說，要做到這件事情

0:30:02.380,0:30:04.780
有多有效率

0:30:04.780,0:30:08.640
就是，沒錯，你只要有夠多的

0:30:08.640,0:30:11.380
參數，你只要這個 hidden layer 夠寬

0:30:11.380,0:30:15.520
你就可以描述任何的 function

0:30:15.520,0:30:18.440
但是，這個理論沒有告訴我們的事情是

0:30:18.440,0:30:21.660
當我們用這一件事情

0:30:21.660,0:30:23.560
我們只用一個 hidden layer

0:30:23.560,0:30:25.660
來描述 function 的時候

0:30:25.660,0:30:27.700
它其實是沒有效率的

0:30:27.700,0:30:31.740
當你有 multi-layer，當你有 hierarchy 的 structure

0:30:31.740,0:30:34.860
你用這個方式來描述你的 function 的時候

0:30:34.860,0:30:36.960
它是比較有效率的

0:30:37.720,0:30:41.440
如果剛才模組化的概念，你沒有聽得很明白的話呢

0:30:41.440,0:30:43.840
我們這邊舉另外一個例子

0:30:43.840,0:30:46.880
如果，你是 EE 的 background

0:30:46.880,0:30:49.200
然後，你修過交換電路的話

0:30:49.200,0:30:52.440
我相信你聽過這個例子以後，就會對

0:30:52.440,0:30:56.500
deep 為甚麼 powerful 沒有太多的懷疑

0:30:56.500,0:31:00.740
我想 EE background 的人，都修過

0:31:00.740,0:31:02.700
邏輯電路

0:31:02.700,0:31:07.160
其實邏輯電路可以跟 neural network 類比

0:31:07.160,0:31:09.580
我們知道在邏輯電路裡面

0:31:09.580,0:31:12.840
我們的電路是由一堆邏輯閘

0:31:12.840,0:31:15.300
AND gate, NOR gate 所構成的

0:31:15.300,0:31:18.400
對不對，在 neural network 裡面

0:31:18.400,0:31:22.680
整個 network 是由一堆 neuron、神經元所構成的

0:31:22.680,0:31:26.660
如果你有修過邏輯電路的話，你會知道說

0:31:26.660,0:31:29.580
其實只要兩層邏輯閘

0:31:29.580,0:31:33.100
你就可以表示任何的 boolean function

0:31:33.100,0:31:36.700
如果你修過邏輯電路的話，你應該知道這件事

0:31:36.700,0:31:39.940
這件事情應該不會讓你特別的驚訝

0:31:39.940,0:31:44.920
所以，既然兩層邏輯閘可以表示任何的 boolean function

0:31:44.920,0:31:47.580
那有一個 hidden layer 的 neural network

0:31:47.580,0:31:49.620
有一個 hidden layer 的 neural network，其實也是兩層

0:31:49.620,0:31:52.740
它一個 input layer、一個 output layer，所以它也是兩層

0:31:52.740,0:31:54.800
有一個 hidden layer 的 neural network

0:31:54.800,0:31:57.060
它可以表示任何的 continuous function

0:31:57.060,0:32:00.100
其實，也不會讓人特別的驚訝

0:32:00.100,0:32:03.860
但是，雖然我們可以用兩層邏輯閘

0:32:03.860,0:32:07.200
就描述任何的 boolean function

0:32:07.200,0:32:10.280
但是，實際上你在做電路設計的時候，你根本

0:32:10.280,0:32:12.180
不可能會這樣做，對不對

0:32:12.180,0:32:15.180
你可以用兩層邏輯閘就做一台電腦，但是

0:32:15.180,0:32:17.300
沒有人會這麼做

0:32:17.300,0:32:22.620
為甚麼呢？因為當你用 hierarchy 的架構的時候

0:32:22.620,0:32:24.700
當你不是用兩層邏輯閘，而是用

0:32:24.700,0:32:26.380
很多層的時候

0:32:26.380,0:32:29.240
這個時候，你拿來設計一個電路是

0:32:29.240,0:32:30.500
比較有效率的

0:32:30.500,0:32:32.720
雖然，兩層邏輯閘可以做到同樣的事情

0:32:32.720,0:32:34.820
但是，這麼做是沒有效率的

0:32:34.820,0:32:37.620
如果類比到 neural network 的話

0:32:37.620,0:32:39.920
其實，意思是一樣的

0:32:39.920,0:32:44.080
你用一層 hidden layer 可以做到任何事情

0:32:44.080,0:32:48.740
但是，用比較多的 hidden layer 是比較有效率的

0:32:49.220,0:32:53.360
所以，從邏輯閘這邊來看，你用多個邏輯閘

0:32:53.360,0:32:57.680
你用多層的架構，可以用比較少的邏輯閘就完成一個電路

0:32:57.680,0:33:00.620
那你用比較多層的

0:33:00.620,0:33:03.400
你用比較多層的 neural network

0:33:03.400,0:33:07.020
你就可以用比較少的 neuron 就完成同樣的 function

0:33:07.020,0:33:09.660
所以，你會需要比較少的參數

0:33:09.660,0:33:11.660
比較少的參數意謂著甚麼

0:33:11.660,0:33:14.840
比較少的參數意謂著，你比較不容易 overfitting

0:33:14.840,0:33:19.060
或者是，你其實只需要比較少的 data

0:33:19.060,0:33:23.500
你就可以完成你現在要 train 的任務

0:33:23.500,0:33:27.940
所以，這件事情有沒有跟你平常的認知是相反的呢

0:33:27.940,0:33:29.780
很多人的認知是

0:33:29.780,0:33:32.800
deep learning 就是很多 data 硬輾壓過去

0:33:32.800,0:33:35.720
其實不是，當我們用 deep learning 的時候

0:33:35.720,0:33:37.780
我們可以用比較少的 data

0:33:37.780,0:33:39.700
就達到同樣的任務

0:33:39.700,0:33:45.180
我們從邏輯閘這邊，再舉一個實際的例子

0:33:45.180,0:33:48.240
假設我們現在要做 parity check

0:33:48.240,0:33:50.320
假設你要設計一個電路做 parity check

0:33:50.320,0:33:52.780
那甚麼是 parity check，就是

0:33:52.780,0:33:56.180
你希望 input 一串數字

0:33:56.180,0:33:58.920
input 一串 binary 的數字

0:33:58.920,0:34:03.300
如果裡面出現的 1 的數目是偶數的話

0:34:03.300,0:34:06.480
它的 output 就是 1，如果出現的是奇數的話呢

0:34:06.480,0:34:08.680
它的 output 就是 0

0:34:08.680,0:34:13.580
假設你 input 的 sequence 的長度

0:34:13.580,0:34:16.220
總共有 1 個 bit 的話

0:34:16.220,0:34:19.440
那用兩層邏輯閘，理論上可以保證你

0:34:19.440,0:34:23.660
你要 2^d 個 gate

0:34:23.660,0:34:28.200
你要 2^d 個 gate，才能夠描述

0:34:28.200,0:34:33.320
才能描述這樣子的一個電路

0:34:33.320,0:34:36.340
但是，如果你用多層次的架構的話

0:34:36.340,0:34:37.960
你就可以用比較少的邏輯閘

0:34:37.960,0:34:40.060
就做到 parity check 這件事情

0:34:40.060,0:34:42.380
舉例來說，你可以把

0:34:42.380,0:34:45.900
好幾個 XNOR gate 接在一起

0:34:45.900,0:34:50.820
如果你把邏輯閘用這種方式接的話

0:34:50.820,0:34:52.720
現在 input 1 跟 0

0:34:52.720,0:34:56.880
我把 XNOR gate 的真值表放在右上角

0:34:56.880,0:34:59.380
input 1 跟 0，它的 output 就是 0

0:34:59.380,0:35:02.960
i然後，input 0 跟 1，它的 output 就是 0

0:35:02.960,0:35:04.940
input 0 跟 0，它的 output 是 1

0:35:04.940,0:35:07.180
你就做完 parity check 這件事情了

0:35:07.180,0:35:11.340
這邊用的就是一個 hierarchical 的架構

0:35:11.340,0:35:13.820
當你用這樣子的架構的時候

0:35:13.820,0:35:17.560
當你用這種比較多層次的架構的時候

0:35:17.560,0:35:20.720
你其實只需要 O(d) gates

0:35:20.720,0:35:23.520
你就可以完成你現在要做的任務了

0:35:23.520,0:35:27.300
所以，當你用比較多層次的架構來設計電路的時候

0:35:27.300,0:35:30.480
你可以用比較少的邏輯閘，就達到同樣的事情

0:35:30.480,0:35:32.700
這對 neural network 來說也是一樣的

0:35:32.700,0:35:35.640
用比較少的 neuron，去描述同樣的 function

0:35:35.640,0:35:39.300
如果剛才舉的例子，你沒有聽懂的話

0:35:39.300,0:35:41.620
如果你沒有修過邏輯電路，你沒有聽懂的話

0:35:41.620,0:35:44.940
以下是一個日常生活中就會碰到的例子

0:35:44.940,0:35:46.920
這個例子是剪窗花的

0:35:46.920,0:35:48.860
剪窗花大家知道嗎？

0:35:48.860,0:35:50.500
剪窗花就是說

0:35:50.500,0:35:52.120
這個應該不用解釋啦

0:35:52.120,0:35:54.620
就是一個色紙，然後把它摺起來

0:35:54.620,0:35:56.960
然後再剪一剪，就可以變成這個樣子

0:35:56.960,0:36:00.320
你並不是真的去把這個形狀的花樣剪出來

0:36:00.320,0:36:02.280
這樣太麻煩了，你先把紙摺起來

0:36:02.280,0:36:03.820
然後才剪這樣子

0:36:03.820,0:36:06.600
這個跟 deep learning 有什麼關係呢

0:36:06.600,0:36:12.100
你想想看我們用之前講的

0:36:12.100,0:36:15.460
我們用之前講的這個例子來做比喻

0:36:15.460,0:36:19.540
假設我們現在 input 的點有四個

0:36:19.540,0:36:23.180
有四個，那這個紅色的點是一類

0:36:23.180,0:36:25.420
藍色的點是一類

0:36:25.420,0:36:28.280
我們之前講說如果你沒有 hidden layer 的話

0:36:28.280,0:36:30.580
如果你是一個 linear 的 model，你要怎麼做

0:36:30.580,0:36:32.960
都沒有辦法把藍色分在一邊

0:36:32.960,0:36:34.500
把紅色分在一邊

0:36:34.500,0:36:37.720
但是，當你加了 hidden layer 的時候會發生什麼事呢

0:36:37.720,0:36:40.060
當你加了 hidden layer 的時候

0:36:40.060,0:36:43.200
就做了一個 feature 的 transformation

0:36:43.200,0:36:45.700
你把原來的 x1, x2

0:36:45.700,0:36:47.260
你把原來的 x1, x2

0:36:47.260,0:36:50.620
ship 到另外一個平面，轉換到另外一個平面

0:36:50.620,0:36:53.440
變成 x1'、x2'

0:36:53.440,0:36:55.800
變成 x1'、x2'

0:36:55.800,0:36:59.220
所以，原來的紅色這個點跑到這裡

0:36:59.220,0:37:02.000
原來的紅色這個點跑到這裡

0:37:02.000,0:37:04.820
原來這兩個藍色的點都跑到這裡

0:37:04.820,0:37:07.200
所以，你發現這兩個藍色的點呢

0:37:07.200,0:37:08.940
是重合在一起

0:37:08.940,0:37:12.140
所以，當你從這裡

0:37:12.140,0:37:16.920
通過一個 hidden layer 變到這裡的時候

0:37:16.920,0:37:20.480
其實你就好像是把原來的這個平面

0:37:20.480,0:37:21.720
對折了一樣

0:37:21.720,0:37:24.200
你把這個平面對折，所以這個藍色的點

0:37:24.200,0:37:27.940
跟這個藍色的點，這兩個藍色的點重和在一起

0:37:27.940,0:37:30.620
這就好像是說我們在做

0:37:30.620,0:37:34.000
剪窗花的時候，先把色紙對折一樣

0:37:34.000,0:37:37.800
你把這兩個平面對折，就好像是把色紙對折一樣

0:37:37.800,0:37:40.040
當你把這個色紙對折的時候

0:37:40.040,0:37:43.540
如果你在這個地方戳一個洞

0:37:43.540,0:37:46.600
到時候，你把色紙打開的時候

0:37:46.600,0:37:50.280
它只要看你摺幾折，它在這些地方

0:37:50.280,0:37:52.560
都會有一個洞

0:37:52.560,0:37:56.520
所以，如果你把剪窗花這件事情

0:37:56.520,0:37:58.660
想成是 training

0:37:58.660,0:38:01.740
你把剪色紙這件事情

0:38:01.740,0:38:04.820
想成是根據我們的 training data

0:38:04.820,0:38:07.200
training data 告訴我們說

0:38:07.200,0:38:09.700
有畫斜線的部分是 positive

0:38:09.700,0:38:13.400
沒畫斜線的部分是屬於 negative example

0:38:13.400,0:38:15.800
假設我們已經把這個平面 

0:38:15.800,0:38:17.920
像色紙一樣折起來的時候 

0:38:17.920,0:38:20.780
這個時候 training data 只要告訴我們說

0:38:20.780,0:38:24.260
在這個範圍之內、在這個範圍之內、在這個範圍之內

0:38:24.260,0:38:26.540
是屬於 positive 的

0:38:26.540,0:38:29.620
它只要告訴我們這個小的區間裡面的 data

0:38:29.620,0:38:33.100
展開以後我們就可以做出複雜的圖樣

0:38:33.100,0:38:36.280
那本來 training data 只告訴我們比較簡單的事情 

0:38:36.280,0:38:41.100
但是因為，現在有把空間對折的關係

0:38:41.100,0:38:43.940
你現在要把空間做各種各樣對折的關係

0:38:43.940,0:38:48.140
所以展開以後，你就可以有非常複雜的圖案

0:38:48.140,0:38:51.360
或者是說，你只要在這個地方戳一個洞

0:38:51.360,0:38:55.480
在其他地方，也就都等於戳一個洞

0:38:55.480,0:38:58.680
所以，一筆 data，如果只用這個例子來看的話

0:38:58.680,0:39:01.420
一筆 data 它就可以發揮五筆 data 的效用

0:39:01.420,0:39:03.360
所以，當你做 deep learning 的時候

0:39:03.360,0:39:05.840
你其實是用比較有效率的方式

0:39:05.840,0:39:08.120
來使用你的 data

0:39:08.120,0:39:11.000
你可能會想說，真的是這個樣子嗎

0:39:11.000,0:39:13.860
我在文獻上沒有看到太好的例子

0:39:13.860,0:39:16.140
這個比較像是我臆測

0:39:16.140,0:39:17.840
但是我做了一個 toy example

0:39:17.840,0:39:19.600
來展示這件事情

0:39:19.600,0:39:21.640
這個 toy example 是這樣子的

0:39:21.640,0:39:23.740
我們有一個 function

0:39:23.740,0:39:26.760
它的 input 是

0:39:26.760,0:39:30.700
二維 R^2，它的 output 是 0 跟 1

0:39:30.700,0:39:33.760
那這個 function 是一個地毯形狀的 function

0:39:33.760,0:39:35.600
地毯形狀的 function

0:39:35.600,0:39:37.540
在這個紅色的、菱形的範圍內

0:39:37.540,0:39:41.740
它的 input 這個 R^2，就是座標

0:39:41.740,0:39:44.160
那紅色的、這個菱形的範圍內

0:39:44.160,0:39:46.160
它的 output 就要是 1

0:39:46.160,0:39:50.060
藍色的、菱形的範圍內，它的 output 就要是 0

0:39:50.060,0:39:52.720
那現在，我們來考慮

0:39:52.720,0:39:56.980
如果我們用了不同的 training example

0:39:56.980,0:39:58.640
不同量的 training example

0:39:58.640,0:40:02.480
在一個 hidden layer 跟三個 hidden layer 的時候

0:40:02.480,0:40:04.700
我們看到甚麼樣的情境

0:40:04.700,0:40:09.080
這邊要注意一下就是，我們有特別調整一個 hidden layer

0:40:09.080,0:40:11.740
和三個 hidden layer 的參數

0:40:11.740,0:40:14.580
所以並不是說，當有三個 hidden layer 的時候

0:40:14.580,0:40:17.300
它的參數是比一個 hidden layer 多的

0:40:17.300,0:40:18.860
所以，一個 hidden layer 的 neural network

0:40:18.860,0:40:20.340
是一個很胖的 neural network

0:40:20.340,0:40:22.120
三個 hidden layer 的 neural network

0:40:22.120,0:40:23.520
它是一個很瘦的 neural network

0:40:23.520,0:40:25.180
所以，它們的參數

0:40:25.180,0:40:26.960
是調整到接近

0:40:26.960,0:40:30.040
所以你要注意一下，當你在比

0:40:30.040,0:40:31.380
一個 shallow 的 network 跟

0:40:31.380,0:40:32.880
一個比較 deep 的 network 的時候

0:40:32.880,0:40:35.680
一個公平的評比，應該要讓它們有一樣的參數

0:40:35.680,0:40:37.940
應該要讓它們有一樣的參數量

0:40:37.940,0:40:41.260
那如果你現在給它看這個

0:40:41.260,0:40:43.380
這邊是十萬筆 data 的話

0:40:43.380,0:40:46.460
那這兩個 network

0:40:46.460,0:40:49.300
都可以 learn 出這樣子的 training data

0:40:49.300,0:40:53.300
你從這個 function 裡面 sample 十萬筆 data

0:40:53.300,0:40:55.480
然後，給它去學，給它去學

0:40:55.480,0:40:58.620
然後，它學出來就是長這樣

0:40:58.620,0:41:00.180
長的就是這樣

0:41:00.180,0:41:02.100
那對一個 hidden layer 來說

0:41:02.100,0:41:04.280
反正，它可以模擬任何 function

0:41:04.280,0:41:06.160
只要它夠寬，它就可以模擬任何 function

0:41:06.160,0:41:07.160
這種菱形的 function

0:41:07.160,0:41:10.380
這種地毯的 function 應該也不是甚麼問題

0:41:10.380,0:41:13.920
現在，如果我們減少參數的量

0:41:13.920,0:41:15.940
減少到只用兩萬筆

0:41:15.940,0:41:18.620
我們只從這裡 sample 出兩萬筆來做 training 

0:41:18.620,0:41:20.000
這個時候你會發現說

0:41:20.000,0:41:21.700
如果只有 1 個 hidden layer 的時候

0:41:21.700,0:41:24.680
你的結果就崩掉了

0:41:24.680,0:41:26.620
但是，如果是 3 個 hidden layer 的時候

0:41:26.620,0:41:28.800
你結果也是變得比較差

0:41:28.800,0:41:30.980
比 training data 多的時候還要差

0:41:30.980,0:41:34.460
但是你會發現說，你用 3 個 hidden layer 的時候

0:41:34.460,0:41:37.900
它的崩壞是有次序的崩壞

0:41:37.900,0:41:40.160
你看這個結果

0:41:40.160,0:41:42.160
它這個結果就像是

0:41:42.160,0:41:44.200
你今天要剪窗花的時候

0:41:44.200,0:41:46.720
你把色紙折起來，但是最後剪壞了

0:41:46.720,0:41:50.340
然後，展開以後長成這個樣子

0:41:51.420,0:41:54.320
所以說

0:41:54.320,0:41:56.260
而且你會發現說

0:41:56.260,0:41:58.660
在比較少的 training data 的時候

0:41:58.660,0:42:01.800
你有比較多的 hidden layer 最後得到的結果呢

0:42:01.800,0:42:04.760
其實是比較好的

0:42:08.160,0:42:10.440
當我們用 deep learning 的時候呢

0:42:10.440,0:42:14.540
另外一個好處是我們可以做 End-to-end learning

0:42:14.540,0:42:17.320
所謂的  End-to-end learning 的意思是這樣

0:42:17.320,0:42:19.620
比如說我們要處理的問題呢

0:42:19.620,0:42:21.140
非常的複雜

0:42:21.140,0:42:25.600
比如說，語音辨識就是一個非常複雜的問題

0:42:25.600,0:42:28.500
那我們說，我們要解一個 machine learning 的 problem 的時候

0:42:28.500,0:42:29.800
我們要做的事情就是

0:42:29.800,0:42:33.120
先找一個 hypothesis 的 function set

0:42:33.120,0:42:35.880
也就是找一個 model

0:42:35.880,0:42:38.720
當你要處理的問題是很複雜的時候

0:42:38.720,0:42:41.300
你這個 model 裡面，它會變成一個

0:42:41.300,0:42:44.140
它會需要是一個生產線

0:42:44.140,0:42:45.920
它會需要是一個生產線

0:42:45.920,0:42:48.800
那你這個 model 裡面，它表示一個很複雜的 function

0:42:48.800,0:42:52.220
一個很複雜的 function 是由很多比較簡單的 function

0:42:52.220,0:42:53.880
串接在一起

0:42:53.880,0:42:55.760
比如說，你要做語音辨識的話

0:42:55.760,0:42:57.240
你先把聲音訊號送進來

0:42:57.240,0:42:59.840
再透過很多層 function，一層一層的轉換

0:42:59.840,0:43:02.580
最後，變成文字

0:43:02.580,0:43:05.040
當你做 End-to-end learning 的時候

0:43:05.040,0:43:07.820
意思就是說，你只給你的 model

0:43:07.820,0:43:09.460
input 跟 output

0:43:09.460,0:43:12.340
不告訴它說，中間每一個 function

0:43:12.340,0:43:14.440
要怎麼分工

0:43:14.440,0:43:16.200
你就只給它 input 跟 output

0:43:16.200,0:43:18.400
然後，讓它自己去學

0:43:18.400,0:43:19.740
讓它去學會說

0:43:19.740,0:43:23.460
 中間每一個 function，生產線的每一個點

0:43:23.460,0:43:27.240
每一站，它應該要做什麼事情

0:43:29.580,0:43:33.360
那這件事情，如果
你在 deep learning 裡面要做這件事情的時候

0:43:33.360,0:43:35.740
你就是疊一個很深的 neural network

0:43:35.740,0:43:39.260
每一層就是生產線上的一個點

0:43:39.260,0:43:41.300
每一層都是一個 simple 的 function

0:43:41.300,0:43:43.120
每一層會自己學到說

0:43:43.120,0:43:44.800
它應該要做什麼樣的事情

0:43:45.680,0:43:47.720
比如說，在語音辨識裡面

0:43:47.720,0:43:50.940
在還沒有用 deep learning 的時候

0:43:50.940,0:43:53.460
在還是 shallow learning 的時代

0:43:53.460,0:43:56.300
我們怎麼做語音辨識呢，們可能是這樣做的

0:43:56.300,0:43:58.940
你先有一段聲音訊號

0:43:58.940,0:44:03.000
然後，要怎麼把聲音訊號對應成文字呢

0:44:03.000,0:44:07.060
你要先做 DFT，你不知道這是甚麼也沒有關係

0:44:07.060,0:44:09.280
反正就是一個 function

0:44:09.280,0:44:11.300
生產線上的某一個站

0:44:11.300,0:44:13.380
然後，它變成 spectrogram

0:44:13.380,0:44:16.340
然後，這個 spectrogram 通過 filter bank

0:44:16.340,0:44:19.120
不知道 filter bank 是甚麼東西沒有關係
反正就生產線上另外一站

0:44:19.120,0:44:22.020
再得到 output，再取 log

0:44:22.020,0:44:24.480
取 log 我想大家應該都知道吧，但是

0:44:24.480,0:44:28.120
它的原理其實是，這個取 log 其實是非常有道理的

0:44:28.120,0:44:30.280
不過，我們這邊不講就是了

0:44:30.280,0:44:33.740
然後再做 DCT，最後得到 MFCC

0:44:33.740,0:44:35.880
然後再把 MFCC 丟到 GMM 裡面

0:44:35.880,0:44:39.560
最後，你可以得到語音辨識的結果

0:44:39.560,0:44:42.740
這個 GMM 其實你把它換成 DNN

0:44:42.740,0:44:45.700
也是會有非常顯著的 improvement

0:44:45.700,0:44:48.940
那在這整個生產線上面呢

0:44:48.940,0:44:50.960
只有最後一個 block

0:44:50.960,0:44:54.040
只有最後這個 GMM 這個部分

0:44:54.040,0:44:57.040
藍色這個 block，是由 training data 學出來的

0:44:57.040,0:45:00.700
前面這個綠色的部分，這個都是人手訂的

0:45:00.700,0:45:04.440
就是過去有五聖先賢

0:45:04.440,0:45:09.800
他們研究了各種人類生理的知識以後

0:45:09.800,0:45:13.600
訂出了這些 function，那它非常非常的強

0:45:13.600,0:45:16.400
增一分則太肥，減一分則太瘦這樣

0:45:16.400,0:45:18.220
你就不要想在這上面再去改什麼東西

0:45:18.220,0:45:19.720
你改了之後會比較差

0:45:19.720,0:45:22.960
就這樣子大概卡了 20 年

0:45:22.960,0:45:25.840
五聖先賢實在太厲害了

0:45:25.840,0:45:29.220
但是，後來有了 deep learning 以後

0:45:29.220,0:45:31.680
我們可以把這些東西

0:45:31.680,0:45:35.820
用 neural network 把它取代掉

0:45:35.820,0:45:37.800
就是說，你可以把

0:45:37.800,0:45:41.560
你就把你的 deep neural network 多加幾層

0:45:41.560,0:45:43.540
然後，你就把 DCT 拿掉

0:45:43.540,0:45:45.640
這件事情現在已經是

0:45:45.640,0:45:47.060
typical 的做法了

0:45:47.060,0:45:52.040
過去 MFCC 這種 feature，如果你上語音課的話呢

0:45:52.040,0:45:53.300
你上李琳山老師的語音課

0:45:53.300,0:45:55.580
你很有可能知道 MFCC 是甚麼

0:45:55.580,0:45:58.280
過去，可能 20 年，這個 feature

0:45:58.280,0:46:00.460
是 dominate 語音辨識這件事情

0:46:00.460,0:46:03.540
但是現在已經不再是這樣子了 

0:46:03.540,0:46:06.640
你可以直接從 log 的 output 開始做

0:46:06.640,0:46:09.520
甚至，比較多人從 log 的 output 開始做

0:46:09.520,0:46:12.720
你把你的 neural network 疊深一點，
直接從 log 的 output 開始做

0:46:12.720,0:46:16.160
你會得到比較好的結果

0:46:16.160,0:46:20.720
所以我記得在14年的、在語音的會議上的時候

0:46:22.960,0:46:24.840
MSR 的 research team (MSR = Microsoft Research)

0:46:24.840,0:46:28.360
語音 research team 的 head, Deng Li 進來說，掰掰 MFCC

0:46:28.360,0:46:31.340
大家也沒有甚麼特別的意見這樣

0:46:31.340,0:46:35.100
現在，甚至你可以從 spectrogram 開始做

0:46:35.100,0:46:38.160
你把這些都拿掉

0:46:38.160,0:46:41.160
通通都拿 deep neural network 來取代掉

0:46:41.160,0:46:43.100
也可以得到更好的結果

0:46:43.100,0:46:47.600
那 deep neural network 學到的，它要做的事情

0:46:47.600,0:46:50.660
你會發現，如果你分析
那個 deep neural network 的 weight 的話 

0:46:50.660,0:46:53.720
它可以自動學到要做 filter bank 這件事情

0:46:53.720,0:46:57.120
filter bank 是模擬人類的聽覺器官 

0:46:57.120,0:46:58.400
所製定出來的 filter

0:46:58.400,0:47:00.700
但是 deep learning 可以自動學到這件事情

0:47:00.700,0:47:03.120
接下來，有人就會想要挑戰說

0:47:03.120,0:47:06.680
我們能不能夠疊一個很深很深的 neural network

0:47:06.680,0:47:09.580
我們能不能夠疊一個很深很深的 neural network

0:47:09.580,0:47:11.960
直接 input 就是 time domain 上的聲音訊號

0:47:11.960,0:47:13.940
然後，output 直接就是

0:47:13.940,0:47:17.500
文字，中間完全不要做 feature transform 之類的

0:47:17.500,0:47:19.760
如果連 feature transform 都不用做的話

0:47:19.760,0:47:21.780
那你就不需要學訊號與系統

0:47:24.940,0:47:28.580
但是還好這件事情，後來結局是這個樣子

0:47:28.580,0:47:30.160
這件事情的結局是這個樣子

0:47:30.160,0:47:32.580
有好多好多人前仆後繼的

0:47:32.580,0:47:33.920
在做這一件事情

0:47:33.920,0:47:35.860
這個甚至曾經一度

0:47:35.860,0:47:39.240
在 conference 裡面有兩個 session 都在做這件事情

0:47:39.240,0:47:41.980
最後，Google 有一篇 paper 是這樣

0:47:41.980,0:47:43.380
它最後的結果是

0:47:43.380,0:47:46.480
它拼死去 learn 了一個很大的 neural network

0:47:46.480,0:47:48.040
input 就是聲音訊號

0:47:48.040,0:47:49.680
完全不做其他任何的事情 

0:47:49.680,0:47:52.880
input 就是 row 的 wave phone

0:47:52.880,0:47:56.600
最後可以做到跟有做 feature transform 的結果打平

0:47:56.600,0:47:59.100
但也僅止於打平而已

0:47:59.100,0:48:02.320
我目前還沒有看到有一個結果是，可以 input

0:48:02.320,0:48:03.780
聲音訊號

0:48:03.780,0:48:06.600
input time domain 的聲音，不做 feature transform

0:48:06.600,0:48:08.780
結果比 feature transform 好

0:48:08.780,0:48:11.480
可見 feature transform 很強，或許它已經是

0:48:11.480,0:48:13.340
訊號處理的極限了

0:48:13.340,0:48:14.700
就跟 machine learning learn 出來的結果

0:48:14.700,0:48:16.860
其實也就是 feature transform

0:48:17.520,0:48:18.580
如果你觀察

0:48:18.580,0:48:21.300
你看 Google 那篇 paper 的話，它其實會分析一下

0:48:21.300,0:48:23.740
它的這個 machine 做的事情

0:48:23.740,0:48:26.500
它做的事情就很像是在做 feature transform

0:48:26.500,0:48:29.100
但是，做出來也就跟 feature transform 一樣好

0:48:29.100,0:48:31.000
也沒也辦法比 feature transform 做的更好

0:48:31.000,0:48:33.140
所以，修訊號與系統還是必要的

0:48:34.780,0:48:37.820
剛才講的都是語音的例子

0:48:37.820,0:48:40.980
那影像的話，其實也是差不多啦

0:48:40.980,0:48:44.200
這個我想大家應該都知道，所以

0:48:44.200,0:48:47.480
我們就稍微跳過去，過去影像也是

0:48:47.480,0:48:49.120
疊很多很多的 block

0:48:49.120,0:48:52.260
有很多很多人訂的、handcrafted 的 feature

0:48:52.260,0:48:55.600
那你只是在用很多很多的 block

0:48:55.600,0:48:58.320
很多很多 handcrafted 的 feature 去處理你 input 的影像

0:48:58.320,0:49:01.940
然後，只又在最後一層，用一個 shallow 的 classifier

0:49:01.940,0:49:04.360
現在，你就直接兜一個

0:49:04.360,0:49:05.920
很深的 network

0:49:05.920,0:49:07.500
input 就直接是 pixel

0:49:07.500,0:49:09.520
output 就直接是裡面影像是甚麼

0:49:09.520,0:49:10.680
就不需要抽 feature 了

0:49:11.840,0:49:13.700
那 deep learning  還有什麼好處呢

0:49:13.700,0:49:16.260
有時候我們會做

0:49:16.260,0:49:18.420
通常我們真正在意的 task

0:49:18.420,0:49:20.820
它是非常的複雜的

0:49:20.820,0:49:23.380
那在這種非常的複雜的 task 裡面

0:49:23.380,0:49:28.660
有時候非常像的 input，它會有很不一樣的output

0:49:28.660,0:49:30.960
舉例來說，你在做影像辨識的時候

0:49:30.960,0:49:33.100
這個白色的狗

0:49:33.100,0:49:35.840
跟北極熊其實看起來是很像的

0:49:35.840,0:49:37.680
它們其實是很像的

0:49:37.680,0:49:39.820
但是你的 machine 要知道說

0:49:39.820,0:49:44.480
看到這個要 output 狗，看到這個要 output 北極熊

0:49:45.420,0:49:49.380
有時候看起來很不一樣的東西

0:49:49.380,0:49:51.960
其實是一樣的，比如說，這個是火車

0:49:51.960,0:49:56.360
側面看是這個樣子，橫看成嶺側成峰

0:49:57.000,0:49:59.580
橫著看就變這個樣子

0:49:59.580,0:50:02.480
所以它們是不一樣的，但 output 都要是火車

0:50:02.480,0:50:05.620
如果你今天的 network

0:50:05.620,0:50:06.740
只有一層的話

0:50:06.740,0:50:08.120
你只能夠簡單的 transform

0:50:08.120,0:50:11.360
你沒有辦法把一樣的東西變得很不一樣

0:50:11.360,0:50:13.580
把不一樣的東西變得很像

0:50:13.580,0:50:15.900
你要讓原來 input 很像的東西

0:50:15.900,0:50:18.160
結果看起來很不像

0:50:18.160,0:50:20.860
你需要做很多層次的轉換

0:50:20.860,0:50:23.520
舉例來說，如果我們看下面這個例子

0:50:23.520,0:50:25.340
這個是語音的例子

0:50:25.340,0:50:27.680
在這個圖上，我們是吧

0:50:27.680,0:50:29.380
這個不是我做的

0:50:29.380,0:50:32.460
這個是來自於 ICASSP 2012 的一篇 paper

0:50:32.460,0:50:33.720
在這個圖上

0:50:33.720,0:50:35.600
這邊做的事情是

0:50:35.600,0:50:39.400
把 MFCC 投影到二維的平面上

0:50:39.400,0:50:42.260
那同樣的顏色

0:50:42.260,0:50:44.500
代表的是這個

0:50:44.500,0:50:46.720
不同的顏色

0:50:46.720,0:50:50.920
代表的是不同的人說的話

0:50:50.920,0:50:52.880
紅色代表是某個人說的句子

0:50:52.880,0:50:54.560
綠色代表是某個人說的句子

0:50:54.560,0:50:55.740
藍色代表是某個人說的句子

0:50:55.740,0:50:58.400
注意一下，這些人說的句子是不一樣的

0:50:59.000,0:51:03.740
在語音上，你會發現說同樣的句子

0:51:03.740,0:51:05.180
不同的人說

0:51:05.180,0:51:08.380
它的聲音訊號看起來是非常不一樣的

0:51:08.380,0:51:11.260
你會發現說，這個紅色看起來跟藍色間沒有什麼關係

0:51:11.260,0:51:13.120
藍色看起來跟綠色間沒有什麼關係

0:51:13.120,0:51:15.260
所以，有人看到這個圖就覺得

0:51:15.260,0:51:17.160
語音辨識不能做啊

0:51:17.160,0:51:20.740
不能做，不同的人說話的聲音太不一樣了

0:51:20.740,0:51:23.180
就算說同樣的句子，感覺也太不一樣不能做

0:51:23.180,0:51:25.800
如果你今天 learn 一個 neural network

0:51:25.800,0:51:29.600
如果你只看第一層的 hidden layer 的 output

0:51:29.600,0:51:32.740
你會發現說不同的人

0:51:32.740,0:51:35.400
講的話、講的同一個句子

0:51:35.400,0:51:37.260
還是看起來很不一樣

0:51:37.260,0:51:41.460
但是如果你今天看的八個 hidden layer 的 output 時候

0:51:41.460,0:51:43.900
你會發現說

0:51:43.900,0:51:46.380
不同的人說的同樣的句子

0:51:46.380,0:51:49.400
它自動的被 align 在一起

0:51:49.400,0:51:52.900
也就是說，這個 DNN 在很多的 layer 的轉換的時候

0:51:52.900,0:51:55.760
它把本來看起來很不像的東西

0:51:55.760,0:51:58.180
它知道說它們應該是一樣的

0:51:58.180,0:51:59.820
經過很多的 layer 的轉換以後

0:51:59.820,0:52:02.040
就把它們兜在一起

0:52:02.040,0:52:06.500
就把它們 map 在一起了

0:52:06.500,0:52:08.560
比如說，你看這個圖上面

0:52:08.560,0:52:12.180
這邊你會看到一條一條的線

0:52:12.180,0:52:16.100
那在這條線裡面，你會看到不同顏色的聲音訊號

0:52:16.100,0:52:19.060
也就是說，不同的人說同樣的話

0:52:19.060,0:52:21.600
經過 8 個 hidden layer 的轉換以後

0:52:21.600,0:52:24.260
對 neural network 來說，它就變得很像

0:52:24.260,0:52:27.660
本來的 input 完全不像，再通過很多個 layer 的轉換以後

0:52:27.660,0:52:29.740
它就變得像

0:52:30.160,0:52:33.520
或者是，今天這個是語音的例子

0:52:33.520,0:52:36.300
如果我們看 MNIST 手寫數字辨識的例子

0:52:36.300,0:52:38.260
其實也可以輕易地做到這些實驗

0:52:38.260,0:52:40.800
input 的 vector 是長這個樣子

0:52:40.800,0:52:45.060
input 就是 28*28 個 pixel

0:52:45.060,0:52:47.260
如果你把 28*28 個 pixel

0:52:47.260,0:52:50.480
28*28 的 vector project 到

0:52:50.480,0:52:56.760
二維的平面的話，那它看起來像是這個樣子

0:52:56.760,0:52:58.940
你會發現說，在這個圖上

0:52:58.940,0:53:03.680
它這邊這個 4 跟 9 幾乎是疊在一起的

0:53:03.680,0:53:05.660
因為 4 跟 9 很像，我們仔細想想看

0:53:05.660,0:53:08.940
4 跟 9 都是一個圈圈再加一條線

0:53:08.940,0:53:12.440
4 跟 9 很像，所以如果你光看 input 的 pixel 的話

0:53:12.440,0:53:16.300
4 跟 9 幾乎是疊在一起的，你幾乎沒有辦法把它分開

0:53:16.300,0:53:20.160
但是，如果我們看的一個 hidden layer 的 output

0:53:20.160,0:53:24.120
這個時候你會發現說， 4 跟 9 還是很像

0:53:24.120,0:53:26.020
它們還是離得很近

0:53:26.020,0:53:29.120
7 也跟 4 很像

0:53:29.120,0:53:33.040
4、7、9，它們是很像的

0:53:33.040,0:53:34.860
這是第一個 hidden layer 的 output

0:53:34.860,0:53:38.040
但是，如果我們看第二個
hidden layer 的 output，你就會發現說

0:53:38.040,0:53:39.840
4、7、9，是逐漸被分開的

0:53:39.840,0:53:43.200
到第三個 hidden layer 的 output，它們又被分得更開

0:53:43.200,0:53:47.360
所以，如果你今天要讓不一樣的 input

0:53:47.360,0:53:49.680
被 merge 在一起，相當在語音舉的例子

0:53:49.680,0:53:52.060
或者是讓

0:53:52.060,0:53:55.360
你要讓原來看起來很像的 input 

0:53:55.360,0:53:57.060
最後被分得很開

0:53:57.060,0:54:01.160
那你就需要好多 hidden layer 才能辦到這件事情

0:54:01.860,0:54:05.480
那其實還有更多用 deep learning 的理由啦

0:54:05.480,0:54:08.360
那這個有人寫了一篇 paper

0:54:08.360,0:54:10.580
Microsoft 的 researcher

0:54:10.580,0:54:14.160
Rich Caruana，他寫了一篇 paper，它的 title 是

0:54:14.160,0:54:17.680
Do Deep Nets Really Need to be Deep？

0:54:17.680,0:54:20.140
如果翻譯成中文就可以翻譯成這個

0:54:20.140,0:54:22.920
深度學習是不是過譽了

0:54:25.780,0:54:27.840
在這篇 paper 裡面呢

0:54:27.840,0:54:29.480
他做了一個很神奇

0:54:29.480,0:54:33.080
這篇 paper 有點舊，它大概是兩年前 publish 的

0:54:33.080,0:54:35.520
這篇 paper 看起來，那時候覺得很神奇

0:54:35.520,0:54:36.880
但現在已經是 common sense 了

0:54:36.880,0:54:38.820
他的做法是這樣，他說

0:54:38.820,0:54:42.400
我們今天來比較一下一層的 hidden layer

0:54:42.400,0:54:44.200
跟三層的 hidden layer 

0:54:44.200,0:54:46.040
它們在 MNIST 還有 TIMIT 這些

0:54:46.040,0:54:47.820
benchmark corpus 上的差別

0:54:47.820,0:54:49.640
當然結果並不意外

0:54:49.640,0:54:52.780
當你把一個 hidden layer 跟

0:54:52.780,0:54:54.820
三個 hidden layer 調一樣參數的時候

0:54:54.820,0:54:58.440
當然是三個 hidden layer performance 是比較好的

0:54:58.440,0:55:01.620
其實，你也可以自己 verify 這件事情

0:55:01.620,0:55:04.940
如果你有真的在做 deep learning 的話

0:55:04.940,0:55:08.360
其實，這是 common sense，然後

0:55:08.360,0:55:10.200
接下來，他發現說

0:55:10.200,0:55:11.560
一個 hidden layer

0:55:11.560,0:55:13.000
參數怎麼增加

0:55:13.000,0:55:14.480
performance 都不好

0:55:14.480,0:55:16.280
它很快就 saturate 了

0:55:16.280,0:55:21.120
他就想說，怎麼會這樣呢

0:55:21.120,0:55:24.400
他就做了一件當時看起來很匪夷所思的事

0:55:24.400,0:55:27.120
他說，一個 hidden layer 的 neural network

0:55:27.120,0:55:31.840
你 learning 的 target 不要用真正的 label

0:55:31.840,0:55:33.940
懂嗎？就是我們 本來learning 的時候

0:55:33.940,0:55:35.760
你要用真正的 label 阿

0:55:35.900,0:55:38.320
你就看說，這個 image 有人告訴你說這個是 1

0:55:38.320,0:55:39.460
有人告訴你說是 0

0:55:39.460,0:55:40.860
你的 network 就是用這個 train 的嘛

0:55:40.860,0:55:42.840
這是很合理的想法，他說

0:55:42.840,0:55:45.060
你現在的 shallow network 不要用這個 label

0:55:45.060,0:55:50.140
你用三層 hidden layer 的 output 當作你的 feature

0:55:50.140,0:55:53.700
三層 hidden layer，你把所有的 image

0:55:53.700,0:55:55.740
都丟到一個 learn 好的三層 hidden layer

0:55:55.740,0:55:57.000
然後，得到那些 output

0:55:57.000,0:55:59.940
那有一些 output 是錯的，就不管它是錯的這樣

0:55:59.940,0:56:03.600
然後，一層的 hidden layer 就去學三層的 hidden layer

0:56:03.600,0:56:05.920
幫你 label 的結果，那一個錯的 ，它就學一個錯的

0:56:05.920,0:56:08.540
結果，它的 performance 會比較好

0:56:08.540,0:56:14.220
會逼近三層的 hidden layer，
幾乎跟三層的 hidden layer 一樣好

0:56:14.220,0:56:15.740
因為，他就是想說

0:56:15.740,0:56:18.960
照理說，你只要一個 hidden layer 就能做到任何事

0:56:18.960,0:56:21.100
所以，沒有理由三層可以得到這個 performance

0:56:21.100,0:56:22.580
一層得不到這個 performance

0:56:22.580,0:56:25.220
但是，你直接 learn 一個一層的 network

0:56:25.220,0:56:26.580
你就是 learn 不出這個結果

0:56:26.580,0:56:29.080
你要去讓一層 network 模擬三層 network 的行為

0:56:29.080,0:56:32.580
它才能夠 learn 出這個結果

0:56:32.580,0:56:34.820
那有人讀了這篇 paper，他覺得說

0:56:34.820,0:56:38.180
Rich 的結論是 deep learning 不 work

0:56:38.180,0:56:39.920
其實他的結論不是 deep learning 不 work

0:56:39.920,0:56:41.200
我在 conference 遇過他本人

0:56:41.200,0:56:42.160
我問過他說

0:56:42.160,0:56:44.460
你的意思是 deep learning 不 work，他說不是

0:56:44.460,0:56:46.700
我的意思是 deep learning 是 work 的

0:56:46.700,0:56:49.740
就是你直接在一層 network 是 learn 不起來的

0:56:49.740,0:56:50.860
你要先 learn 三層的 network

0:56:50.860,0:56:53.900
再用一層的 network 去模擬三層 network 的行為

0:56:53.900,0:56:54.820
你才 learn 的起來

0:56:54.820,0:56:56.740
然後，這個是我在 ASRU

0:56:56.740,0:56:59.240
2015 的時候，聽過他的 keynote speech

0:56:59.240,0:57:00.480
這個時他的第一頁投影片

0:57:00.480,0:57:02.500
Do Deep Nets Really Need to be Deep？

0:57:02.500,0:57:04.000
然後，第二頁 Yes！

0:57:04.000,0:57:07.160
然後，我們留下很多時間給大家問問題，結束！

0:57:12.500,0:57:16.240
如果你想要學更多的話，你可以看一下這個

0:57:16.240,0:57:20.820
Bengio 的 deep learning 的 Theoretical 的 Motivations

0:57:20.820,0:57:24.060
他講了很多非常發人深省的想法

0:57:24.060,0:57:27.460
或者是，現在 deep learning 很紅了，所以有各種

0:57:27.460,0:57:30.720
來自其他領域的解讀，比如說從

0:57:30.720,0:57:33.040
物理的角度來解釋，為什麼要做 deep learning

0:57:33.040,0:57:36.480
從化學的角度來解釋，為什麼要做 deep learning

0:57:36.480,0:57:39.680
我把連結留在這邊給大家參考

0:57:39.680,0:57:41.040
講到這邊剛好告一個段落

0:57:41.040,0:57:44.720
臺灣大學人工智慧中心
科技部人工智慧技術暨全幅健康照護聯合研究中心
http://aintu.tw
